{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training species classifier Expt 3: cross-validation of Oswald data\n",
    "# Mar 16, 2021: fight overfitting\n",
    "# Replace categorical cross-entropy by binary cross-entropy\n",
    "## Spatial Pyramid Pooling (SPP): [1, 1], [1, 2], [1, 4], [1, 8]\n",
    "## The augemented noise is from the all five deployments.\n",
    "## Trained on PICEAS2005 & STAR2000 whereas tested on HICEAS2002, STAR2003 & STAR2006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import permutations\n",
    "import random\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n",
    "import pandas as pd\n",
    "from os import makedirs\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "from math import floor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# from MulticoreTSNE import MulticoreTSNE as TSNE\n",
    "# from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout, Activation\n",
    "from tensorflow.keras.layers import Conv2D, Lambda, Flatten, MaxPooling2D, Concatenate, LSTM, Reshape, Lambda, ConvLSTM2D, GlobalAveragePooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, GRU\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay, PiecewiseConstantDecay\n",
    "from tensorflow.keras.optimizers import SGD,Adam\n",
    "from tensorflow.keras.losses import binary_crossentropy, categorical_crossentropy  # CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow_addons.layers.spatial_pyramid_pooling as spp\n",
    "# import tensorflow_datasets as tfds\n",
    "from tensorflow.math import l2_normalize\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "# learning_rate = 1.0e-3\n",
    "conv_dim = 16\n",
    "rnn_dim = 16\n",
    "pool_size = 2\n",
    "pool_stride = 2\n",
    "l2_regu = 0.01\n",
    "drop_rate = 0.4\n",
    "hidden_units = 256\n",
    "fcn_dim = 256\n",
    "\n",
    "# learning_rate = 1.e-4\n",
    "# conv_dim = 64\n",
    "# rnn_dim = 16\n",
    "# pool_size = 2\n",
    "# pool_stride = 2\n",
    "# l2_regu = 0.00\n",
    "# drop_rate = 0.2\n",
    "# # drop_rate = 0.5\n",
    "# hidden_units = 512\n",
    "# fcn_dim = 512\n",
    "\n",
    "num_epoch = 200\n",
    "# batch_size = 128\n",
    "# batch_size = 32  # for cnn14+attention\n",
    "batch_size = 16  # for cnn14+spp\n",
    "\n",
    "num_patience = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_type_dict = {1: 'universal', 2: 'file', 3: 'encounter', 4: 'domain'}\n",
    "# data_type = 2\n",
    "\n",
    "work_path = '/home/ys587/__Data/__whistle/__whislte_30_species'\n",
    "fit_result_path =  os.path.join(work_path, '__fit_result_species')\n",
    "# feature_path = os.path.join(work_path, '__feature_species')\n",
    "feature_path = os.path.join(work_path, '__dataset/20210210')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_dict = {'BD': 0, 'CD': 1, 'STR': 2, 'SPT': 3, 'SPIN': 4, 'PLT': 5, 'RT': 6,  'FKW': 7}\n",
    "num_species = len(species_dict)\n",
    "# species_dict = {'BD': 0, 'MH': 1, 'CD': 2, 'STR': 3, 'SPT': 4, 'SPIN': 5, 'PLT': 6, 'RD': 7, 'RT': 8,\n",
    "#                 'WSD': 9, 'FKW': 10, 'BEL': 11, 'KW': 12, 'WBD': 13, 'DUSK': 14, 'FRA': 15, 'PKW': 16, 'LPLT': 17,\n",
    "#                 'CLY': 18, 'SPE': 19, 'ASP': 20}\n",
    "species_list = list(species_dict.keys())\n",
    "species_id = list(species_dict.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment = ['STAR2000', 'STAR2003', 'STAR2006', 'HICEAS2002', 'PICEAS2005']  # oswald_STAR2000_orig.npz, oswald_STAR2000_aug.npz\n",
    "feature_path = '/home/ys587/__Data/__whistle/__whislte_30_species/__dataset/20210223_augment_all_three_noise_mixed'\n",
    "# feature_path = '/home/ys587/__Data/__whistle/__whislte_30_species/__dataset/20210308_augment_all_three_noise_mixed_class_balanced_min_5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    for ee in deployment:\n",
    "        print(ee)\n",
    "        ee_others = [ee2 for ee2 in deployment if (ee2 != ee) ]\n",
    "        fea_train_files_tot = []\n",
    "        for ee2 in ee_others:\n",
    "            fea_train_files_tot.append('oswald_'+ee2+'_orig.npz')\n",
    "            fea_train_files_tot.append('oswald_'+ee2+'_aug.npz')\n",
    "\n",
    "        # Training data\n",
    "        fea_train_list = []\n",
    "        label_train_list = []\n",
    "        for ii in range(len(fea_train_files_tot)):\n",
    "            ff = fea_train_files_tot[ii]\n",
    "            print(ff)\n",
    "            fea_temp = np.load(os.path.join(feature_path, ff))\n",
    "            print(fea_temp.files)\n",
    "\n",
    "            if ii == 0:\n",
    "                fea_train = fea_temp['feas_orig']\n",
    "                label_train = fea_temp['labels_orig']\n",
    "                print(fea_train.shape)\n",
    "                print(label_train.shape)\n",
    "            elif ii % 2 == 0:  # even\n",
    "                fea_train = np.concatenate([fea_train, fea_temp['feas_orig']])\n",
    "                label_train = np.concatenate([label_train, fea_temp['labels_orig']])\n",
    "                print(fea_train.shape)\n",
    "                print(label_train.shape)\n",
    "            else:\n",
    "                fea_train = np.concatenate([fea_train, fea_temp['feas_aug']])\n",
    "                label_train = np.concatenate([label_train, fea_temp['labels_aug']])\n",
    "                print(fea_train.shape)\n",
    "                print(label_train.shape)\n",
    "        print(fea_train.shape)\n",
    "        print(label_train.shape)\n",
    "        np.savez(os.path.join(feature_path, './train_oswald_no_'+ee+'.npz'), fea_train=fea_train, label_train=label_train)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data generator\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, feature, label, batch_size=32, num_classes=None, shuffle=True):\n",
    "        self.batch_size = batch_size\n",
    "        self.X = feature\n",
    "        self.X_dim = len(feature.shape)\n",
    "        self.y = to_categorical(label, num_classes)\n",
    "        self.indices = np.arange(self.y.shape[0])\n",
    "        self.num_classes = num_classes\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        # self.index = np.arange(len(self.indices))\n",
    "        #self.df = dataframe\n",
    "        #self.indices = self.df.index.tolist()        \n",
    "        # self.x_col = x_col\n",
    "        # self.y_col = y_col\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(floor(len(self.indices)/self.batch_size))\n",
    "        # return label.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # index = self.index[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        # batch = [self.indices[k] for k in index]\n",
    "        batch = list(range(index*self.batch_size, (index+1)*self.batch_size))\n",
    "        \n",
    "        X, y = self.__get_data(batch)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "    def __get_data(self, batch):\n",
    "        y = np.zeros((self.batch_size, self.y.shape[1]))\n",
    "        \n",
    "        if self.X_dim == 3:\n",
    "            X = np.zeros((self.batch_size, self.X.shape[1], self.X.shape[2]))\n",
    "            for i, id in enumerate(batch):\n",
    "                X[i,:, :] = self.X[id, :, :]  # logic\n",
    "                y[i, :] = self.y[id, :] # labels\n",
    "                \n",
    "        elif self.X_dim == 4:\n",
    "            X = np.zeros((self.batch_size, self.X.shape[1], self.X.shape[2], self.X.shape[3]))\n",
    "            for i, id in enumerate(batch):\n",
    "                X[i,:, :, :] = self.X[id, :, :, :]  # logic\n",
    "                y[i, :] = self.y[id, :] # labels\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kong's attention\n",
    "# def max_pooling(inputs, **kwargs):\n",
    "#     input = inputs[0]   # (batch_size, time_steps, freq_bins)\n",
    "#     return K.max(input, axis=1)\n",
    "def max_pooling(inputs, **kwargs):\n",
    "    # input = inputs[0]   # (batch_size, time_steps, freq_bins)\n",
    "    return K.max(inputs, axis=1)\n",
    "\n",
    "\n",
    "def average_pooling(inputs, **kwargs):\n",
    "    input = inputs[0]   # (batch_size, time_steps, freq_bins)\n",
    "    return K.mean(input, axis=1)\n",
    "\n",
    "\n",
    "def attention_pooling(inputs, **kwargs):\n",
    "    [out, att] = inputs\n",
    "\n",
    "    epsilon = 1e-7\n",
    "    att = K.clip(att, epsilon, 1. - epsilon)\n",
    "    normalized_att = att / K.sum(att, axis=1)[:, None, :]\n",
    "\n",
    "    return K.sum(out * normalized_att, axis=1)\n",
    "\n",
    "\n",
    "def pooling_shape(input_shape):\n",
    "\n",
    "    if isinstance(input_shape, list):\n",
    "        (sample_num, time_steps, freq_bins) = input_shape[0]\n",
    "\n",
    "    else:\n",
    "        (sample_num, time_steps, freq_bins) = input_shape\n",
    "\n",
    "    return (sample_num, freq_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn14 SPP\n",
    "def model_cnn14_spp(time_steps, freq_bins, classes_num, conv_dim=64, rnn_dim=128, pool_size=2, pool_stride=2, hidden_units=512, l2_regu=0., drop_rate=0., multilabel=True):\n",
    "    input_layer = Input(shape=(time_steps, freq_bins, 1), name='input')\n",
    "    # group 1\n",
    "    y = Conv2D(conv_dim, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(input_layer)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = Conv2D(conv_dim, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = MaxPooling2D(pool_size=(pool_size, 2), strides=(pool_stride, 2), padding='same')(y)\n",
    "    y = Dropout(drop_rate)(y)\n",
    "    \n",
    "    # group 2\n",
    "    y = Conv2D(conv_dim*2, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = Conv2D(conv_dim*2, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = MaxPooling2D(pool_size=(pool_size, 2), strides=(pool_stride, 2), padding='same')(y)\n",
    "    y = Dropout(drop_rate)(y)\n",
    "    \n",
    "    # group 3\n",
    "    y = Conv2D(conv_dim*4, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = Conv2D(conv_dim*4, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = MaxPooling2D(pool_size=(pool_size, 2), strides=(pool_stride, 2), padding='same')(y)\n",
    "    y = Dropout(drop_rate)(y)\n",
    "    \n",
    "    # group 4 \n",
    "    y = Conv2D(conv_dim*8, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = Conv2D(conv_dim*8, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = MaxPooling2D(pool_size=(pool_size, 2), strides=(pool_stride, 2), padding='same')(y)\n",
    "    y = Dropout(drop_rate)(y)\n",
    "\n",
    "    # group 5\n",
    "    y = Conv2D(conv_dim*16, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = Conv2D(conv_dim*16, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "#     y = MaxPooling2D(pool_size=(pool_size, 2), strides=(1, 2), padding='same')(y)\n",
    "#     y = Dropout(drop_rate)(y)\n",
    "\n",
    "#     # group 6\n",
    "#     y = Conv2D(conv_dim*32, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "#     y = BatchNormalization()(y)\n",
    "#     y = Activation(activation='relu')(y)\n",
    "#     y = Conv2D(conv_dim*32, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "#     y = BatchNormalization()(y)\n",
    "#     y = Activation(activation='relu')(y)\n",
    "#     y = MaxPooling2D(pool_size=(pool_size, 2), strides=(1, 2), padding='same')(y)\n",
    "#     y = Dropout(drop_rate)(y)\n",
    "    \n",
    "    # change dimensions: samples, time, frequency, channels => samples, time, frequency*channels\n",
    "    #  dim_cnn = K.int_shape(y)\n",
    "    # y = Reshape((dim_cnn[1], dim_cnn[2]*dim_cnn[3]))(y)\n",
    "    \n",
    "    y = spp.SpatialPyramidPooling2D(bins=[[1, 1], [2, 2], [4, 4]], data_format='channels_last')(y)\n",
    "    dim_spp = K.int_shape(y)\n",
    "    y = Reshape((dim_spp[1]*dim_spp[2], ))(y)\n",
    "\n",
    "    # FC block\n",
    "    a1 = Dense(hidden_units)(y)\n",
    "    a1 = BatchNormalization()(a1)\n",
    "    a1 = Activation('relu')(a1)\n",
    "    a1 = Dropout(drop_rate)(a1)\n",
    "\n",
    "    a2 = Dense(hidden_units)(a1)\n",
    "    a2 = BatchNormalization()(a2)\n",
    "    a2 = Activation('relu')(a2)\n",
    "    a2 = Dropout(drop_rate)(a2)\n",
    "\n",
    "    a3 = Dense(hidden_units)(a2)\n",
    "    a3 = BatchNormalization()(a3)\n",
    "    a3 = Activation('relu')(a3)\n",
    "    a3 = Dropout(drop_rate)(a3)\n",
    "    \n",
    "#     y = Dense(hidden_units, activation='relu', name='cnn14_fcn')(y)  # original 512\n",
    "#      y = Dense(hidden_units, activation='relu', name='cnn14_fcn2')(y)  # original 512\n",
    "    # x = Dense(classes_num, activation='softmax')(y)\n",
    "#     x = Dense(classes_num, activation='sigmoid')(y)\n",
    "    x = Dense(classes_num, activation='sigmoid')(a3)\n",
    "    \n",
    "    # Build model\n",
    "    model = Model(inputs=input_layer, outputs=x)\n",
    "    \n",
    "    return model\n",
    "\n",
    "#     a1 = Dense(hidden_units)(y)\n",
    "#     a1 = BatchNormalization()(a1)\n",
    "#     a1 = Activation('relu')(a1)\n",
    "#     a1 = Dropout(drop_rate)(a1)\n",
    "\n",
    "#     a2 = Dense(hidden_units)(a1)\n",
    "#     a2 = BatchNormalization()(a2)\n",
    "#     a2 = Activation('relu')(a2)\n",
    "#     a2 = Dropout(drop_rate)(a2)\n",
    "    \n",
    "#     output_layer = Dense(classes_num, activation='softmax')(a2)\n",
    "\n",
    "#     if False:\n",
    "#         # Pooling layers 'decision_level_max_pooling':\n",
    "#         '''Global max pooling.\n",
    "\n",
    "#         [1] Choi, Keunwoo, et al. \"Automatic tagging using deep convolutional \n",
    "#         neural networks.\" arXiv preprint arXiv:1606.00298 (2016).\n",
    "#         '''\n",
    "#         cla = Dense(classes_num, activation='sigmoid')(a2)\n",
    "\n",
    "#         # output_layer = Lambda(\n",
    "#         #    max_pooling, \n",
    "#         #    output_shape=pooling_shape)(\n",
    "#         #    [cla])\n",
    "#         output_layer = Lambda(max_pooling)(cla)\n",
    "\n",
    "#     # Build model\n",
    "#     model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn14 attention with customized maxpooling\n",
    "def model_cnn14_attention_multi(time_steps, freq_bins, classes_num, model_type='feature_level_attention', conv_dim=64, rnn_dim=128, pool_size=2, pool_stride=2, hidden_units=512, l2_regu=0., drop_rate=0., multilabel=True):\n",
    "    # Kong's attention\n",
    "    # model_type = 'decision_level_max_pooling'  # problem with dimensions of the Lambda layer after training\n",
    "    # model_type = 'decision_level_average_pooling' # problem with dimensions of the Lambda layer after training\n",
    "    # model_type = 'decision_level_single_attention'\n",
    "    # model_type = 'decision_level_multi_attention'\n",
    "    # model_type = 'feature_level_attention'\n",
    "\n",
    "    input_layer = Input(shape=(time_steps, freq_bins, 1), name='input')\n",
    "    # group 1\n",
    "    y = Conv2D(conv_dim, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(input_layer)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = Conv2D(conv_dim, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = MaxPooling2D(pool_size=(pool_size, 2), strides=(pool_stride, 2), padding='same')(y)\n",
    "    y = Dropout(drop_rate)(y)\n",
    "    \n",
    "    # group 2\n",
    "    y = Conv2D(conv_dim*2, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = Conv2D(conv_dim*2, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = MaxPooling2D(pool_size=(pool_size, 2), strides=(pool_stride, 2), padding='same')(y)\n",
    "    y = Dropout(drop_rate)(y)\n",
    "    \n",
    "    # group 3\n",
    "    y = Conv2D(conv_dim*4, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = Conv2D(conv_dim*4, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = MaxPooling2D(pool_size=(pool_size, 2), strides=(pool_stride, 2), padding='same')(y)\n",
    "    y = Dropout(drop_rate)(y)\n",
    "    \n",
    "    # group 4 \n",
    "    y = Conv2D(conv_dim*8, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = Conv2D(conv_dim*8, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = MaxPooling2D(pool_size=(pool_size, 2), strides=(pool_stride, 2), padding='same')(y)\n",
    "    y = Dropout(drop_rate)(y)\n",
    "\n",
    "    # group 5\n",
    "    y = Conv2D(conv_dim*16, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = Conv2D(conv_dim*16, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = MaxPooling2D(pool_size=(pool_size, 2), strides=(1, 2), padding='same')(y)\n",
    "    y = Dropout(drop_rate)(y)\n",
    "\n",
    "    # group 6\n",
    "    y = Conv2D(conv_dim*32, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = Conv2D(conv_dim*32, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = MaxPooling2D(pool_size=(pool_size, 2), strides=(1, 2), padding='same')(y)\n",
    "    y = Dropout(drop_rate)(y)\n",
    "    \n",
    "    # change dimensions: samples, time, frequency, channels => samples, time, frequency*channels\n",
    "    dim_cnn = K.int_shape(y)\n",
    "    y = Reshape((dim_cnn[1], dim_cnn[2]*dim_cnn[3]))(y)\n",
    "\n",
    "    a1 = Dense(hidden_units)(y)\n",
    "    a1 = BatchNormalization()(a1)\n",
    "    a1 = Activation('relu')(a1)\n",
    "    a1 = Dropout(drop_rate)(a1)\n",
    "\n",
    "    a2 = Dense(hidden_units)(a1)\n",
    "    a2 = BatchNormalization()(a2)\n",
    "    a2 = Activation('relu')(a2)\n",
    "    a2 = Dropout(drop_rate)(a2)\n",
    "\n",
    "    a3 = Dense(hidden_units)(a2)\n",
    "    a3 = BatchNormalization()(a3)\n",
    "    a3 = Activation('relu')(a3)\n",
    "    a3 = Dropout(drop_rate)(a3)\n",
    "\n",
    "    # Pooling layers\n",
    "    if model_type == 'decision_level_max_pooling':\n",
    "        '''Global max pooling.\n",
    "\n",
    "        [1] Choi, Keunwoo, et al. \"Automatic tagging using deep convolutional \n",
    "        neural networks.\" arXiv preprint arXiv:1606.00298 (2016).\n",
    "        '''\n",
    "        cla = Dense(classes_num, activation='sigmoid')(a3)\n",
    "        \n",
    "        # output_layer = Lambda(\n",
    "        #    max_pooling, \n",
    "        #    output_shape=pooling_shape)(\n",
    "        #    [cla])\n",
    "        output_layer = Lambda(max_pooling)(cla)\n",
    "\n",
    "    elif model_type == 'decision_level_average_pooling':\n",
    "        '''Global average pooling.\n",
    "\n",
    "        [2] Lin, Min, et al. Qiang Chen, and Shuicheng Yan. \"Network in \n",
    "        network.\" arXiv preprint arXiv:1312.4400 (2013).\n",
    "        '''\n",
    "        cla = Dense(classes_num, activation='sigmoid')(a3)\n",
    "        # output_layer = Lambda(\n",
    "        #    average_pooling,\n",
    "        #    output_shape=pooling_shape)(\n",
    "        #    [cla])\n",
    "        output_layer = Lambda(average_pooling)(cla)\n",
    "\n",
    "    elif model_type == 'decision_level_single_attention':\n",
    "        '''Decision level single attention pooling.\n",
    "        [3] Kong, Qiuqiang, et al. \"Audio Set classification with attention\n",
    "        model: A probabilistic perspective.\" arXiv preprint arXiv:1711.00927\n",
    "        (2017).\n",
    "        '''\n",
    "        cla = Dense(classes_num, activation='sigmoid')(a3)\n",
    "        att = Dense(classes_num, activation='softmax')(a3)\n",
    "        output_layer = Lambda(\n",
    "            attention_pooling, output_shape=pooling_shape)([cla, att])\n",
    "\n",
    "    elif model_type == 'decision_level_multi_attention':\n",
    "        '''Decision level multi attention pooling.\n",
    "        [4] Yu, Changsong, et al. \"Multi-level Attention Model for Weakly\n",
    "        Supervised Audio Classification.\" arXiv preprint arXiv:1803.02353\n",
    "        (2018).\n",
    "        '''\n",
    "        cla1 = Dense(classes_num, activation='sigmoid')(a2)\n",
    "        att1 = Dense(classes_num, activation='softmax')(a2)\n",
    "        out1 = Lambda(\n",
    "            attention_pooling, output_shape=pooling_shape)([cla1, att1])\n",
    "\n",
    "        cla2 = Dense(classes_num, activation='sigmoid')(a3)\n",
    "        att2 = Dense(classes_num, activation='softmax')(a3)\n",
    "        out2 = Lambda(\n",
    "            attention_pooling, output_shape=pooling_shape)([cla2, att2])\n",
    "\n",
    "        b1 = Concatenate(axis=-1)([out1, out2])\n",
    "        b1 = Dense(classes_num)(b1)\n",
    "        \n",
    "        if multilabel:\n",
    "            output_layer = Activation('sigmoid')(b1)\n",
    "        else:\n",
    "            output_layer = Activation('softmax')(b1)\n",
    "\n",
    "    elif model_type == 'feature_level_attention':\n",
    "        '''Feature level attention.\n",
    "        [1] Kong, Qiuqiang, et al. \"Weakly labelled audioset tagging with \n",
    "        attention neural networks.\" (2019).\n",
    "        '''\n",
    "        cla = Dense(hidden_units, activation='linear')(a3)\n",
    "        att = Dense(hidden_units, activation='sigmoid')(a3)\n",
    "        b1 = Lambda(\n",
    "            attention_pooling, output_shape=pooling_shape)([cla, att])\n",
    "\n",
    "        b1 = BatchNormalization()(b1)\n",
    "        b1 = Activation(activation='relu')(b1)\n",
    "        b1 = Dropout(drop_rate)(b1)\n",
    "        \n",
    "        if multilabel:\n",
    "            output_layer = Dense(classes_num, activation='sigmoid')(b1)\n",
    "        else:\n",
    "            output_layer = Dense(classes_num, activation='softmax')(b1)\n",
    "\n",
    "    else:\n",
    "        raise Exception(\"Incorrect model_type!\")\n",
    "\n",
    "    # Build model\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model compile, class weight & fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_best_model(model_folder, remove_others=False):\n",
    "#     model_list = glob.glob(model_folder+'/*.hdf5')\n",
    "#     model_list.sort()\n",
    "#     the_best_model = model_list[-1]\n",
    "    \n",
    "#     if remove_others==True:\n",
    "#         for mm in model_list[:-1]:\n",
    "#             os.remove(mm)\n",
    "            \n",
    "#     print(the_best_model)\n",
    "    \n",
    "#     return the_best_model\n",
    "import re\n",
    "\n",
    "def find_best_model(classifier_path, fmt='epoch_\\d+_valloss_(\\d+.\\d{4})_valacc_(\\d+.\\d{4}).hdf5', is_max=True, purge=True):\n",
    "    \"\"\"\n",
    "    Return the path to the model with the best accuracy, given the path to\n",
    "    all the trained classifiers\n",
    "    Args:\n",
    "        classifier_path: path to all the trained classifiers\n",
    "        fmt: e.g. \"epoch_\\d+_[0-1].\\d+_(\\d+.\\d{4}).hdf5\"\n",
    "        'epoch_\\d+_valloss_(\\d+.\\d{4})_valacc_\\d+.\\d{4}.hdf5'\n",
    "        is_max: use max; otherwise, min\n",
    "        purge: True to purge models files except the best one\n",
    "    Return:\n",
    "        the path of the model with the best accuracy\n",
    "    \"\"\"\n",
    "    # list all files ending with .hdf5\n",
    "    day_list = sorted(glob.glob(os.path.join(classifier_path + '/', '*.hdf5')))\n",
    "\n",
    "    # re the last 4 digits for accuracy\n",
    "    hdf5_filename = []\n",
    "    hdf5_accu = np.zeros(len(day_list))\n",
    "    for dd in range(len(day_list)):\n",
    "        filename = os.path.basename(day_list[dd])\n",
    "        hdf5_filename.append(filename)\n",
    "        # m = re.search(\"_F1_(0.\\d{4}).hdf5\", filename)\n",
    "        # m = re.search(\"_([0-1].\\d{4}).hdf5\", filename)\n",
    "        # m = re.search(\"epoch_\\d+_[0-1].\\d+_(\\d+.\\d{4}).hdf5\", filename)\n",
    "        m = re.search(fmt, filename)\n",
    "        try:\n",
    "            #  hdf5_accu[dd] = float(m.groups()[0])\n",
    "            hdf5_accu[dd] = float(m.groups()[1])\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    # select the laregest one and write to the variable classifier_file\n",
    "    if len(hdf5_accu) == 0:\n",
    "        best_model_path = ''\n",
    "        best_accu = 0\n",
    "    else:\n",
    "        if is_max is True:\n",
    "            ind_max = np.argmax(hdf5_accu)\n",
    "        else: # use min instead\n",
    "            ind_max = np.argmin(hdf5_accu)\n",
    "        best_model_path = day_list[int(ind_max)]\n",
    "        best_accu = hdf5_accu[ind_max]\n",
    "        # purge all model files except the best_model\n",
    "        if purge:\n",
    "            for ff in day_list:\n",
    "                if ff != best_model_path:\n",
    "                    os.remove(ff)\n",
    "    print('Best model:'+str(best_accu))\n",
    "    print(best_model_path)\n",
    "    return best_model_path, best_accu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### cnn4 + attention\n",
    "# model = model_cnn_attention(dim_time, dim_freq, num_species, model_type='decision_level_max_pooling', conv_dim=conv_dim, l2_regu=l2_regu, drop_rate=drop_rate)\n",
    "# model = model_cnn_attention(dim_time, dim_freq, num_species, model_type='decision_level_multi_attention', conv_dim=conv_dim, l2_regu=l2_regu, drop_rate=drop_rate)\n",
    "# model = model_cnn_attention(dim_time, dim_freq, num_species, model_type='feature_level_attention', conv_dim=conv_dim, l2_regu=l2_regu, drop_rate=drop_rate)\n",
    "\n",
    "# vggish\n",
    "# model = model_vggish(dim_time, dim_freq, num_species, conv_dim=conv_dim, fcn_dim=fcn_dim)\n",
    "\n",
    "# cnn10\n",
    "# model = model_cnn10(dim_time, dim_freq, num_species, conv_dim=conv_dim, fcn_dim=fcn_dim, l2_regu=l2_regu, drop_rate=drop_rate)\n",
    "\n",
    "# cnn14\n",
    "# model = model_cnn14(dim_time, dim_freq, num_species, conv_dim=conv_dim, fcn_dim=fcn_dim, l2_regu=l2_regu, drop_rate=drop_rate)\n",
    "\n",
    "# cnn14 attention\n",
    "# model = model_cnn14_attention(dim_time, dim_freq, num_species, model_type='feature_level_attention', conv_dim=conv_dim, pool_size=pool_size, pool_stride=pool_stride, hidden_units=hidden_units, l2_regu=l2_regu, drop_rate=drop_rate)\n",
    "# model = model_cnn14_bigru_attention(dim_time, dim_freq, num_species, model_type='feature_level_attention', conv_dim=conv_dim, rnn_dim=rnn_dim, hidden_units=hidden_units, l2_regu=l2_regu, drop_rate=drop_rate)\n",
    "\n",
    "# model = model_cnn14_attention_multi(dim_time, dim_freq, num_species, model_type='feature_level_attention', conv_dim=conv_dim, pool_size=pool_size, pool_stride=pool_stride, hidden_units=hidden_units, l2_regu=l2_regu, drop_rate=drop_rate)\n",
    "# model = model_cnn14_spp(dim_time, dim_freq, num_species, conv_dim=conv_dim, pool_size=pool_size, pool_stride=pool_stride, hidden_units=hidden_units, l2_regu=l2_regu, drop_rate=drop_rate)\n",
    "# loss = CategoricalCrossentropy()\n",
    "# model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss=loss, metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boundaries = [20, 40, 60, 80]\n",
    "boundaries = [100, 200, 300, 400]\n",
    "values = [1.0e-3, 3.33e-4, 1.0e-4, 3.33e-5, 1.0e-5]\n",
    "learning_rate_fn = PiecewiseConstantDecay(boundaries, values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.now()\n",
    "# create a folder based on date & time\n",
    "fit_result_path1 = os.path.join(fit_result_path, today.strftime('%Y%m%d_%H%M%S'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STAR2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STAR2000\n"
     ]
    }
   ],
   "source": [
    "ee = deployment[0]\n",
    "print(ee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "fea_temp = np.load(os.path.join(feature_path, 'train_oswald_no_'+ee+'.npz'))\n",
    "fea_train = fea_temp['fea_train']\n",
    "label_train_list = fea_temp['label_train']\n",
    "del fea_temp\n",
    "\n",
    "fea_train = fea_train[:,:100,:]\n",
    "label_train = np.zeros(len(label_train_list))\n",
    "for ii in range(len(label_train_list)):\n",
    "    label_train[ii] = species_dict[label_train_list[ii]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing data\n",
    "fea_temp = np.load(os.path.join(feature_path, 'oswald_'+ee+'_orig.npz'))\n",
    "fea_test = fea_temp['feas_orig']\n",
    "label_test_list = fea_temp['labels_orig']\n",
    "\n",
    "fea_test = fea_test[:,:100,:]\n",
    "label_test = np.zeros(len(label_test_list))\n",
    "for ii in range(len(label_test_list)):\n",
    "    label_test[ii] = species_dict[label_test_list[ii]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'BD': 10740,\n",
       "         'CD': 4656,\n",
       "         'FKW': 19080,\n",
       "         'SPIN': 3264,\n",
       "         'SPT': 8556,\n",
       "         'STR': 8352,\n",
       "         'PLT': 11856,\n",
       "         'RT': 7410})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(label_train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0.0: 121, 1.0: 3964, 5.0: 31, 6.0: 76, 4.0: 491, 3.0: 845, 2.0: 1140})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(label_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_result_path2 = os.path.join(fit_result_path1, ee)\n",
    "if not os.path.exists(fit_result_path2):\n",
    "    makedirs(fit_result_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature train shape: (73914, 100, 128)\n",
      "feature test shape: (6668, 100, 128)\n",
      "label train shape: (73914,)\n",
      "label test shape: (6668,)\n",
      "dim_time: 100\n",
      "dim_freq: 128\n"
     ]
    }
   ],
   "source": [
    "print('feature train shape: '+str(fea_train.shape))\n",
    "print('feature test shape: '+str(fea_test.shape))\n",
    "print('label train shape: '+str(label_train.shape))\n",
    "print('label test shape: '+str(label_test.shape))\n",
    "\n",
    "dim_time = fea_train.shape[1]\n",
    "dim_freq = fea_train.shape[2]\n",
    "print('dim_time: '+str(dim_time))\n",
    "print('dim_freq: '+str(dim_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle features & labels\n",
    "fea_train, label_train = shuffle(fea_train, label_train, random_state=0)\n",
    "fea_test, label_test = shuffle(fea_test, label_test, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class weight\n",
    "weights = compute_class_weight(class_weight='balanced', classes=np.unique(label_train), y=label_train)\n",
    "\n",
    "class_weights = dict()\n",
    "for ii in range(num_species):\n",
    "    class_weights[ii] = weights[ii]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_train = np.expand_dims(fea_train, axis=3)\n",
    "fea_test = np.expand_dims(fea_test, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_train, fea_validate, label_train, label_validate = train_test_split(fea_train, label_train, test_size=0.10, random_state=42+4)\n",
    "\n",
    "train_generator = DataGenerator(fea_train, label_train, batch_size=batch_size, num_classes=num_species)\n",
    "del fea_train\n",
    "validate_generator = DataGenerator(fea_validate, label_validate, batch_size=batch_size, num_classes=num_species)\n",
    "del fea_validate\n",
    "\n",
    "# test_generator = DataGenerator(fea_test, label_test, batch_size=batch_size, num_classes=num_species)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 100, 128, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 100, 128, 16)      160       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 100, 128, 16)      64        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 100, 128, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 100, 128, 16)      2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 100, 128, 16)      64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 100, 128, 16)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 50, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 50, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 50, 64, 32)        4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 50, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 50, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 50, 64, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 50, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 50, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 25, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 25, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 25, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 25, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 25, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 25, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 25, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 25, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 13, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 13, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 13, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 13, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 13, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 13, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 13, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 7, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 7, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 7, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 7, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 7, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 7, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 7, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "spatial_pyramid_pooling2d (S (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               1376512   \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 2056      \n",
      "=================================================================\n",
      "Total params: 2,695,672\n",
      "Trainable params: 2,692,152\n",
      "Non-trainable params: 3,520\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.7660 - accuracy: 0.1259\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.14922, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2000/epoch_01_valloss_0.5011_valacc_0.1492.hdf5\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.7659 - accuracy: 0.1259 - val_loss: 0.5011 - val_accuracy: 0.1492\n",
      "Epoch 2/200\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 0.5030 - accuracy: 0.1242\n",
      "Epoch 00002: val_accuracy improved from 0.14922 to 0.15057, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2000/epoch_02_valloss_0.4430_valacc_0.1506.hdf5\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.5030 - accuracy: 0.1242 - val_loss: 0.4430 - val_accuracy: 0.1506\n",
      "Epoch 3/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.4640 - accuracy: 0.1353\n",
      "Epoch 00003: val_accuracy did not improve from 0.15057\n",
      "4157/4157 [==============================] - 71s 17ms/step - loss: 0.4640 - accuracy: 0.1353 - val_loss: 0.4322 - val_accuracy: 0.1284\n",
      "Epoch 4/200\n",
      "4154/4157 [============================>.] - ETA: 0s - loss: 0.4459 - accuracy: 0.1599\n",
      "Epoch 00004: val_accuracy did not improve from 0.15057\n",
      "4157/4157 [==============================] - 71s 17ms/step - loss: 0.4459 - accuracy: 0.1600 - val_loss: 0.4275 - val_accuracy: 0.1149\n",
      "Epoch 5/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.4309 - accuracy: 0.1931\n",
      "Epoch 00005: val_accuracy did not improve from 0.15057\n",
      "4157/4157 [==============================] - 71s 17ms/step - loss: 0.4309 - accuracy: 0.1931 - val_loss: 0.4310 - val_accuracy: 0.1098\n",
      "Epoch 6/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.4182 - accuracy: 0.2197\n",
      "Epoch 00006: val_accuracy did not improve from 0.15057\n",
      "4157/4157 [==============================] - 71s 17ms/step - loss: 0.4182 - accuracy: 0.2197 - val_loss: 0.4709 - val_accuracy: 0.1116\n",
      "Epoch 7/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.4035 - accuracy: 0.2614\n",
      "Epoch 00007: val_accuracy improved from 0.15057 to 0.18764, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2000/epoch_07_valloss_0.4223_valacc_0.1876.hdf5\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.4035 - accuracy: 0.2614 - val_loss: 0.4223 - val_accuracy: 0.1876\n",
      "Epoch 8/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.3880 - accuracy: 0.3015\n",
      "Epoch 00008: val_accuracy improved from 0.18764 to 0.26028, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2000/epoch_08_valloss_0.4050_valacc_0.2603.hdf5\n",
      "4157/4157 [==============================] - 71s 17ms/step - loss: 0.3881 - accuracy: 0.3014 - val_loss: 0.4050 - val_accuracy: 0.2603\n",
      "Epoch 9/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.3727 - accuracy: 0.3451\n",
      "Epoch 00009: val_accuracy did not improve from 0.26028\n",
      "4157/4157 [==============================] - 71s 17ms/step - loss: 0.3727 - accuracy: 0.3451 - val_loss: 0.4210 - val_accuracy: 0.2340\n",
      "Epoch 10/200\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 0.3610 - accuracy: 0.3772\n",
      "Epoch 00010: val_accuracy improved from 0.26028 to 0.35173, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2000/epoch_10_valloss_0.3670_valacc_0.3517.hdf5\n",
      "4157/4157 [==============================] - 71s 17ms/step - loss: 0.3610 - accuracy: 0.3772 - val_loss: 0.3670 - val_accuracy: 0.3517\n",
      "Epoch 11/200\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 0.3498 - accuracy: 0.4026\n",
      "Epoch 00011: val_accuracy did not improve from 0.35173\n",
      "4157/4157 [==============================] - 71s 17ms/step - loss: 0.3498 - accuracy: 0.4026 - val_loss: 0.3675 - val_accuracy: 0.3367\n",
      "Epoch 12/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.3419 - accuracy: 0.4207\n",
      "Epoch 00012: val_accuracy improved from 0.35173 to 0.42154, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2000/epoch_12_valloss_0.3341_valacc_0.4215.hdf5\n",
      "4157/4157 [==============================] - 71s 17ms/step - loss: 0.3419 - accuracy: 0.4207 - val_loss: 0.3341 - val_accuracy: 0.4215\n",
      "Epoch 13/200\n",
      "4154/4157 [============================>.] - ETA: 0s - loss: 0.3332 - accuracy: 0.4386\n",
      "Epoch 00013: val_accuracy did not improve from 0.42154\n",
      "4157/4157 [==============================] - 71s 17ms/step - loss: 0.3333 - accuracy: 0.4386 - val_loss: 0.3426 - val_accuracy: 0.4038\n",
      "Epoch 14/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.3277 - accuracy: 0.4518\n",
      "Epoch 00014: val_accuracy did not improve from 0.42154\n",
      "4157/4157 [==============================] - 71s 17ms/step - loss: 0.3277 - accuracy: 0.4519 - val_loss: 0.3296 - val_accuracy: 0.4092\n",
      "Epoch 15/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.3220 - accuracy: 0.4623\n",
      "Epoch 00015: val_accuracy improved from 0.42154 to 0.47606, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2000/epoch_15_valloss_0.3031_valacc_0.4761.hdf5\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.3220 - accuracy: 0.4624 - val_loss: 0.3031 - val_accuracy: 0.4761\n",
      "Epoch 16/200\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 0.3158 - accuracy: 0.4787\n",
      "Epoch 00016: val_accuracy improved from 0.47606 to 0.48931, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2000/epoch_16_valloss_0.3004_valacc_0.4893.hdf5\n",
      "4157/4157 [==============================] - 71s 17ms/step - loss: 0.3158 - accuracy: 0.4787 - val_loss: 0.3004 - val_accuracy: 0.4893\n",
      "Epoch 17/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.3107 - accuracy: 0.4911\n",
      "Epoch 00017: val_accuracy improved from 0.48931 to 0.50785, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2000/epoch_17_valloss_0.2875_valacc_0.5078.hdf5\n",
      "4157/4157 [==============================] - 71s 17ms/step - loss: 0.3107 - accuracy: 0.4911 - val_loss: 0.2875 - val_accuracy: 0.5078\n",
      "Epoch 18/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.3063 - accuracy: 0.5029\n",
      "Epoch 00018: val_accuracy did not improve from 0.50785\n",
      "4157/4157 [==============================] - 71s 17ms/step - loss: 0.3063 - accuracy: 0.5029 - val_loss: 0.2978 - val_accuracy: 0.4801\n",
      "Epoch 19/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.3026 - accuracy: 0.5112\n",
      "Epoch 00019: val_accuracy improved from 0.50785 to 0.52394, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2000/epoch_19_valloss_0.2795_valacc_0.5239.hdf5\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.3026 - accuracy: 0.5112 - val_loss: 0.2795 - val_accuracy: 0.5239\n",
      "Epoch 20/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.2983 - accuracy: 0.5184\n",
      "Epoch 00020: val_accuracy improved from 0.52394 to 0.55519, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2000/epoch_20_valloss_0.2680_valacc_0.5552.hdf5\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2983 - accuracy: 0.5184 - val_loss: 0.2680 - val_accuracy: 0.5552\n",
      "Epoch 21/200\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 0.2956 - accuracy: 0.5268\n",
      "Epoch 00021: val_accuracy did not improve from 0.55519\n",
      "4157/4157 [==============================] - 71s 17ms/step - loss: 0.2956 - accuracy: 0.5268 - val_loss: 0.2698 - val_accuracy: 0.5528\n",
      "Epoch 22/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.2922 - accuracy: 0.5311\n",
      "Epoch 00022: val_accuracy did not improve from 0.55519\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2923 - accuracy: 0.5311 - val_loss: 0.2698 - val_accuracy: 0.5488\n",
      "Epoch 23/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.2882 - accuracy: 0.5420\n",
      "Epoch 00023: val_accuracy did not improve from 0.55519\n",
      "4157/4157 [==============================] - 71s 17ms/step - loss: 0.2882 - accuracy: 0.5420 - val_loss: 0.2702 - val_accuracy: 0.5541\n",
      "Epoch 24/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.2851 - accuracy: 0.5485\n",
      "Epoch 00024: val_accuracy did not improve from 0.55519\n",
      "4157/4157 [==============================] - 71s 17ms/step - loss: 0.2850 - accuracy: 0.5485 - val_loss: 0.2880 - val_accuracy: 0.5188\n",
      "Epoch 25/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.2824 - accuracy: 0.5541\n",
      "Epoch 00025: val_accuracy improved from 0.55519 to 0.61607, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2000/epoch_25_valloss_0.2434_valacc_0.6161.hdf5\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2824 - accuracy: 0.5541 - val_loss: 0.2434 - val_accuracy: 0.6161\n",
      "Epoch 26/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.2791 - accuracy: 0.5620\n",
      "Epoch 00026: val_accuracy did not improve from 0.61607\n",
      "4157/4157 [==============================] - 71s 17ms/step - loss: 0.2791 - accuracy: 0.5620 - val_loss: 0.2866 - val_accuracy: 0.5126\n",
      "Epoch 27/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.2780 - accuracy: 0.5672\n",
      "Epoch 00027: val_accuracy did not improve from 0.61607\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2780 - accuracy: 0.5672 - val_loss: 0.2466 - val_accuracy: 0.6092\n",
      "Epoch 28/200\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 0.2747 - accuracy: 0.5724\n",
      "Epoch 00028: val_accuracy did not improve from 0.61607\n",
      "4157/4157 [==============================] - 71s 17ms/step - loss: 0.2747 - accuracy: 0.5724 - val_loss: 0.2469 - val_accuracy: 0.5996\n",
      "Epoch 29/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.2728 - accuracy: 0.5743\n",
      "Epoch 00029: val_accuracy did not improve from 0.61607\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2729 - accuracy: 0.5742 - val_loss: 0.2546 - val_accuracy: 0.5837\n",
      "Epoch 30/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.2708 - accuracy: 0.5825\n",
      "Epoch 00030: val_accuracy did not improve from 0.61607\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2708 - accuracy: 0.5825 - val_loss: 0.2425 - val_accuracy: 0.6084\n",
      "Epoch 31/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.2676 - accuracy: 0.5869\n",
      "Epoch 00031: val_accuracy did not improve from 0.61607\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2675 - accuracy: 0.5870 - val_loss: 0.2561 - val_accuracy: 0.5798\n",
      "Epoch 32/200\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 0.2659 - accuracy: 0.5905\n",
      "Epoch 00032: val_accuracy improved from 0.61607 to 0.61742, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2000/epoch_32_valloss_0.2382_valacc_0.6174.hdf5\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2659 - accuracy: 0.5905 - val_loss: 0.2382 - val_accuracy: 0.6174\n",
      "Epoch 33/200\n",
      "4154/4157 [============================>.] - ETA: 0s - loss: 0.2644 - accuracy: 0.5936\n",
      "Epoch 00033: val_accuracy did not improve from 0.61742\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2643 - accuracy: 0.5937 - val_loss: 0.2707 - val_accuracy: 0.5679\n",
      "Epoch 34/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.2618 - accuracy: 0.5987\n",
      "Epoch 00034: val_accuracy did not improve from 0.61742\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2618 - accuracy: 0.5987 - val_loss: 0.2550 - val_accuracy: 0.5901\n",
      "Epoch 35/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.2596 - accuracy: 0.6045\n",
      "Epoch 00035: val_accuracy did not improve from 0.61742\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2596 - accuracy: 0.6046 - val_loss: 0.2416 - val_accuracy: 0.6089\n",
      "Epoch 36/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.2578 - accuracy: 0.6071\n",
      "Epoch 00036: val_accuracy improved from 0.61742 to 0.63406, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2000/epoch_36_valloss_0.2342_valacc_0.6341.hdf5\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2578 - accuracy: 0.6071 - val_loss: 0.2342 - val_accuracy: 0.6341\n",
      "Epoch 37/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.2568 - accuracy: 0.6099\n",
      "Epoch 00037: val_accuracy did not improve from 0.63406\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2568 - accuracy: 0.6099 - val_loss: 0.2386 - val_accuracy: 0.6258\n",
      "Epoch 38/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.2550 - accuracy: 0.6137\n",
      "Epoch 00038: val_accuracy did not improve from 0.63406\n",
      "4157/4157 [==============================] - 71s 17ms/step - loss: 0.2550 - accuracy: 0.6138 - val_loss: 0.2639 - val_accuracy: 0.5682\n",
      "Epoch 39/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.2540 - accuracy: 0.6164\n",
      "Epoch 00039: val_accuracy improved from 0.63406 to 0.63785, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2000/epoch_39_valloss_0.2317_valacc_0.6379.hdf5\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2540 - accuracy: 0.6164 - val_loss: 0.2317 - val_accuracy: 0.6379\n",
      "Epoch 40/200\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 0.2535 - accuracy: 0.6173\n",
      "Epoch 00040: val_accuracy did not improve from 0.63785\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2535 - accuracy: 0.6173 - val_loss: 0.2489 - val_accuracy: 0.6032\n",
      "Epoch 41/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.2502 - accuracy: 0.6214\n",
      "Epoch 00041: val_accuracy did not improve from 0.63785\n",
      "4157/4157 [==============================] - 71s 17ms/step - loss: 0.2502 - accuracy: 0.6214 - val_loss: 0.2462 - val_accuracy: 0.6097\n",
      "Epoch 42/200\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 0.2496 - accuracy: 0.6263\n",
      "Epoch 00042: val_accuracy improved from 0.63785 to 0.64556, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2000/epoch_42_valloss_0.2266_valacc_0.6456.hdf5\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2496 - accuracy: 0.6263 - val_loss: 0.2266 - val_accuracy: 0.6456\n",
      "Epoch 43/200\n",
      "4154/4157 [============================>.] - ETA: 0s - loss: 0.2481 - accuracy: 0.6285\n",
      "Epoch 00043: val_accuracy did not improve from 0.64556\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2481 - accuracy: 0.6285 - val_loss: 0.2316 - val_accuracy: 0.6319\n",
      "Epoch 44/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.2464 - accuracy: 0.6327\n",
      "Epoch 00044: val_accuracy improved from 0.64556 to 0.65463, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2000/epoch_44_valloss_0.2221_valacc_0.6546.hdf5\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2464 - accuracy: 0.6327 - val_loss: 0.2221 - val_accuracy: 0.6546\n",
      "Epoch 45/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.2454 - accuracy: 0.6316\n",
      "Epoch 00045: val_accuracy did not improve from 0.65463\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2454 - accuracy: 0.6316 - val_loss: 0.2296 - val_accuracy: 0.6437\n",
      "Epoch 46/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.2442 - accuracy: 0.6370\n",
      "Epoch 00046: val_accuracy improved from 0.65463 to 0.66180, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2000/epoch_46_valloss_0.2225_valacc_0.6618.hdf5\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2442 - accuracy: 0.6370 - val_loss: 0.2225 - val_accuracy: 0.6618\n",
      "Epoch 47/200\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 0.2435 - accuracy: 0.6382\n",
      "Epoch 00047: val_accuracy did not improve from 0.66180\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2435 - accuracy: 0.6382 - val_loss: 0.2385 - val_accuracy: 0.6388\n",
      "Epoch 48/200\n",
      "4154/4157 [============================>.] - ETA: 0s - loss: 0.2423 - accuracy: 0.6411\n",
      "Epoch 00048: val_accuracy did not improve from 0.66180\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2423 - accuracy: 0.6412 - val_loss: 0.2271 - val_accuracy: 0.6488\n",
      "Epoch 49/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.2412 - accuracy: 0.6440\n",
      "Epoch 00049: val_accuracy did not improve from 0.66180\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2411 - accuracy: 0.6440 - val_loss: 0.2293 - val_accuracy: 0.6437\n",
      "Epoch 50/200\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 0.2404 - accuracy: 0.6481\n",
      "Epoch 00050: val_accuracy did not improve from 0.66180\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2404 - accuracy: 0.6481 - val_loss: 0.2297 - val_accuracy: 0.6496\n",
      "Epoch 51/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.2392 - accuracy: 0.6465\n",
      "Epoch 00051: val_accuracy did not improve from 0.66180\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2392 - accuracy: 0.6465 - val_loss: 0.2300 - val_accuracy: 0.6460\n",
      "Epoch 52/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.2368 - accuracy: 0.6527\n",
      "Epoch 00052: val_accuracy did not improve from 0.66180\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2368 - accuracy: 0.6527 - val_loss: 0.2284 - val_accuracy: 0.6546\n",
      "Epoch 53/200\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 0.2369 - accuracy: 0.6530\n",
      "Epoch 00053: val_accuracy did not improve from 0.66180\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2369 - accuracy: 0.6530 - val_loss: 0.2362 - val_accuracy: 0.6364\n",
      "Epoch 54/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.2364 - accuracy: 0.6553\n",
      "Epoch 00054: val_accuracy improved from 0.66180 to 0.66342, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2000/epoch_54_valloss_0.2248_valacc_0.6634.hdf5\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2364 - accuracy: 0.6553 - val_loss: 0.2248 - val_accuracy: 0.6634\n",
      "Epoch 55/200\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 0.2354 - accuracy: 0.6564\n",
      "Epoch 00055: val_accuracy improved from 0.66342 to 0.66775, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2000/epoch_55_valloss_0.2192_valacc_0.6677.hdf5\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2354 - accuracy: 0.6564 - val_loss: 0.2192 - val_accuracy: 0.6677\n",
      "Epoch 56/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.2335 - accuracy: 0.6597\n",
      "Epoch 00056: val_accuracy did not improve from 0.66775\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2335 - accuracy: 0.6597 - val_loss: 0.2275 - val_accuracy: 0.6598\n",
      "Epoch 57/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.2328 - accuracy: 0.6620\n",
      "Epoch 00057: val_accuracy did not improve from 0.66775\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2328 - accuracy: 0.6620 - val_loss: 0.2205 - val_accuracy: 0.6652\n",
      "Epoch 58/200\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 0.2324 - accuracy: 0.6621\n",
      "Epoch 00058: val_accuracy did not improve from 0.66775\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2324 - accuracy: 0.6621 - val_loss: 0.2247 - val_accuracy: 0.6575\n",
      "Epoch 59/200\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 0.2318 - accuracy: 0.6651\n",
      "Epoch 00059: val_accuracy did not improve from 0.66775\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2318 - accuracy: 0.6651 - val_loss: 0.2408 - val_accuracy: 0.6277\n",
      "Epoch 60/200\n",
      "4154/4157 [============================>.] - ETA: 0s - loss: 0.2306 - accuracy: 0.6667\n",
      "Epoch 00060: val_accuracy did not improve from 0.66775\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2306 - accuracy: 0.6667 - val_loss: 0.2238 - val_accuracy: 0.6656\n",
      "Epoch 61/200\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 0.2296 - accuracy: 0.6691\n",
      "Epoch 00061: val_accuracy improved from 0.66775 to 0.68980, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2000/epoch_61_valloss_0.2102_valacc_0.6898.hdf5\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2296 - accuracy: 0.6691 - val_loss: 0.2102 - val_accuracy: 0.6898\n",
      "Epoch 62/200\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 0.2283 - accuracy: 0.6703\n",
      "Epoch 00062: val_accuracy did not improve from 0.68980\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2283 - accuracy: 0.6703 - val_loss: 0.2099 - val_accuracy: 0.6880\n",
      "Epoch 63/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.2279 - accuracy: 0.6739\n",
      "Epoch 00063: val_accuracy did not improve from 0.68980\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2279 - accuracy: 0.6739 - val_loss: 0.2131 - val_accuracy: 0.6852\n",
      "Epoch 64/200\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 0.2267 - accuracy: 0.6739\n",
      "Epoch 00064: val_accuracy did not improve from 0.68980\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2267 - accuracy: 0.6739 - val_loss: 0.2337 - val_accuracy: 0.6568\n",
      "Epoch 65/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.2260 - accuracy: 0.6741\n",
      "Epoch 00065: val_accuracy did not improve from 0.68980\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2260 - accuracy: 0.6741 - val_loss: 0.2188 - val_accuracy: 0.6749\n",
      "Epoch 66/200\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 0.2238 - accuracy: 0.6797\n",
      "Epoch 00066: val_accuracy improved from 0.68980 to 0.69616, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2000/epoch_66_valloss_0.2052_valacc_0.6962.hdf5\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2238 - accuracy: 0.6797 - val_loss: 0.2052 - val_accuracy: 0.6962\n",
      "Epoch 67/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.2247 - accuracy: 0.6794\n",
      "Epoch 00067: val_accuracy did not improve from 0.69616\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2247 - accuracy: 0.6794 - val_loss: 0.2155 - val_accuracy: 0.6855\n",
      "Epoch 68/200\n",
      "4154/4157 [============================>.] - ETA: 0s - loss: 0.2241 - accuracy: 0.6799\n",
      "Epoch 00068: val_accuracy did not improve from 0.69616\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2241 - accuracy: 0.6799 - val_loss: 0.2289 - val_accuracy: 0.6525\n",
      "Epoch 69/200\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 0.2235 - accuracy: 0.6829\n",
      "Epoch 00069: val_accuracy did not improve from 0.69616\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2235 - accuracy: 0.6829 - val_loss: 0.2264 - val_accuracy: 0.6623\n",
      "Epoch 70/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.2224 - accuracy: 0.6835\n",
      "Epoch 00070: val_accuracy did not improve from 0.69616\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2224 - accuracy: 0.6835 - val_loss: 0.2262 - val_accuracy: 0.6623\n",
      "Epoch 71/200\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 0.2221 - accuracy: 0.6864\n",
      "Epoch 00071: val_accuracy did not improve from 0.69616\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2221 - accuracy: 0.6864 - val_loss: 0.2253 - val_accuracy: 0.6613\n",
      "Epoch 72/200\n",
      "4154/4157 [============================>.] - ETA: 0s - loss: 0.2219 - accuracy: 0.6849\n",
      "Epoch 00072: val_accuracy did not improve from 0.69616\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2219 - accuracy: 0.6848 - val_loss: 0.2249 - val_accuracy: 0.6664\n",
      "Epoch 73/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.2213 - accuracy: 0.6870\n",
      "Epoch 00073: val_accuracy did not improve from 0.69616\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2213 - accuracy: 0.6870 - val_loss: 0.2231 - val_accuracy: 0.6660\n",
      "Epoch 74/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.2196 - accuracy: 0.6915\n",
      "Epoch 00074: val_accuracy did not improve from 0.69616\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2196 - accuracy: 0.6915 - val_loss: 0.2299 - val_accuracy: 0.6484\n",
      "Epoch 75/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.2196 - accuracy: 0.6912\n",
      "Epoch 00075: val_accuracy did not improve from 0.69616\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2197 - accuracy: 0.6912 - val_loss: 0.2237 - val_accuracy: 0.6733\n",
      "Epoch 76/200\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 0.2186 - accuracy: 0.6919\n",
      "Epoch 00076: val_accuracy did not improve from 0.69616\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2186 - accuracy: 0.6919 - val_loss: 0.2288 - val_accuracy: 0.6664\n",
      "Epoch 77/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.2185 - accuracy: 0.6919\n",
      "Epoch 00077: val_accuracy did not improve from 0.69616\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2185 - accuracy: 0.6919 - val_loss: 0.2134 - val_accuracy: 0.6949\n",
      "Epoch 78/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.2177 - accuracy: 0.6957\n",
      "Epoch 00078: val_accuracy improved from 0.69616 to 0.70143, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2000/epoch_78_valloss_0.2057_valacc_0.7014.hdf5\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2177 - accuracy: 0.6957 - val_loss: 0.2057 - val_accuracy: 0.7014\n",
      "Epoch 79/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.2177 - accuracy: 0.6947\n",
      "Epoch 00079: val_accuracy did not improve from 0.70143\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2177 - accuracy: 0.6946 - val_loss: 0.2124 - val_accuracy: 0.6926\n",
      "Epoch 80/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.2159 - accuracy: 0.6984\n",
      "Epoch 00080: val_accuracy did not improve from 0.70143\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2159 - accuracy: 0.6984 - val_loss: 0.2163 - val_accuracy: 0.6910\n",
      "Epoch 81/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.2155 - accuracy: 0.6985\n",
      "Epoch 00081: val_accuracy did not improve from 0.70143\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2155 - accuracy: 0.6985 - val_loss: 0.2140 - val_accuracy: 0.6814\n",
      "Epoch 82/200\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 0.2150 - accuracy: 0.7001\n",
      "Epoch 00082: val_accuracy did not improve from 0.70143\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2150 - accuracy: 0.7001 - val_loss: 0.2105 - val_accuracy: 0.6960\n",
      "Epoch 83/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.2144 - accuracy: 0.7035\n",
      "Epoch 00083: val_accuracy did not improve from 0.70143\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2145 - accuracy: 0.7035 - val_loss: 0.2327 - val_accuracy: 0.6519\n",
      "Epoch 84/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.2144 - accuracy: 0.7016\n",
      "Epoch 00084: val_accuracy did not improve from 0.70143\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2145 - accuracy: 0.7015 - val_loss: 0.2366 - val_accuracy: 0.6479\n",
      "Epoch 85/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.2139 - accuracy: 0.7024\n",
      "Epoch 00085: val_accuracy did not improve from 0.70143\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2139 - accuracy: 0.7024 - val_loss: 0.2236 - val_accuracy: 0.6705\n",
      "Epoch 86/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.2134 - accuracy: 0.7050\n",
      "Epoch 00086: val_accuracy did not improve from 0.70143\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2134 - accuracy: 0.7051 - val_loss: 0.2133 - val_accuracy: 0.6987\n",
      "Epoch 87/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.2127 - accuracy: 0.7063\n",
      "Epoch 00087: val_accuracy did not improve from 0.70143\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2128 - accuracy: 0.7063 - val_loss: 0.2132 - val_accuracy: 0.6906\n",
      "Epoch 88/200\n",
      "4154/4157 [============================>.] - ETA: 0s - loss: 0.2122 - accuracy: 0.7062\n",
      "Epoch 00088: val_accuracy did not improve from 0.70143\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2122 - accuracy: 0.7062 - val_loss: 0.2095 - val_accuracy: 0.6966\n",
      "Epoch 89/200\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 0.2113 - accuracy: 0.7086\n",
      "Epoch 00089: val_accuracy did not improve from 0.70143\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2113 - accuracy: 0.7086 - val_loss: 0.2260 - val_accuracy: 0.6665\n",
      "Epoch 90/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.2115 - accuracy: 0.7096\n",
      "Epoch 00090: val_accuracy did not improve from 0.70143\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2115 - accuracy: 0.7095 - val_loss: 0.2129 - val_accuracy: 0.6887\n",
      "Epoch 91/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.2109 - accuracy: 0.7088\n",
      "Epoch 00091: val_accuracy improved from 0.70143 to 0.70509, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2000/epoch_91_valloss_0.2049_valacc_0.7051.hdf5\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2109 - accuracy: 0.7088 - val_loss: 0.2049 - val_accuracy: 0.7051\n",
      "Epoch 92/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.2099 - accuracy: 0.7134\n",
      "Epoch 00092: val_accuracy improved from 0.70509 to 0.71604, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2000/epoch_92_valloss_0.2021_valacc_0.7160.hdf5\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2099 - accuracy: 0.7134 - val_loss: 0.2021 - val_accuracy: 0.7160\n",
      "Epoch 93/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.2104 - accuracy: 0.7096\n",
      "Epoch 00093: val_accuracy did not improve from 0.71604\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2103 - accuracy: 0.7096 - val_loss: 0.2074 - val_accuracy: 0.7059\n",
      "Epoch 94/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.2091 - accuracy: 0.7140\n",
      "Epoch 00094: val_accuracy did not improve from 0.71604\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2091 - accuracy: 0.7140 - val_loss: 0.2065 - val_accuracy: 0.7050\n",
      "Epoch 95/200\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 0.2099 - accuracy: 0.7117\n",
      "Epoch 00095: val_accuracy did not improve from 0.71604\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2099 - accuracy: 0.7117 - val_loss: 0.2351 - val_accuracy: 0.6437\n",
      "Epoch 96/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.2087 - accuracy: 0.7150\n",
      "Epoch 00096: val_accuracy did not improve from 0.71604\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2087 - accuracy: 0.7151 - val_loss: 0.2369 - val_accuracy: 0.6491\n",
      "Epoch 97/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.2087 - accuracy: 0.7135\n",
      "Epoch 00097: val_accuracy did not improve from 0.71604\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2087 - accuracy: 0.7135 - val_loss: 0.2370 - val_accuracy: 0.6483\n",
      "Epoch 98/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.2067 - accuracy: 0.7179\n",
      "Epoch 00098: val_accuracy did not improve from 0.71604\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2067 - accuracy: 0.7179 - val_loss: 0.2216 - val_accuracy: 0.6755\n",
      "Epoch 99/200\n",
      "4154/4157 [============================>.] - ETA: 0s - loss: 0.2073 - accuracy: 0.7168\n",
      "Epoch 00099: val_accuracy did not improve from 0.71604\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2074 - accuracy: 0.7167 - val_loss: 0.2118 - val_accuracy: 0.6963\n",
      "Epoch 100/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.2060 - accuracy: 0.7206\n",
      "Epoch 00100: val_accuracy did not improve from 0.71604\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2060 - accuracy: 0.7206 - val_loss: 0.2012 - val_accuracy: 0.7140\n",
      "Epoch 101/200\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 0.2062 - accuracy: 0.7197\n",
      "Epoch 00101: val_accuracy did not improve from 0.71604\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2062 - accuracy: 0.7197 - val_loss: 0.2148 - val_accuracy: 0.6964\n",
      "Epoch 102/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.2055 - accuracy: 0.7218\n",
      "Epoch 00102: val_accuracy did not improve from 0.71604\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2055 - accuracy: 0.7218 - val_loss: 0.2105 - val_accuracy: 0.7020\n",
      "Epoch 103/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.2044 - accuracy: 0.7252\n",
      "Epoch 00103: val_accuracy did not improve from 0.71604\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2044 - accuracy: 0.7252 - val_loss: 0.2420 - val_accuracy: 0.6376\n",
      "Epoch 104/200\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 0.2048 - accuracy: 0.7233\n",
      "Epoch 00104: val_accuracy did not improve from 0.71604\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2048 - accuracy: 0.7233 - val_loss: 0.2101 - val_accuracy: 0.7005\n",
      "Epoch 105/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.2038 - accuracy: 0.7255\n",
      "Epoch 00105: val_accuracy improved from 0.71604 to 0.72376, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2000/epoch_105_valloss_0.1994_valacc_0.7238.hdf5\n",
      "4157/4157 [==============================] - 73s 17ms/step - loss: 0.2039 - accuracy: 0.7255 - val_loss: 0.1994 - val_accuracy: 0.7238\n",
      "Epoch 106/200\n",
      "4154/4157 [============================>.] - ETA: 0s - loss: 0.2033 - accuracy: 0.7266\n",
      "Epoch 00106: val_accuracy did not improve from 0.72376\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2033 - accuracy: 0.7265 - val_loss: 0.2143 - val_accuracy: 0.7010\n",
      "Epoch 107/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.2031 - accuracy: 0.7271\n",
      "Epoch 00107: val_accuracy did not improve from 0.72376\n",
      "4157/4157 [==============================] - 73s 17ms/step - loss: 0.2032 - accuracy: 0.7271 - val_loss: 0.2227 - val_accuracy: 0.6794\n",
      "Epoch 108/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.2024 - accuracy: 0.7271\n",
      "Epoch 00108: val_accuracy did not improve from 0.72376\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2024 - accuracy: 0.7272 - val_loss: 0.2306 - val_accuracy: 0.6709\n",
      "Epoch 109/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.2037 - accuracy: 0.7260\n",
      "Epoch 00109: val_accuracy did not improve from 0.72376\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2037 - accuracy: 0.7260 - val_loss: 0.2486 - val_accuracy: 0.6419\n",
      "Epoch 110/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.2029 - accuracy: 0.7285\n",
      "Epoch 00110: val_accuracy did not improve from 0.72376\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2030 - accuracy: 0.7284 - val_loss: 0.2393 - val_accuracy: 0.6466\n",
      "Epoch 111/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.2011 - accuracy: 0.7300\n",
      "Epoch 00111: val_accuracy did not improve from 0.72376\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2011 - accuracy: 0.7300 - val_loss: 0.2169 - val_accuracy: 0.6902\n",
      "Epoch 112/200\n",
      "4154/4157 [============================>.] - ETA: 0s - loss: 0.2018 - accuracy: 0.7309\n",
      "Epoch 00112: val_accuracy did not improve from 0.72376\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2018 - accuracy: 0.7310 - val_loss: 0.2164 - val_accuracy: 0.6991\n",
      "Epoch 113/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.1995 - accuracy: 0.7326\n",
      "Epoch 00113: val_accuracy did not improve from 0.72376\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.1995 - accuracy: 0.7326 - val_loss: 0.2282 - val_accuracy: 0.6668\n",
      "Epoch 114/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.2011 - accuracy: 0.7309\n",
      "Epoch 00114: val_accuracy did not improve from 0.72376\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2011 - accuracy: 0.7309 - val_loss: 0.2085 - val_accuracy: 0.7119\n",
      "Epoch 115/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.2004 - accuracy: 0.7314\n",
      "Epoch 00115: val_accuracy did not improve from 0.72376\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.2004 - accuracy: 0.7314 - val_loss: 0.2303 - val_accuracy: 0.6644\n",
      "Epoch 116/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.1997 - accuracy: 0.7370\n",
      "Epoch 00116: val_accuracy did not improve from 0.72376\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.1997 - accuracy: 0.7370 - val_loss: 0.2344 - val_accuracy: 0.6577\n",
      "Epoch 117/200\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 0.1994 - accuracy: 0.7353\n",
      "Epoch 00117: val_accuracy did not improve from 0.72376\n",
      "4157/4157 [==============================] - 73s 17ms/step - loss: 0.1994 - accuracy: 0.7353 - val_loss: 0.2238 - val_accuracy: 0.6782\n",
      "Epoch 118/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.1989 - accuracy: 0.7356\n",
      "Epoch 00118: val_accuracy did not improve from 0.72376\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.1989 - accuracy: 0.7356 - val_loss: 0.2046 - val_accuracy: 0.7186\n",
      "Epoch 119/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.1992 - accuracy: 0.7342\n",
      "Epoch 00119: val_accuracy did not improve from 0.72376\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.1992 - accuracy: 0.7342 - val_loss: 0.2100 - val_accuracy: 0.7109\n",
      "Epoch 120/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.1996 - accuracy: 0.7346\n",
      "Epoch 00120: val_accuracy did not improve from 0.72376\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.1996 - accuracy: 0.7346 - val_loss: 0.2250 - val_accuracy: 0.6810\n",
      "Epoch 121/200\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 0.1981 - accuracy: 0.7374\n",
      "Epoch 00121: val_accuracy did not improve from 0.72376\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.1981 - accuracy: 0.7374 - val_loss: 0.2136 - val_accuracy: 0.6936\n",
      "Epoch 122/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.1978 - accuracy: 0.7390\n",
      "Epoch 00122: val_accuracy did not improve from 0.72376\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.1978 - accuracy: 0.7391 - val_loss: 0.2066 - val_accuracy: 0.7151\n",
      "Epoch 123/200\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 0.1967 - accuracy: 0.7396\n",
      "Epoch 00123: val_accuracy did not improve from 0.72376\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.1967 - accuracy: 0.7396 - val_loss: 0.2239 - val_accuracy: 0.6834\n",
      "Epoch 124/200\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 0.1968 - accuracy: 0.7412\n",
      "Epoch 00124: val_accuracy did not improve from 0.72376\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.1968 - accuracy: 0.7412 - val_loss: 0.2167 - val_accuracy: 0.7012\n",
      "Epoch 125/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.1968 - accuracy: 0.7412\n",
      "Epoch 00125: val_accuracy did not improve from 0.72376\n",
      "4157/4157 [==============================] - 73s 17ms/step - loss: 0.1968 - accuracy: 0.7411 - val_loss: 0.2576 - val_accuracy: 0.6322\n",
      "Epoch 126/200\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 0.1967 - accuracy: 0.7412\n",
      "Epoch 00126: val_accuracy did not improve from 0.72376\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.1967 - accuracy: 0.7412 - val_loss: 0.2183 - val_accuracy: 0.6949\n",
      "Epoch 127/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.1964 - accuracy: 0.7401\n",
      "Epoch 00127: val_accuracy improved from 0.72376 to 0.72578, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2000/epoch_127_valloss_0.2020_valacc_0.7258.hdf5\n",
      "4157/4157 [==============================] - 73s 17ms/step - loss: 0.1964 - accuracy: 0.7402 - val_loss: 0.2020 - val_accuracy: 0.7258\n",
      "Epoch 128/200\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 0.1952 - accuracy: 0.7429\n",
      "Epoch 00128: val_accuracy did not improve from 0.72578\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.1952 - accuracy: 0.7429 - val_loss: 0.2325 - val_accuracy: 0.6851\n",
      "Epoch 129/200\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 0.1946 - accuracy: 0.7454\n",
      "Epoch 00129: val_accuracy did not improve from 0.72578\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.1946 - accuracy: 0.7454 - val_loss: 0.2145 - val_accuracy: 0.7048\n",
      "Epoch 130/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.1958 - accuracy: 0.7431\n",
      "Epoch 00130: val_accuracy did not improve from 0.72578\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.1958 - accuracy: 0.7431 - val_loss: 0.2231 - val_accuracy: 0.6956\n",
      "Epoch 131/200\n",
      "4154/4157 [============================>.] - ETA: 0s - loss: 0.1953 - accuracy: 0.7449\n",
      "Epoch 00131: val_accuracy did not improve from 0.72578\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.1953 - accuracy: 0.7448 - val_loss: 0.2415 - val_accuracy: 0.6550\n",
      "Epoch 132/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.1932 - accuracy: 0.7483\n",
      "Epoch 00132: val_accuracy did not improve from 0.72578\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.1932 - accuracy: 0.7483 - val_loss: 0.2068 - val_accuracy: 0.7167\n",
      "Epoch 133/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.1938 - accuracy: 0.7466\n",
      "Epoch 00133: val_accuracy did not improve from 0.72578\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.1938 - accuracy: 0.7466 - val_loss: 0.2336 - val_accuracy: 0.6709\n",
      "Epoch 134/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.1934 - accuracy: 0.7495\n",
      "Epoch 00134: val_accuracy did not improve from 0.72578\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.1934 - accuracy: 0.7496 - val_loss: 0.2089 - val_accuracy: 0.7202\n",
      "Epoch 135/200\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 0.1936 - accuracy: 0.7490\n",
      "Epoch 00135: val_accuracy did not improve from 0.72578\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.1936 - accuracy: 0.7490 - val_loss: 0.2118 - val_accuracy: 0.7133\n",
      "Epoch 136/200\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 0.1932 - accuracy: 0.7488\n",
      "Epoch 00136: val_accuracy did not improve from 0.72578\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.1932 - accuracy: 0.7488 - val_loss: 0.2361 - val_accuracy: 0.6686\n",
      "Epoch 137/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.1932 - accuracy: 0.7504\n",
      "Epoch 00137: val_accuracy did not improve from 0.72578\n",
      "4157/4157 [==============================] - 73s 18ms/step - loss: 0.1932 - accuracy: 0.7504 - val_loss: 0.2285 - val_accuracy: 0.6784\n",
      "Epoch 138/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.1929 - accuracy: 0.7502\n",
      "Epoch 00138: val_accuracy did not improve from 0.72578\n",
      "4157/4157 [==============================] - 73s 17ms/step - loss: 0.1929 - accuracy: 0.7501 - val_loss: 0.2195 - val_accuracy: 0.6939\n",
      "Epoch 139/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.1927 - accuracy: 0.7507\n",
      "Epoch 00139: val_accuracy did not improve from 0.72578\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.1927 - accuracy: 0.7507 - val_loss: 0.2387 - val_accuracy: 0.6519\n",
      "Epoch 140/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.1915 - accuracy: 0.7531\n",
      "Epoch 00140: val_accuracy did not improve from 0.72578\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.1914 - accuracy: 0.7531 - val_loss: 0.2194 - val_accuracy: 0.6978\n",
      "Epoch 141/200\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 0.1909 - accuracy: 0.7526\n",
      "Epoch 00141: val_accuracy did not improve from 0.72578\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.1909 - accuracy: 0.7526 - val_loss: 0.2570 - val_accuracy: 0.6499\n",
      "Epoch 142/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.1908 - accuracy: 0.7547\n",
      "Epoch 00142: val_accuracy did not improve from 0.72578\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.1908 - accuracy: 0.7547 - val_loss: 0.2286 - val_accuracy: 0.6880\n",
      "Epoch 143/200\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 0.1908 - accuracy: 0.7535\n",
      "Epoch 00143: val_accuracy did not improve from 0.72578\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.1908 - accuracy: 0.7535 - val_loss: 0.2125 - val_accuracy: 0.7075\n",
      "Epoch 144/200\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 0.1905 - accuracy: 0.7572\n",
      "Epoch 00144: val_accuracy did not improve from 0.72578\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.1905 - accuracy: 0.7572 - val_loss: 0.2091 - val_accuracy: 0.7151\n",
      "Epoch 145/200\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 0.1900 - accuracy: 0.7550\n",
      "Epoch 00145: val_accuracy did not improve from 0.72578\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.1900 - accuracy: 0.7550 - val_loss: 0.2179 - val_accuracy: 0.7024\n",
      "Epoch 146/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.1901 - accuracy: 0.7571\n",
      "Epoch 00146: val_accuracy did not improve from 0.72578\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.1901 - accuracy: 0.7571 - val_loss: 0.2393 - val_accuracy: 0.6759\n",
      "Epoch 147/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.1910 - accuracy: 0.7551\n",
      "Epoch 00147: val_accuracy did not improve from 0.72578\n",
      "4157/4157 [==============================] - 73s 17ms/step - loss: 0.1910 - accuracy: 0.7551 - val_loss: 0.2203 - val_accuracy: 0.7041\n",
      "Epoch 148/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.1899 - accuracy: 0.7574\n",
      "Epoch 00148: val_accuracy did not improve from 0.72578\n",
      "4157/4157 [==============================] - 73s 17ms/step - loss: 0.1898 - accuracy: 0.7575 - val_loss: 0.2199 - val_accuracy: 0.6978\n",
      "Epoch 149/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.1878 - accuracy: 0.7607\n",
      "Epoch 00149: val_accuracy did not improve from 0.72578\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.1879 - accuracy: 0.7607 - val_loss: 0.2216 - val_accuracy: 0.6952\n",
      "Epoch 150/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.1894 - accuracy: 0.7575\n",
      "Epoch 00150: val_accuracy did not improve from 0.72578\n",
      "4157/4157 [==============================] - 73s 17ms/step - loss: 0.1894 - accuracy: 0.7576 - val_loss: 0.2190 - val_accuracy: 0.7002\n",
      "Epoch 151/200\n",
      "4154/4157 [============================>.] - ETA: 0s - loss: 0.1894 - accuracy: 0.7588\n",
      "Epoch 00151: val_accuracy did not improve from 0.72578\n",
      "4157/4157 [==============================] - 73s 17ms/step - loss: 0.1893 - accuracy: 0.7589 - val_loss: 0.2075 - val_accuracy: 0.7200\n",
      "Epoch 152/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.1882 - accuracy: 0.7601\n",
      "Epoch 00152: val_accuracy did not improve from 0.72578\n",
      "4157/4157 [==============================] - 73s 17ms/step - loss: 0.1882 - accuracy: 0.7601 - val_loss: 0.2151 - val_accuracy: 0.7152\n",
      "Epoch 153/200\n",
      "4154/4157 [============================>.] - ETA: 0s - loss: 0.1881 - accuracy: 0.7616\n",
      "Epoch 00153: val_accuracy did not improve from 0.72578\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.1881 - accuracy: 0.7617 - val_loss: 0.2201 - val_accuracy: 0.7024\n",
      "Epoch 154/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.1878 - accuracy: 0.7621\n",
      "Epoch 00154: val_accuracy did not improve from 0.72578\n",
      "4157/4157 [==============================] - 73s 17ms/step - loss: 0.1878 - accuracy: 0.7621 - val_loss: 0.2181 - val_accuracy: 0.7004\n",
      "Epoch 155/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.1881 - accuracy: 0.7604\n",
      "Epoch 00155: val_accuracy did not improve from 0.72578\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.1882 - accuracy: 0.7604 - val_loss: 0.2276 - val_accuracy: 0.6962\n",
      "Epoch 156/200\n",
      "4154/4157 [============================>.] - ETA: 0s - loss: 0.1864 - accuracy: 0.7627\n",
      "Epoch 00156: val_accuracy did not improve from 0.72578\n",
      "4157/4157 [==============================] - 73s 17ms/step - loss: 0.1864 - accuracy: 0.7627 - val_loss: 0.2305 - val_accuracy: 0.6856\n",
      "Epoch 157/200\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 0.1863 - accuracy: 0.7631\n",
      "Epoch 00157: val_accuracy did not improve from 0.72578\n",
      "4157/4157 [==============================] - 73s 17ms/step - loss: 0.1863 - accuracy: 0.7631 - val_loss: 0.2200 - val_accuracy: 0.7058\n",
      "Epoch 158/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.1873 - accuracy: 0.7632\n",
      "Epoch 00158: val_accuracy did not improve from 0.72578\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.1873 - accuracy: 0.7632 - val_loss: 0.2158 - val_accuracy: 0.7105\n",
      "Epoch 159/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.1868 - accuracy: 0.7633\n",
      "Epoch 00159: val_accuracy did not improve from 0.72578\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.1868 - accuracy: 0.7634 - val_loss: 0.2268 - val_accuracy: 0.6895\n",
      "Epoch 160/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.1862 - accuracy: 0.7650\n",
      "Epoch 00160: val_accuracy did not improve from 0.72578\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.1862 - accuracy: 0.7650 - val_loss: 0.2172 - val_accuracy: 0.7106\n",
      "Epoch 161/200\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 0.1862 - accuracy: 0.7640\n",
      "Epoch 00161: val_accuracy did not improve from 0.72578\n",
      "4157/4157 [==============================] - 73s 17ms/step - loss: 0.1862 - accuracy: 0.7640 - val_loss: 0.2209 - val_accuracy: 0.7041\n",
      "Epoch 162/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.1845 - accuracy: 0.7675\n",
      "Epoch 00162: val_accuracy did not improve from 0.72578\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.1845 - accuracy: 0.7675 - val_loss: 0.2194 - val_accuracy: 0.7004\n",
      "Epoch 163/200\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 0.1844 - accuracy: 0.7672\n",
      "Epoch 00163: val_accuracy did not improve from 0.72578\n",
      "4157/4157 [==============================] - 73s 17ms/step - loss: 0.1844 - accuracy: 0.7672 - val_loss: 0.2520 - val_accuracy: 0.6453\n",
      "Epoch 164/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.1839 - accuracy: 0.7669\n",
      "Epoch 00164: val_accuracy did not improve from 0.72578\n",
      "4157/4157 [==============================] - 73s 17ms/step - loss: 0.1839 - accuracy: 0.7668 - val_loss: 0.2354 - val_accuracy: 0.6715\n",
      "Epoch 165/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.1854 - accuracy: 0.7676\n",
      "Epoch 00165: val_accuracy did not improve from 0.72578\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.1854 - accuracy: 0.7676 - val_loss: 0.2182 - val_accuracy: 0.7063\n",
      "Epoch 166/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.1840 - accuracy: 0.7688\n",
      "Epoch 00166: val_accuracy improved from 0.72578 to 0.72890, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2000/epoch_166_valloss_0.2072_valacc_0.7289.hdf5\n",
      "4157/4157 [==============================] - 73s 18ms/step - loss: 0.1840 - accuracy: 0.7689 - val_loss: 0.2072 - val_accuracy: 0.7289\n",
      "Epoch 167/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.1837 - accuracy: 0.7683\n",
      "Epoch 00167: val_accuracy did not improve from 0.72890\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.1837 - accuracy: 0.7683 - val_loss: 0.2236 - val_accuracy: 0.7010\n",
      "Epoch 168/200\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 0.1845 - accuracy: 0.7695\n",
      "Epoch 00168: val_accuracy did not improve from 0.72890\n",
      "4157/4157 [==============================] - 73s 17ms/step - loss: 0.1845 - accuracy: 0.7695 - val_loss: 0.2275 - val_accuracy: 0.6955\n",
      "Epoch 169/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.1834 - accuracy: 0.7706\n",
      "Epoch 00169: val_accuracy did not improve from 0.72890\n",
      "4157/4157 [==============================] - 73s 18ms/step - loss: 0.1834 - accuracy: 0.7706 - val_loss: 0.2225 - val_accuracy: 0.7094\n",
      "Epoch 170/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.1837 - accuracy: 0.7713\n",
      "Epoch 00170: val_accuracy did not improve from 0.72890\n",
      "4157/4157 [==============================] - 73s 17ms/step - loss: 0.1837 - accuracy: 0.7713 - val_loss: 0.2231 - val_accuracy: 0.6956\n",
      "Epoch 171/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.1819 - accuracy: 0.7736\n",
      "Epoch 00171: val_accuracy did not improve from 0.72890\n",
      "4157/4157 [==============================] - 73s 17ms/step - loss: 0.1819 - accuracy: 0.7736 - val_loss: 0.2308 - val_accuracy: 0.6943\n",
      "Epoch 172/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.1834 - accuracy: 0.7714\n",
      "Epoch 00172: val_accuracy did not improve from 0.72890\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.1834 - accuracy: 0.7715 - val_loss: 0.2229 - val_accuracy: 0.7054\n",
      "Epoch 173/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.1825 - accuracy: 0.7729\n",
      "Epoch 00173: val_accuracy did not improve from 0.72890\n",
      "4157/4157 [==============================] - 73s 17ms/step - loss: 0.1825 - accuracy: 0.7729 - val_loss: 0.2260 - val_accuracy: 0.6972\n",
      "Epoch 174/200\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 0.1818 - accuracy: 0.7732\n",
      "Epoch 00174: val_accuracy did not improve from 0.72890\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.1818 - accuracy: 0.7732 - val_loss: 0.2083 - val_accuracy: 0.7244\n",
      "Epoch 175/200\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 0.1812 - accuracy: 0.7726\n",
      "Epoch 00175: val_accuracy did not improve from 0.72890\n",
      "4157/4157 [==============================] - 73s 17ms/step - loss: 0.1812 - accuracy: 0.7726 - val_loss: 0.2296 - val_accuracy: 0.6918\n",
      "Epoch 176/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.1814 - accuracy: 0.7760\n",
      "Epoch 00176: val_accuracy did not improve from 0.72890\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.1814 - accuracy: 0.7760 - val_loss: 0.2299 - val_accuracy: 0.6889\n",
      "Epoch 177/200\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 0.1805 - accuracy: 0.7777\n",
      "Epoch 00177: val_accuracy did not improve from 0.72890\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.1805 - accuracy: 0.7777 - val_loss: 0.2350 - val_accuracy: 0.6860\n",
      "Epoch 178/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.1812 - accuracy: 0.7750\n",
      "Epoch 00178: val_accuracy did not improve from 0.72890\n",
      "4157/4157 [==============================] - 73s 17ms/step - loss: 0.1812 - accuracy: 0.7750 - val_loss: 0.2177 - val_accuracy: 0.7202\n",
      "Epoch 179/200\n",
      "4154/4157 [============================>.] - ETA: 0s - loss: 0.1808 - accuracy: 0.7750\n",
      "Epoch 00179: val_accuracy did not improve from 0.72890\n",
      "4157/4157 [==============================] - 73s 17ms/step - loss: 0.1808 - accuracy: 0.7750 - val_loss: 0.2343 - val_accuracy: 0.6916\n",
      "Epoch 180/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.1806 - accuracy: 0.7768\n",
      "Epoch 00180: val_accuracy did not improve from 0.72890\n",
      "4157/4157 [==============================] - 73s 17ms/step - loss: 0.1806 - accuracy: 0.7767 - val_loss: 0.2238 - val_accuracy: 0.7044\n",
      "Epoch 181/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.1812 - accuracy: 0.7764\n",
      "Epoch 00181: val_accuracy did not improve from 0.72890\n",
      "4157/4157 [==============================] - 73s 17ms/step - loss: 0.1812 - accuracy: 0.7765 - val_loss: 0.2238 - val_accuracy: 0.7077\n",
      "Epoch 182/200\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 0.1815 - accuracy: 0.7771\n",
      "Epoch 00182: val_accuracy did not improve from 0.72890\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.1815 - accuracy: 0.7771 - val_loss: 0.2220 - val_accuracy: 0.7050\n",
      "Epoch 183/200\n",
      "4154/4157 [============================>.] - ETA: 0s - loss: 0.1809 - accuracy: 0.7767\n",
      "Epoch 00183: val_accuracy did not improve from 0.72890\n",
      "4157/4157 [==============================] - 73s 17ms/step - loss: 0.1809 - accuracy: 0.7767 - val_loss: 0.2188 - val_accuracy: 0.7155\n",
      "Epoch 184/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.1801 - accuracy: 0.7784\n",
      "Epoch 00184: val_accuracy did not improve from 0.72890\n",
      "4157/4157 [==============================] - 73s 17ms/step - loss: 0.1801 - accuracy: 0.7784 - val_loss: 0.2121 - val_accuracy: 0.7246\n",
      "Epoch 185/200\n",
      "4154/4157 [============================>.] - ETA: 0s - loss: 0.1796 - accuracy: 0.7786\n",
      "Epoch 00185: val_accuracy did not improve from 0.72890\n",
      "4157/4157 [==============================] - 73s 18ms/step - loss: 0.1796 - accuracy: 0.7786 - val_loss: 0.2161 - val_accuracy: 0.7229\n",
      "Epoch 186/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.1797 - accuracy: 0.7789\n",
      "Epoch 00186: val_accuracy did not improve from 0.72890\n",
      "4157/4157 [==============================] - 73s 18ms/step - loss: 0.1797 - accuracy: 0.7789 - val_loss: 0.2125 - val_accuracy: 0.7269\n",
      "Epoch 187/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.1791 - accuracy: 0.7802\n",
      "Epoch 00187: val_accuracy improved from 0.72890 to 0.73282, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2000/epoch_187_valloss_0.2082_valacc_0.7328.hdf5\n",
      "4157/4157 [==============================] - 73s 18ms/step - loss: 0.1791 - accuracy: 0.7802 - val_loss: 0.2082 - val_accuracy: 0.7328\n",
      "Epoch 188/200\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 0.1781 - accuracy: 0.7819\n",
      "Epoch 00188: val_accuracy did not improve from 0.73282\n",
      "4157/4157 [==============================] - 73s 17ms/step - loss: 0.1781 - accuracy: 0.7819 - val_loss: 0.2308 - val_accuracy: 0.6907\n",
      "Epoch 189/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.1793 - accuracy: 0.7805\n",
      "Epoch 00189: val_accuracy did not improve from 0.73282\n",
      "4157/4157 [==============================] - 73s 17ms/step - loss: 0.1793 - accuracy: 0.7805 - val_loss: 0.2424 - val_accuracy: 0.6745\n",
      "Epoch 190/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.1784 - accuracy: 0.7821\n",
      "Epoch 00190: val_accuracy did not improve from 0.73282\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.1784 - accuracy: 0.7821 - val_loss: 0.2231 - val_accuracy: 0.7066\n",
      "Epoch 191/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.1787 - accuracy: 0.7822\n",
      "Epoch 00191: val_accuracy did not improve from 0.73282\n",
      "4157/4157 [==============================] - 73s 17ms/step - loss: 0.1788 - accuracy: 0.7821 - val_loss: 0.2322 - val_accuracy: 0.6937\n",
      "Epoch 192/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.1796 - accuracy: 0.7807\n",
      "Epoch 00192: val_accuracy did not improve from 0.73282\n",
      "4157/4157 [==============================] - 73s 17ms/step - loss: 0.1796 - accuracy: 0.7807 - val_loss: 0.2270 - val_accuracy: 0.6967\n",
      "Epoch 193/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.1780 - accuracy: 0.7836\n",
      "Epoch 00193: val_accuracy did not improve from 0.73282\n",
      "4157/4157 [==============================] - 72s 17ms/step - loss: 0.1780 - accuracy: 0.7836 - val_loss: 0.2226 - val_accuracy: 0.7113\n",
      "Epoch 194/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.1780 - accuracy: 0.7848\n",
      "Epoch 00194: val_accuracy did not improve from 0.73282\n",
      "4157/4157 [==============================] - 73s 17ms/step - loss: 0.1780 - accuracy: 0.7848 - val_loss: 0.2388 - val_accuracy: 0.6840\n",
      "Epoch 195/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.1780 - accuracy: 0.7838\n",
      "Epoch 00195: val_accuracy did not improve from 0.73282\n",
      "4157/4157 [==============================] - 73s 17ms/step - loss: 0.1780 - accuracy: 0.7838 - val_loss: 0.2149 - val_accuracy: 0.7248\n",
      "Epoch 196/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.1751 - accuracy: 0.7878\n",
      "Epoch 00196: val_accuracy did not improve from 0.73282\n",
      "4157/4157 [==============================] - 73s 18ms/step - loss: 0.1751 - accuracy: 0.7878 - val_loss: 0.2161 - val_accuracy: 0.7240\n",
      "Epoch 197/200\n",
      "4155/4157 [============================>.] - ETA: 0s - loss: 0.1761 - accuracy: 0.7883\n",
      "Epoch 00197: val_accuracy did not improve from 0.73282\n",
      "4157/4157 [==============================] - 73s 18ms/step - loss: 0.1761 - accuracy: 0.7882 - val_loss: 0.2399 - val_accuracy: 0.6817\n",
      "Epoch 198/200\n",
      "4157/4157 [==============================] - ETA: 0s - loss: 0.1765 - accuracy: 0.7854\n",
      "Epoch 00198: val_accuracy did not improve from 0.73282\n",
      "4157/4157 [==============================] - 73s 17ms/step - loss: 0.1765 - accuracy: 0.7854 - val_loss: 0.2306 - val_accuracy: 0.6997\n",
      "Epoch 199/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.1764 - accuracy: 0.7873\n",
      "Epoch 00199: val_accuracy did not improve from 0.73282\n",
      "4157/4157 [==============================] - 73s 17ms/step - loss: 0.1764 - accuracy: 0.7873 - val_loss: 0.2414 - val_accuracy: 0.6830\n",
      "Epoch 200/200\n",
      "4156/4157 [============================>.] - ETA: 0s - loss: 0.1757 - accuracy: 0.7869\n",
      "Epoch 00200: val_accuracy did not improve from 0.73282\n",
      "4157/4157 [==============================] - 73s 17ms/step - loss: 0.1757 - accuracy: 0.7869 - val_loss: 0.2204 - val_accuracy: 0.7131\n"
     ]
    }
   ],
   "source": [
    "# model = model_cnn14_attention_multi(dim_time, dim_freq, num_species, model_type='feature_level_attention', conv_dim=conv_dim, pool_size=pool_size, pool_stride=pool_stride, hidden_units=hidden_units, l2_regu=l2_regu, drop_rate=drop_rate)\n",
    "model = model_cnn14_spp(dim_time, dim_freq, num_species, conv_dim=conv_dim, pool_size=pool_size, pool_stride=pool_stride, hidden_units=hidden_units, l2_regu=l2_regu, drop_rate=drop_rate)\n",
    "# loss = categorical_crossentropy\n",
    "loss = binary_crossentropy\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate_fn), loss=loss, metrics=['accuracy'])\n",
    "# model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss=loss, metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# With classes\n",
    "# history = model.fit(fea_train, to_categorical(label_train), class_weight=class_weights, validation_split=0.3, batch_size=batch_size, epochs=num_epoch, callbacks=[EarlyStopping(patience=num_patience), ModelCheckpoint(filepath=os.path.join(fit_result_path, '{epoch:02d}-{val_loss:.4f}.hdf5'), verbose=1, monitor=\"val_loss\", save_best_only=True)])\n",
    "# history = model.fit(train_generator, validation_data=validate_generator, class_weight=class_weights, epochs=num_epoch, callbacks=[EarlyStopping(patience=num_patience, monitor='val_loss', mode='min', verbose=1), TensorBoard(log_dir=fit_result_path1), ModelCheckpoint(filepath=os.path.join(fit_result_path1, '{epoch:02d}-{val_loss:.4f}.hdf5'), verbose=1, monitor=\"val_loss\", save_best_only=True)])\n",
    "# history = model.fit(train_generator, validation_data=validate_generator, class_weight=class_weights, epochs=num_epoch, callbacks=[EarlyStopping(patience=num_patience, monitor='val_loss', mode='min', verbose=1), TensorBoard(log_dir=fit_result_path2), ModelCheckpoint(filepath=os.path.join(fit_result_path2, 'epoch_{epoch:02d}_valloss_{val_loss:.4f}_valacc_{val_accuracy:.4f}.hdf5' ), verbose=1, monitor=\"val_loss\", save_best_only=True)])\n",
    "# history = model.fit(train_generator, validation_data=validate_generator, class_weight=class_weights, epochs=num_epoch, callbacks=[EarlyStopping(patience=num_patience, monitor='val_loss', mode='min', verbose=1), TensorBoard(log_dir=fit_result_path2), ModelCheckpoint(filepath=os.path.join(fit_result_path2, 'epoch_{epoch:02d}_valloss_{val_loss:.4f}_valacc_{val_accuracy:.4f}.hdf5' ), verbose=1, monitor=\"val_accuracy\", save_best_only=True)])\n",
    "history = model.fit(train_generator, validation_data=validate_generator, class_weight=class_weights, epochs=num_epoch, callbacks=[EarlyStopping(patience=num_patience, monitor='val_accuracy', mode='max', verbose=1), TensorBoard(log_dir=fit_result_path2), ModelCheckpoint(filepath=os.path.join(fit_result_path2, 'epoch_{epoch:02d}_valloss_{val_loss:.4f}_valacc_{val_accuracy:.4f}.hdf5' ), verbose=1, monitor=\"val_accuracy\", save_best_only=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model:0.7328\n",
      "/home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2000/epoch_187_valloss_0.2082_valacc_0.7328.hdf5\n"
     ]
    }
   ],
   "source": [
    "# fit_result_path2 = '/home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210310_095616/STAR2000'\n",
    "the_best_model, _ = find_best_model(fit_result_path2, purge=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 100, 128, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 100, 128, 16)      160       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 100, 128, 16)      64        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 100, 128, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 100, 128, 16)      2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 100, 128, 16)      64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 100, 128, 16)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 50, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 50, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 50, 64, 32)        4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 50, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 50, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 50, 64, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 50, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 50, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 25, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 25, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 25, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 25, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 25, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 25, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 25, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 25, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 13, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 13, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 13, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 13, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 13, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 13, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 13, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 7, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 7, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 7, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 7, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 7, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 7, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 7, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "spatial_pyramid_pooling2d (S (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               1376512   \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 2056      \n",
      "=================================================================\n",
      "Total params: 2,695,672\n",
      "Trainable params: 2,692,152\n",
      "Non-trainable params: 3,520\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_model(the_best_model)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Training data\n",
    "fea_temp = np.load(os.path.join(feature_path, 'oswald_STAR2000_orig.npz'))\n",
    "# fea_temp = np.load(os.path.join(feature_path, 'oswald_STAR2003_orig.npz'))\n",
    "# fea_temp = np.load(os.path.join(feature_path, 'oswald_STAR2006_orig.npz'))\n",
    "# fea_temp = np.load(os.path.join(feature_path, 'oswald_HICEAS2002_orig.npz'))\n",
    "# fea_temp = np.load(os.path.join(feature_path, 'oswald_PICEAS2005_orig.npz'))\n",
    "    \n",
    "fea_train = fea_temp['feas_orig']\n",
    "label_train_list = fea_temp['labels_orig']\n",
    "del fea_temp\n",
    "\n",
    "fea_train = fea_train[:,:100,:]\n",
    "label_train = np.zeros(len(label_train_list))\n",
    "for ii in range(len(label_train_list)):\n",
    "    label_train[ii] = species_dict[label_train_list[ii]]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# testing the training data\n",
    "label_train_pred = model.predict(fea_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "np.set_printoptions(linewidth=200, precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(\"Confusion matrix:\")\n",
    "cm = confusion_matrix(label_train[:label_train_pred.shape[0]], np.argmax(label_train_pred, axis=1), labels=species_id)\n",
    "\n",
    "print(species_list)\n",
    "print('')\n",
    "print(cm)\n",
    "print('')\n",
    "\n",
    "cm2 = cm*1.0\n",
    "for ii in range(cm.shape[0]):\n",
    "    cm_row = cm[ii, :]*1.0\n",
    "\n",
    "    cm_row_sum = cm_row.sum()\n",
    "    if cm_row_sum != 0:\n",
    "        cm2[ii, :] = cm_row / cm_row_sum\n",
    "    else:\n",
    "        cm2[ii, :] = np.zeros(cm.shape[1])\n",
    "\n",
    "print(cm2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics._plot.confusion_matrix import ConfusionMatrixDisplay\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=species_list)\n",
    "disp2 = ConfusionMatrixDisplay(confusion_matrix=cm2, display_labels=species_list)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(figsize=[15, 15])\n",
    "disp.plot(include_values=True,\n",
    "                     cmap='viridis', ax=ax, xticks_rotation='horizontal',\n",
    "                     values_format=None, colorbar=True)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots(figsize=[15, 15])\n",
    "disp2.plot(include_values=True,\n",
    "                     cmap='viridis', ax=ax, xticks_rotation='horizontal',\n",
    "                     values_format='.2f', colorbar=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## top k accuracy score"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.metrics import top_k_accuracy_score"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "top_k = []\n",
    "for kk in range(1, num_species+1):\n",
    "    print('k='+str(kk)+':  ')\n",
    "    this_acc = top_k_accuracy_score(label_train[:label_train_pred.shape[0]], label_train_pred, k=kk, labels=list(range(num_species)))\n",
    "    print(this_acc)\n",
    "    top_k.append(this_acc)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# %matplotlib inline\n",
    "fig = plt.figure()\n",
    "ax = fig.subplots()\n",
    "ax.bar(list(range(1, num_species+1)), top_k)\n",
    "ax.grid(axis='y')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# data cleaning. Remove those not trained well\n",
    "np.savez(os.path.join(feature_path, 'train_oswald_no_'+ee+'_label_correct.npz'), label_train=label_train, label_train_pred=label_train_pred )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "label_train = label_train[:label_train_pred.shape[0]]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "label_train.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "label_train_pred[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "label_pred = model.predict(fea_test)\n",
    "# label_pred = model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=200, precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "['BD', 'CD', 'STR', 'SPT', 'SPIN', 'PLT', 'RT', 'FKW']\n",
      "\n",
      "[[  19   12    7   48    4    6   19    6]\n",
      " [ 165 2108  311  696   88  339  234   23]\n",
      " [  90  217  200  435   44   99   49    6]\n",
      " [  33  486   13  198    9   73   28    5]\n",
      " [  79   85   17  219   63   17   11    0]\n",
      " [   0    0    0    0    0   25    1    5]\n",
      " [  12    5    6    8    0    7   34    4]\n",
      " [   0    0    0    0    0    0    0    0]]\n",
      "\n",
      "[[0.16 0.1  0.06 0.4  0.03 0.05 0.16 0.05]\n",
      " [0.04 0.53 0.08 0.18 0.02 0.09 0.06 0.01]\n",
      " [0.08 0.19 0.18 0.38 0.04 0.09 0.04 0.01]\n",
      " [0.04 0.58 0.02 0.23 0.01 0.09 0.03 0.01]\n",
      " [0.16 0.17 0.03 0.45 0.13 0.03 0.02 0.  ]\n",
      " [0.   0.   0.   0.   0.   0.81 0.03 0.16]\n",
      " [0.16 0.07 0.08 0.11 0.   0.09 0.45 0.05]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.  ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix:\")\n",
    "cm = confusion_matrix(label_test, np.argmax(label_pred, axis=1), labels=species_id)\n",
    "\n",
    "print(species_list)\n",
    "print('')\n",
    "print(cm)\n",
    "print('')\n",
    "\n",
    "cm2 = cm*1.0\n",
    "for ii in range(cm.shape[0]):\n",
    "    cm_row = cm[ii, :]*1.0\n",
    "\n",
    "    cm_row_sum = cm_row.sum()\n",
    "    if cm_row_sum != 0:\n",
    "        cm2[ii, :] = cm_row / cm_row_sum\n",
    "    else:\n",
    "        cm2[ii, :] = np.zeros(cm.shape[1])\n",
    "\n",
    "print(cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics._plot.confusion_matrix import ConfusionMatrixDisplay\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=species_list)\n",
    "disp2 = ConfusionMatrixDisplay(confusion_matrix=cm2, display_labels=species_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fba57ae0760>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=[15, 15])\n",
    "disp.plot(include_values=True,\n",
    "                     cmap='viridis', ax=ax, xticks_rotation='horizontal',\n",
    "                     values_format=None, colorbar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fba57ae07f0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0EAAANDCAYAAABrNRTSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAACO6ElEQVR4nOzdeXxU1fnH8e+ZyR4IJJlshFVlUZE1yKIggvtStdrW1trWVgUVbV3qUq22dWvrvltbrbbuqFWsKCgKKMjiioAEWQOELJMEErJn5vz+mBQyyQDxZ5IZ5n7efeUlM/e5d849vTN3nnuee8ZYawUAAAAATuEKdwMAAAAAoCuRBAEAAABwFJIgAAAAAI5CEgQAAADAUUiCAAAAADhKTLgbAAAAAKDjnXhssi0r94W7Gfv06Yr6Odbak7r6dUmCAAAAgChUVu7Tsjl9w92MfXLnfOMJx+tSDgcAAADAUUiCAAAAADgKSRAAAAAQhawkf4T/rz2MMScZY/KNMeuMMdeHWN7DGPOmMeZLY8wqY8wF+9smSRAAAACAiGSMcUt6RNLJkg6T9GNjzGGtwi6TtNpaO1zSZEn3GGPi9rVdkiAAAAAAkepISeustRustQ2SXpR0RqsYK6m7McZI6iapXFLTvjbK7HAAAABAVLLy2faVnIWRxxjzSYvHT1hrn2jxOFfSlhaPt0oa22obD0uaJalQUndJP7J23ztOEgQAAAAgXLzW2rx9LDchnrOtHp8o6QtJUyQdLOldY8yH1trKvW2UcjgAAAAAkWqrpD4tHvdWYMSnpQskvWYD1knaKGnIvjbKSBAAAAAQhQKzw7UeNDngLJc00BgzQNI2SedK+kmrmAJJUyV9aIzJkjRY0oZ9bZQkCAAAAEBEstY2GWNmSJojyS3pKWvtKmPM9Oblj0u6VdLTxpivFCifu85a693XdkmCAAAAAEQsa+1sSbNbPfd4i38XSjrh22yTe4IAAAAAOAojQQAAAECU8ivip8gOC0aCAAAAADgKSRAAAAAAR6EcDgAAAIhCVlY+e8BPkd0pGAkCAAAA4CgkQQAAAAAchXI4AAAAIEr5RTlcKIwEAQAAAHAUkiAAAAAAjkI5HAAAABCFrCQf5XAhMRIEAAAAwFFIggAAAAA4CuVwAAAAQJRidrjQGAkCAAAA4CgkQQAAAAAchSQIAAAAgKNwTxAAAAAQhawkn+WeoFAYCQIAAADgKCRBAAAAAByFcjgAAAAgSvnD3YAIxUgQAAAAAEchCQIAAADgKJTDAQAAAFHIysonZocLhZEgAAAAAI5CEgQAAADAUSiHAwAAAKKRlXxUw4XESBAAAAAARyEJAgAAAOAolMMBAAAAUciKH0vdG0aCAAAAADgKSRAAAAAAR6EcDgAAAIhKRj6ZcDciIjESBAAAAMBRSIIAAAAAOApJEAAAAABH4Z4gAAAAIApZSX4b7lZEJkaCAAAAADgKSRAAAAAAR6EcDgAAAIhSTJEdGiNBAAAAAByFJAgAAACAo1AOBwAAAEQhK8rh9oaRIAAAAACOQhIEAAAAwFEohwMAAACilN9SDhcKI0EAAAAAHIUkCAAAAICjUA4HAAAARCFmh9s7RoIAAAAAOApJEAAAAABHIQkCAAAA4CjcEwQAAABEISsjH2MeIdErAAAAAByFJAgAAACAo1AOBwAAAEQpv2WK7FAYCQIAAADgKCRBAAAAAByFcjgAAAAgCllJPlEOFwojQQAAAAAcJapGguLikm1CQmq4mxE1TKMv3E2IHj76siPVZcWHuwlRJWF7bbibEF0M1xc7ik2MC3cTooqpbQh3E6JGra9KDf5ahlgOYFGVBCUkpCov77JwNyNqxJXsCncTooapqAx3E6JK/pX9w92EqDLoT6vD3YToEk+S3lEaDu8T7iZElbhVW8LdhKjxcfkr4W5COxn5LBdmQqFXAAAAADgKSRAAAAAAR4mqcjgAAAAAAVaSnzGPkOgVAAAAAI5CEgQAAADAUUiCAAAAADgK9wQBAAAAUconfs4oFEaCAAAAADgKSRAAAAAAR6EcDgAAAIhC1hr5LGMeodArAAAAAByFJAgAAACAo1AOBwAAAEQpP7PDhcRIEAAAAABHIQkCAAAA4CiUwwEAAABRyEryMeYREr0CAAAAwFFIggAAAAA4CuVwAAAAQFTix1L3hl4BAAAA4CgkQQAAAAAchXI4AAAAIApZSX7GPEKiVwAAAAA4CkkQAAAAAEchCQIAAADgKNwTBAAAAEQpnzXhbkJEYiQIAAAAgKOQBAEAAABwFMrhAAAAgChkZeRjzCMkegUAAACAo5AEAQAAAIhYxpiTjDH5xph1xpjrQyz/rTHmi+a/lcYYnzEmbV/bpBwOAAAAiFJ+e2CPeRhj3JIekXS8pK2SlhtjZllrV/8vxlp7l6S7muNPl3SltbZ8X9s9sHsFAAAAQDQ7UtI6a+0Ga22DpBclnbGP+B9LemF/GyUJAgAAABAuHmPMJy3+Lm61PFfSlhaPtzY/14YxJknSSZJe3d+LUg4HAAAARCErHQizw3mttXn7WB7q117tXmJPl7Rof6VwEiNBAAAAACLXVkl9WjzuLalwL7Hnqh2lcBIjQR1qzLCtuvRnS+VyWb39wSC9+OawoOV9eu3Qb6d9pEP6l+mfL4/SzLeO2L0sOaleV1+0SP377JC10t1PHK2vv8ns6l2IKKPHFGnapZ/L5bKa8/ZBmvnikKDlvftU6srfLtchh+zQM/8cqtdmDm73uk40enypLr5mjVxuq7mv99bMpw9qFWE17bdrlHdUqerr3LrvD0do/ZoUSVJyt0Zd8ftV6nfILslK9/9xqNZ81bPL9yFSTMop0E2jF8ttrF5eP0R/Wz0yZNwRaSV65YTX9etFx+mdLQd9q3WdZPTR5Zp244bA+/WVbM38e59WEVbTbtygMZPKVV/n0r03DNb61d0UG+fXX5/9UrFxVm631UdzPXruoX5h2YdIMnqCV9OuWxvoz//kauZT/VtFWE27bq3GHO1VfZ1b9/7+sN3v9X/O/ki1NW75fEZ+n9GvfzK2y9sfSTivdyyOTfw/LZc00BgzQNI2BRKdn7QOMsb0kHSMpJ+2Z6NhS4KMMT5JXykwxOWTNMNau9gY01/S15LWSEqQVCXpEWvtM+Fqa3u4jF+XX7BE1915okrLkvTIbW9q8Wd9VbCt5+6Yql3xeuSZsZqQV9Bm/ct+tlTLv+ytPz0wRTFun+Ljm7qw9ZHH5bK69PLPdON1k+QtTdL9j7ynJYt7aUtByu6Yqqo4Pf7ISI2fsO1br+s0LpfVJdd/rZsuzZO3OEH3/ftjLVmQqS0bu+2OyTvKq159anTRmRM1eOhOXXbDal3183GSpIt/u0affuzRndeNUEyMX/EJvnDtSti5jF9/yFukn79/qopqk/Xaia9p3tb+WleZ2ibu2hFL9WFR72+9rpO4XFaX3rxeN/5yqLzF8bp/5hda8n6atqxP3h2TN6lCuf1qdeGJeRo8vEozblmnK380Qo0NRjf8Ypjqatxyx/h193Mr9MnCVOV/6ez3+qW/y9eN00bKW5yg+59fpiXzPdqyocV7/egy5fat0YWnT9DgIyo146Y1uvKnR+5efv2Fo1W5Iy4czY8onNc7FsdmeFgZ+WyoarIDh7W2yRgzQ9IcSW5JT1lrVxljpjcvf7w59CxJc6211e3ZbjjL4WqttSOstcMl3SDpzhbL1ltrR1prD1Ug27vSGHNBWFrZToMP8aqwuLu2l3RXk8+t+R8fpKNGB38o7qhMVP6GDPl8wd2elNigI4YU6+35AyVJTT63qmviu6ztkWjQ4HIVFnZT0fZuampyaeH8Php/VHCys3NHgr7JT2vTn+1Z12kGHb5ThVuSVLQtKdAnc3M0bnJJUMy4Y0r0/lu9JBnlr+yp5G6NSvXUKzG5SUNHVmju64F7EJuaXKreFRuGvYgMw9NLtHlXirZUp6jR79Zbmw/Rcb03tYn72aCVmrNlgMrqEr/1uk4yaFiVCgsSVLQ1UU2NLi2cnaHxU4NLucdNLdO8NzIlGeV/maLklCalZjRIMqqrcUuSYmKs3DH+vVeJO8SgoTtVuCVxz3v9nSyNn1waFDPu2FLNezNHklH+Vz2U3L1JqZ768DQ4gnFe71gcm/gurLWzrbWDrLUHW2tvb37u8RYJkKy1T1trz23vNiPlnqAUSRWhFlhrN0i6StIVXdqib8mTWqOSsj1XLkvLk5Se1q5EVDmZVdpZlaDfTvtIj9/xhq666CMlxDd2VlMPCOmeWnlLknY/9pYmKT29ttPXjVbpmXXyFifsfuwtTlB6Rl2rmHqVtowpCcTk5NZoZ0WsrvzDSj343GJd8fuVik9w7hXNrMQaba/ec+WyqCZZWUnVrWKqdULvTXp+3WHfel2nSc+ql3f7ni+H3qI4pWcFf+nxZDWotFWMpznG5bJ66D+f6flFS/T54lTlr3DuKJAUeB97i1q9j1v3Z+v3enG8PJmBGCvptsc/1wMvLNVJZ2/tkjZHKs7rHYtjE5EmnElQYvOvuq6R9A9Jt+4j9jNJIW/qMMZc/L8p9RoawvdlwpgQlx/bOfzodlkN7F+mN98boum/O0N19TE693tfdXALDyyh+tOGnBykY9eNVibkvCqmVUyoY1hyua0OGVKl2a/00RXnTVBdrVs/uGBj5zT0AGBCDDXYVk/dNHqx/vrF2DY/UNeedZ0m5KHZpk/23m9+v9HlZ43SzyaP1aBhVeo30NlJZaj3+rfpz2t+PkZXnDtWN182Uqf9aKuGjgp5fdIROK93LI5NRJpwToxQa60dIUnGmPGS/mWMGbqX2L1+6lhrn5D0hCSlpPQO29eJ0vJkZabvOflmpNWorCJpH2u0XDdJpeXJWrM+Q5K0cGl//djhH5be0iR5Mmt2P/Zk1Ki8LGEfa3TMutHKW5wgT9aekR9PVp3KvPFtYjJaxmTWqcybIFnJWxKv/JU9JUmL3svWDy7Y0CXtjkRFtcnKSd61+3F2UrVKapODYoamler+o96TJKXG12lyrwI1WdOudZ3GWxwvT86eq8Ge7AaVl7Q+NuOV0SqmrFVMdVWMvlrWQ6MnVmjzN87tU29xvDzZwe/jNv1Z0uq9nlWvstJATHnzf3eWx+nj9zM0aGilVn7mzHvWOK93LI7N8PFHTOFXZImIXrHWfizJIyljLyEjFZgsIWLlr/coN7tS2RlVinH7NHn8Bi3+tPUMR6FV7ExSaVmyeufslCSNGrpdm1vceOlEa/NT1St3l7KyqxUT49ekyVu0ZHGvTl83Wq1dnaLcPjXK6lUT6JMTtmvpguBZipYuzNSUUwslWQ0eukPVu2JU4Y1XRVm8SosTlNsv8GVg+JFlKmhxI6vTrCjLVL/uO9U7uVKxLp9O7bdO87YFz0h27KyfaPKs8zR51nl6Z8tBumX5RL23dUC71nWatV91V69+dcrKrVNMrF+TTinVkvfTgmKWvp+uqWeUSLIaPLxS1VVuVZTGKSW1QcndA6WZcfE+jRi/Q1s3JIZ4FedYuypFvfrWKiu3NvBeP6lYSxYEn1qXzs/Q1NO3S7IafMTO3e/1+ESfEpMC/Rmf6NPI8eXavM65CSXn9Y7FsYlIExFTZBtjhigw20OZpKRWy/pLulvSQ13fsvbz+1166Olx+vP1c+VyWb0zf6A2b0vVaVPXSJL+O2+IUnvU6NHb3lRSYqOsNfr+Sav1q2vPUk1tnB5+ZqxuuGyBYmP82l7SXXf97egw71F4+f0uPfbQSN3254VyuazmvjNABZt76JTT1kuSZv/3YKWm1umBR99TUlKj/NbozO9/o2m/OlG1NbEh13Uyv8+lx/56qG59+FO53FbvvpGrgg3ddPLZgR9gfvvVPlr+kUd5R5XqH2982DxF9p6B2b/99VD99rYVion1q2hbku7/w94GbaOfz7r0x0+O1j+PnS23sZq5YbC+2ZmmHx+yWpL0Qqv7gNqzrpP5fUaP3XqwbntyZeD9+mqWCtYl65QfbZckzX4pR8sXpGrMpHI9OfcT1de5dN/vBkmS0jIadfWf8+VyWxkjffiOR8vmp4dzd8LO73PpsTsH67bHAj8RMPf1XipY302n/CBwD8Xsmb21/MN0jTnaqyf/uzjQnzcfLklKTavXTfetkCS5Y6zmz87Wp4s9YduXcOO83rE4NhFpjA1TQXqLKbKlQLnb76y1b+1liuzHrLX/3N82U1J627y8yzqpxc4TV7Jr/0FoF1NRGe4mRJX8q/uHuwlRZdCfVoe7CdEl3tmzgHWkhsPbN/KC9olbtSXcTYgaH5e/op2NJRF/w3H/od3sza+NCHcz9ulXgxd9aq3N6+rXDdtIkLXWvZfnN0lydj0DAAAAgE4TEfcEAQAAAEBXiYh7ggAAAAB0NCO/w38mZG8YCQIAAADgKCRBAAAAAByFcjgAAAAgClkFfp4BbdErAAAAAByFJAgAAACAo1AOBwAAAEQpH2MeIdErAAAAAByFJAgAAACAo1AOBwAAAEQhKyO/5cdSQ2EkCAAAAICjkAQBAAAAcBSSIAAAAACOwj1BAAAAQJRiiuzQ6BUAAAAAjkISBAAAAMBRKIcDAAAAopCV5LeMeYRCrwAAAABwFJIgAAAAAI5CORwAAAAQlYx8MuFuRERiJAgAAACAo5AEAQAAAHAUyuEAAACAKMTscHtHrwAAAABwFJIgAAAAAI5CORwAAAAQpZgdLjRGggAAAAA4CkkQAAAAAEchCQIAAADgKNwTBAAAAEQhaw1TZO8FvQIAAADAUUiCAAAAADgK5XAAAABAlPJRDhcSvQIAAADAUUiCAAAAADhKVJXDmdp6xX21KdzNiBqlz3jC3YSokXl5fLibEFX6vNsU7iZEFdtEf3Ykk8VnZ0eJzy8MdxOiSpPXG+4mRA3rPzA+N60kv0y4mxGRGAkCAAAA4CgkQQAAAAAcJarK4QAAAAD8j2F2uL2gVwAAAAA4CkkQAAAAAEehHA4AAACIQlaS3zI7XCiMBAEAAABwFJIgAAAAAI5CEgQAAADAUbgnCAAAAIhSPsY8QqJXAAAAADgKSRAAAAAAR6EcDgAAAIhCVoYpsveCkSAAAAAAjkISBAAAAMBRKIcDAAAAopSfMY+Q6BUAAAAAjkISBAAAAMBRKIcDAAAAopC1ko/Z4UJiJAgAAACAo5AEAQAAAHAUyuEAAACAKMWPpYbGSBAAAAAARyEJAgAAAOAolMMBAAAAUcjKyG8Z8wiFXgEAAADgKCRBAAAAAByFJAgAAACAo3BPEAAAABClfGKK7FAYCQIAAADgKCRBAAAAAByFcjgAAAAgCllJfks5XCiMBAEAAABwFJIgAAAAAI5CORwAAAAQlYz8ljGPUOgVAAAAAI5CEgQAAADAUSiH60CjjyrTtOu+kcstzXktRzOf7Ncqwmra9d9ozMRy1de5dO9Nh2r91913L3W5rB548ROVlcTrDzOGdW3jI1Dsp9VKeqJE8kv1J/RQ3Q/SgpbHrKhRt9sK5c+KlSQ1TOimuh+nSw1+pVy3RWq0kl9qPKqbas/zhGMXIsrosSW6+DdfyeWymvtmP818dmCrCKtpv1mpvPHFqq9z677bR2r92p6SpDN/tF4nnF4ga6XN61N03x0j1Njg7vJ9iBRjhm7VjJ8skdvl11sLB+uF2cODlvfJ3qHrfrVQA/uV6cnX8vTyO0fsXnbOCSt16qR8WStt2Jqmvzw5UY1Nzv4oHj2pQtNv2iSX2+qdl7M082+5rSKspv9+k8ZMrlB9rVv3XHew1q/qJk9Ova65a51SPY2yVnr7xSy98UxOWPYhkow+sljTLl8hl8tqzlv9NPP5wa0irKZdsUJjxharvt6te+8crfXf9JQknXH2Op142iYZI73z3/5645VDurz9kWT0+FJdfM0audxWc1/vrZlPH9Qqwmrab9co76jSwOfmH47Q+jUpkqTkbo264ver1O+QXZKV7v/jUK35qmeX70MkyZtcqel/2ia3y+rtF9L18iNZrSKsLvnTNh05pVJ1tS7dc2VfrVuZJEm66p4CjT2uUju8MZo2dUjXN/4A5ufHUkMK60iQMSbbGPOiMWa9MWa1MWa2MWaQMabWGPO5MeZrY8wyY8zPw9nO9nC5rC69ca1uvnS4pp9xpI45uVh9DqoOismbWK7cfrW68NSxevCPgzXjpvyg5Wf8dIu2bEzqymZHLp9V0mMlqvpjrnY+2l9xCyrlKqhvE9Z0eKIqH+qnyof6BRIgSYo1qryjjyof7q/KB/sp9tMaudfUdvEORBaXy+qSq1folqvH6ZLzpmjScdvUp39VUEze+BL16l2ti340VQ/9dbguu2aFJCndU6vTz9mo3/xyki47/1i5XFbHHLctHLsREVzGr1+fv1jX33eCfnHj2Zo6doP69aoIiqmqjtdDz48PSn4kydOzWt8/bpWm/fEM/fL3Z8vtspoydkNXNj/iuFxWl/1ho37/q0M17aQRmnyaV30PqQmKGXPMDvXqX6dfTR2pB286SDP+uFGS5Gsy+vud/TTtpBG68pwjdNpPi9qs6zQul9Wlv/lSN187QdN/fpyOmbpVffpVBsXkjS1Wbu9qXXje8Xrw7pGacdUXkqR+Ayp14mmbdOX0ybrsV1N05Pgi9crdFYa9iAwul9Ul13+tW64YrUvOOVqTTtyuPgOC+yPvKK969anRRWdO1EO3Ha7Lbli9e9nFv12jTz/2aPrZR2vGuRO0ZWNyV+9CRHG5rC67fatu+ulBuujYITr2zAr1HVgXFDNmSpVyB9TrgqMP1QPX9dHld27dvWzuy2m68bzWSSjw/xe2JMgYYyT9R9J8a+3B1trDJP1OUpak9dbakdbaQyWdK+lKY8wF4Wpreww6olKFBYkq2pqopiaXFr6dpfHHeoNixh3r1bxZ2ZKM8lf0UHL3JqV6Al/s07PqNGZimea82isMrY88MWvr5M+JlT87Too1apiUorgl1ftfUZKMkRKbD+0mK/msnH4RZNChFSrcmqyiwuTA8TkvV+MmFgXFjDu6SO+/01uSUf6qNCV3b1RqeuAE5Xb7FRfvk8vtV3yCT2XehDDsRWQYclCpCktStL00RU0+t95fdpCOGlkQFLOjKlH5GzPU5Gv7Eet2W8XH+eRy+RUf16SyHc6+8DFo+C4Vbk5Q0ZYENTW6tOAtj8YdF5xUjjuuXPP+kyHJaM0X3dUtpUmpGQ2qKI3T+lXdJEm11W5tWZ+o9KyGMOxF5Bh0aLkKtyWraHvze/393hp/9PagmHFHb9e8OX0kGeWvTlNyt0alptWpT78q5a9OU319jPw+l1Z+6dGESYXh2ZEIMOjwnSrckqSibUmBvpybo3GTS4Jixh1Tovff6iXJKH9lz0BfeuqVmNykoSMrNPf1wKhmU5NL1btiw7AXkWPwyBoVbopXUUG8mhpdmv9GqsafuDMoZvyJO/XeK2mSjNZ8lqzkHj6lZTZKklYu7aaqHc6tQEDHC+dI0LGSGq21j//vCWvtF5K2tAyy1m6QdJWkK7q0dd9Sema9vEV7vhh6i+OVnhU8cuHJrFdpUXxQjCczEDPt2nV66r5D5Pd3TXsjnSlrki9jT4mQ3xMjV1ljm7iYNbVKmbFJ3W7ZKvfmFv3ts0q5fLNSf7pejSOS5Buc2BXNjljpGXXyluzpA29JgtIzatvElAbFJCo9o05l3kS99sIhevq1d/XsG3NVXR2jz5dldlnbI40ntUYl5Xuu6JaWJ8mT2r4E3bsjWS+/M1Qv3f2iXr3/BVXXxumTVb07q6kHBE9Wg0q3t/hcLIpr89mZntUg7/a4oBhPq2QnM7dOBx9Wrfwvu3VugyNcuqfVe700Ueme4KvtHk9t8Hu9NFGejFpt3thdQ4d71T2lXvHxTcobVyRPpnNH0dMz6+QtbnleT1B6Rl2rmHqVtowpCcTk5NZoZ0WsrvzDSj343GJd8fuVik9o6rK2R6L07EaVFu5JBL3bY+XJDj6ve0LEpGe3Pfej/ayVfNZE9F+4hDMJGirp03bGfiYpZAGoMeZiY8wnxphPGvx1oUK6hAnx/6G1rYNaPyFZGR05yasd5bFat7p7m+VooVUnNx0Srx1PHaTKh/ur/rSe6nZbiyuWbqPKh/ppx9MHKWZtndyb2pbSOUmo41OtPnhMiONTVurWvUHjJhbplz84TuefcYISEnw69oQtbWMdImRXtvNDvFtSvSaMLNCPr/2hzrnyx0qIb9Rx49d1bAMPNO06NkOEtDhcE5J8uumRtfrbbf1Vs8vZ91eF7Ks2QSFirLRlc4pmPj9It9+zSLfetVgb1/WQr8m5w+jf5XPT5bY6ZEiVZr/SR1ecN0F1tW794IKNndPQA0T7vie1IwboIAfK7HB7/RS21j5hrc2z1ubFucJXouMtjpcne08S5smqV3lJfKuYBGVk1wfFlJXE6bCROzXu2DL9852Pdd1dqzXsyApdc+dqOZlNj5G7dM9VM5e3Sf60Vl9ukty7y94ax3STfFZmpy94O93cajwiSbGftbOULkp5SxKCruh6MuvalLR5SxKVERRTqzJvgkbkeVVcmKTKHfHy+VxavCBHhx4RXK7kJKUVScpM23M8ZaTVtLukbfRhhSoq7a6dVYny+Vz68NP+GnpIcWc19YDgLYpTRk6Lz8XsBpWVxLWJ8eQ0hIxxx/h10yP5+mCWR4vnpndNoyOYt7TVez2jVuWt3+ulrd7rGbUq8wZGhubO7q8rLpqia6+YpKqqOBVuc+7Imrc4QZ6sluf1OpV5Q5zXW8Y0f7aWlSTIWxKv/JU9JUmL3svWIUOC781yGu/2WGX02jOq48lpVFlx7H5jyoudXUaIzhPOJGiVpNHtjB0p6etObMt3tnZld/XqV6us3FrFxPg16eRiLZkfPCPZ0g/SNfV7RZKsBg/bqepdMarwxuvpBw7Wz46boAtOGq+//PYwrViWqrtvOCw8OxIhmgYlyFXYKFdRo9RoFbewUo1jg28qNRVNuy8RufNrJSvZFJfMziaZXc3JUL1fsV/UyNc7rvVLOMraNT2V27taWTnVgeNz6jYt/Sh4Vp6lH2VryklbJVkNPrxc1btiVVGWoNLiRA0eWqH4+CZJVsPzSrVls3O/GK3ZmKHczEple6oU4/ZpypEbtPjzvu1at6Q8WYcdXKL4uEBfjjqsUJsLe3ZqeyPd2hXd1KtfnbJ61ykm1q9jTvVqybzUoJgl89I09axSSVZDRlSpusqtitI4SVa/uXO9tqxL1H+e4n5KSVq7JlW9eu9SVnbze33KVi1ZFDxj3tJFOZp64hZJVoMPK1d1dawqygOJUo+egYQ0I7NGEyYWasF7zi3XXLs6Rbl9apTVqybQlyds19IFwaXASxdmasqphZKsBg/dsfu8XlEWr9LiBOX2C1wwGX5kmQo2OPdzU5Lyv0hS7oB6ZfWpV0ysX5PPqNCSuSlBMUvmpui4c8olWQ0ZVa2aSrfKS0iC0DnCWTfwvqQ7jDEXWWv/LknGmDGSgi6pGmP6S7pb0kNd3sJvwe9z6bE7Bum2x78MTKX5nxwVrE/WKT8IzKI1e2auln+YrjGTyvXk7CWBqTRvYorHvXIb1UzPUPebtwamyD4+Rb5+8YqfvUOSVH9KT8V9VKX4t3cGUvl4l6qvzZGMkavcp+T7iiR/YIrshond1Xiks08+fp9Lj913hG69d4lcbqt3/9tXBRtTdPKZmyRJb7/eX8s/zlTe+GL94+V5gePzjpGSpPzVqVr0QY4e+OdC+XxGG9b20NtvtJ7+3Tn8fpcefG68/nr1O3K5rN7+cJA2Fabq9MmB6zRvzj9UqSk1+tstbygpsVHWGp1z/Er94saz9fWGTC34ZICe+MPr8vmMvilI138XOPtzwO8zeuyPA3TbP7+W2201d2amCr5J0ik/DkzcMfuFbC2f31NjJlfoqfc/V12tS/ddF5i2+fDRVTruLK82rknSw7O+lCQ9c09fLV+QutfXi3Z+n0uP3T9ct929SC6XNHd2PxVsStEp3wuUYs2eNUDLl2RpzLgiPfn8u6qvd+u+P4/avf6Nty5VSkqDmpqMHr1/uHbtcu4FJL/Ppcf+eqhuffjTwOfmG7kq2NBNJ58dKAd++9U+Wv6RR3lHleofb3zYPEX20N3r/+2vh+q3t61QTKxfRduSdH+LZU7k9xk9clNv3fH8hsBPNbyUps1rE3Xq+YFJpN76t0fL5qVozJQq/XPR16qvdemeq/ZcYLr+kU0aNn6XeqQ16dlPVunfd2drzouM/raH3x4ohV9dy9gwFlsaY3pJul+BEaE6SZsk/UbSCklrJCVIqpL0mLX2n/vbXo/YDDu+5/c7qbXOU/oMv63TUTIvd/Y9SR2tZlBGuJsQVRI+dHb5bUczudnhbkLUMLucPeV5R2sqcnb5bUda6n9PlbY84m+a8xzqsac+c0a4m7FP/xr71KfW2ryuft2w3kFqrS2U9MMQi5w9lRcAAACATuPsaXQAAACAKGVl5A/jNNSRjCJBAAAAABHLGHOSMSbfGLPOGHP9XmImG2O+MMasMsYs2N82GQkCAAAAEJGMMW5Jj0g6XtJWScuNMbOstatbxPSU9Kikk6y1BcaY/f6qO0kQAAAAEKX8e/+5zQPFkZLWWWs3SJIx5kVJZ0hqOavPTyS9Zq0tkCRrbcn+Nko5HAAAAIBw8RhjPmnxd3Gr5bmStrR4vLX5uZYGSUo1xsw3xnxqjPnZ/l6UkSAAAAAA4eLdzxTZoYayWv/GT4wCP7kzVYFZpj82xiyx1q7d20ZJggAAAIAoZKVomB1uq6Q+LR73llQYIsZrra2WVG2MWShpuKS9JkGUwwEAAACIVMslDTTGDDDGxEk6V9KsVjFvSJpojIkxxiRJGivp631tlJEgAAAAABHJWttkjJkhaY4kt6SnrLWrjDHTm5c/bq392hjzjqQVkvyS/mGtXbmv7ZIEAQAAAFHKbw/8wi9r7WxJs1s993irx3dJuqu92zzwewUAAAAAvgWSIAAAAACOQjkcAAAAEI2siYbZ4ToFI0EAAAAAHIUkCAAAAICjkAQBAAAAcBTuCQIAAACikJXkF/cEhcJIEAAAAABHIQkCAAAA4CiUwwEAAABRiimyQ2MkCAAAAICjkAQBAAAAcBTK4QAAAIAoZEU53N4wEgQAAADAUUiCAAAAADgK5XAAAABAlKIcLjRGggAAAAA4CkkQAAAAAEehHA4AAACIQlaGcri9YCQIAAAAgKOQBAEAAABwFJIgAAAAAI7CPUEAAABAlPKLe4JCYSQIAAAAgKOQBAEAAABwlOgqh3O7ZXqkhLsVUSPp8Z7hbkLUqBnkD3cTosrWY2PD3YSoMnBZfLibAIRkGxrC3QTgwGbFFNl7wUgQAAAAAEchCQIAAADgKNFVDgcAAABAkmRFOdzeMBIEAAAAwFFIggAAAAA4CuVwAAAAQJSiHC40RoIAAAAAOApJEAAAAABHoRwOAAAAiEJWhnK4vWAkCAAAAICjkAQBAAAAcBSSIAAAAACOwj1BAAAAQJSy3BMUEiNBAAAAAByFJAgAAACAo1AOBwAAAEQpvyiHC4WRIAAAAACOQhIEAAAAwFEohwMAAACikLWSn9nhQmIkCAAAAICjkAQBAAAAcBTK4QAAAIAoxY+lhsZIEAAAAABHIQkCAAAA4CiUwwEAAABRyTA73F4wEgQAAADAUUiCAAAAADgK5XAAAABAlGJ2uNAYCQIAAADgKCRBAAAAAByFJAgAAACAo3BPEAAAABCFrMQU2XvBSBAAAAAARyEJAgAAAOAolMMBAAAA0chK1oa7EZGJkSAAAAAAjkISBAAAAMBRKIfrQKPHFuviX38ll0ua+9++mvnsoFYRVtN+/ZXyxpeovs6t++4YqfVre0qSzvzhep1w+mZZK23ekKL77hipxgZ3l+9DJDny8C26/Ecfy+WyeuujwXr+nRFBy/tm79D1P1+ggX29+sfrY/TSu8N2Lzt7ykqdNnGNjLH674dD9Mq8I7q49ZFnzNCtmvGTJXK7/Hpr4WC9MHt40PI+2Tt03a8WamC/Mj35Wp5efmdPn51zwkqdOilf1kobtqbpL09OVGOTcz8+JvYq0E1jFsltrF5ed6ieWDkyaPnUPhv1mxHLZa1Rk9+l2z+ZoE9LciRJvzj0S/1w4BpZK63dka7rFk1Wg9+5fSlJo48u07Tr18nltprzao5m/qNfqwiraTes05hJZaqvdeveG4do/dfddy91uaweePlTlRXH6Q+XDZPTjT6yWNMuXyGXy2rOW/008/nBrSKspl2xQmPGFqu+3q177xyt9d/0lCSdcfY6nXjaJhkjvfPf/nrjlUO6vP2RZPRRZZp23TdyuaU5r+Vo5pMhjs3rv9GYieWqr3Pp3psObXtsvviJykri9YcZHJt5kys1/U/b5HZZvf1Cul5+JKtVhNUlf9qmI6dUqq7WpXuu7Kt1K5MkSVfdU6Cxx1VqhzdG06YO6frGH8D8Yna4ULpsJMgYc6MxZpUxZoUx5gtjzAfN/11njNnZ/O8vjDETjDHzjTH5xpgvjTHLjTEjuqqd/18ul9UlV63QLdeM1yU/naJJx21Tn/6VQTF540rUq0+1Ljp3qh66a7guu+ZLSVK6p1ann7NBv/nVMbrsZ1PkclkdM3VbOHYjYriMX7/5ySJd++BJ+vkt52jqmPXql1MRFFNZHa8HX5wQlPxI0oBe5Tpt4hpNv/NM/epPZ2v8sALlZu7syuZHHJfx69fnL9b1952gX9x4tqaO3aB+vYL7s6o6Xg89Pz4o+ZEkT89qff+4VZr2xzP0y9+fLbfLasrYDV3Z/IjiMn79YexHunDeqTp51o90Wv91OqRHeVDMx9t76/Q3f6Dv/fcHumHxZN0+foEkKStxl342ZKXOeutsnfrmj+Qyfp02YF04diNiuFxWl974jW6ePkzTv3ekjjmlRH0Org6KyZtYrtx+tbrw5LF68A+DNOPmtUHLzzh/q7ZsSOrKZkcsl8vq0t98qZuvnaDpPz9Ox0zdqj79Wp2LxhYrt3e1LjzveD1490jNuOoLSVK/AZU68bRNunL6ZF32qyk6cnyReuXuCsNeRIbAsblWN186XNPPOFLHnFysPgft5dg8dawe/ONgzbgpP2j5GT/doi0bOTalQH9edvtW3fTTg3TRsUN07JkV6juwLihmzJQq5Q6o1wVHH6oHruujy+/cunvZ3JfTdON5B3V1sxHFuiQJMsaMl3SapFHW2mGSjpN0nrV2hKQLJX1orR3R/Le4ebXzrLXDJT0q6a6uaOd3MejQChVuTVZRYbKamlxa+F6uxh1dFBQzbuJ2vf9OH0lG+avSlNytUanpgQ8At9uvuHifXG6/4uN9KvMmhGEvIsehA0q1rSRF270pavK59f7yg3X08M1BMTuqErVmc4aafMGHcb+cHVq9IVP1DTHy+V36cm2OJo3c1IWtjzxDDipVYUmKtpc29+eyg3TUyIKgmB1Vicrf2LY/JcnttoqP88nl8is+rkllO5x7Uh+WXqLNVSnasitFjX633tp0sKb22RQUU9MUKzVfeUuMaQz8UEOzGJdfCe4muY1fiTFNKqlJ7rrGR6BBR1SqcEuiirYmqqnRpYWzMzX+WG9QzLgpXs2blSXJKH9FDyV3b1Kqp16SlJ5VpzGTyjTn1ZwwtD7yDDq0XIXbklW0vflc9H5vjT96e1DMuKO3a96c5nPR6uZzUVqd+vSrUv7qNNXXx8jvc2nllx5NmFQYnh2JAIOOqFRhQfOx2eTSwrez2h6bx3o1b1a29npsTizTnFd7haH1kWfwyBoVbopXUUG8mhpdmv9GqsafGHyBcvyJO/XeK2mSjNZ8lqzkHj6lZTZKklYu7aaqHc6ukEHH6qqRoBxJXmttvSRZa73W2vZ+sn4sKbfTWtZB0jPq5C1J3P3YW5qo9IzgKxzpnjqVtowpSVS6p1Zl3kS99uIhevrVuXr29Tmqro7V58szu6ztkcjTs1ol5d12Py7dkSxPavU+1thj47ZUDR+0XSnJdYqPa9K4oVuUmercq5mS5EmtUUn5ni/bpeVJ7e5P745kvfzOUL1094t69f4XVF0bp09W9e6spka87KRqba/ec2wW1XRTVlLbvjy+z0a9c8aL+vvUt3X94smSpOLabnpy1XAtOPtZLf7Bv1TVEKePtvfpqqZHpPSsenm3x+9+7C2OV3pWfVCMJ7NepUXBMZ7mmGnXr9NT9xwsv79r2hvp0j0hzkWe4HORx1MbfC4qTZQno1abN3bX0OFedU+pV3x8k/LGFcmTWdtlbY806Zn18hbtuSDZ7mMzs/nYvHadnrrvEI7NZunZjSotjN392Ls9Vp7sxqAYT4iY9FYx+HasJGtNRP+FS1clQXMl9THGrDXGPGqMOeZbrHuSpNc7p1kdx5gQ8w/a1jEh11S37g0ad3SRfvnD43X+mScqIaFJx56wpTOaecAI2VftnOJxc1Gqnn9nuO65crbuuuJtrduapia/s+cACdmd7fzg6ZZUrwkjC/Tja3+oc678sRLiG3XceAeXcIXoNhviyXe3DNBJb5yrSz84Ub8ZuVySlBJXr6l9NmnKa+fpqJnnKzGmSd8bsLbNuk7SrmMzVJ9boyOP8WpHeZzWre7eNsChQn12tvnoDNmf0pbNKZr5/CDdfs8i3XrXYm1c10O+JufeSxCyL1t3Zohzv5XRkZO82lEey7HZQvv6sx0xQAfpkrtxrbW7jDGjJU2UdKykl4wx11trn97Has8ZY5IluSWN2luQMeZiSRdLUkJM+D5svCWJQVfMPBm1bUravKUJymgZkxmIGZFXquLtSarcEbiatHhhjg49olwfzHXuFeLSimRlpu0ZvcnoWS3vjvaXDc1eNESzFwVunLzozOUqrXB2yVFpRZIy0/aMVmSk1bS7pG30YYUqKu2unVWBK8cfftpfQw8p1nsfO/OG6aLqZOUk7zk2s5N2qaRm7325vKSX+nb7QKnxtRqbXaitu1JUXh/oy7kFAzQqs0izNraeRMU5vMXx8uTsubruyapXeUlcm5iM7OCYspI4HX1CqcZN9mrMxDLFxvuVlOzTNX9erbuvP6zL2h9pvKUJbc5F5W3ORYnB56KMQEWCJM2d3V9zZ/eXJP38olXylibKqbzF8fJk7xlFCxyb8a1iEkIfm8eXaNyxZRoz8ePmY7NJ19y5Wnff4OBjc3usMnrtGdXx5DSqrDh2vzHlrWKAjtJll8ettT5r7Xxr7S2SZkg6ez+rnCdpgKTnJT2yj+0+Ya3Ns9bmxbnDd5/C2jU9ldunWlk51YqJ8WvScdu0dFF2UMzSj7I15aQtkqwGH16u6l2xqihLUGlxogYfXqH4+CZJVsNHe7Vlk7OvHq3ZlKHemZXKTq9UjNunKWPWa9GXfdu9fs/ugRN8ZtouTRy1Ue8tP7izmnpAWLMxQ7mZlcr2VAX688gNWvx5+/qzpDxZhx1covi4wPE56rBCbS7s2antjWRflWWqf/ed6t2tUrEun07tv17ztvQPiunbfaf+d/39sLRSxbp9qqhP0PbqbhqRUawEd6Mkq/E527R+Z2qX70MkWbuyu3r1rVVWbq1iYv2adEqJlnzgCYpZ+oFHU79XLMlq8LCdqt4VowpvvJ6+/yD9bOoEXXDCeP3lmsO0YmlPRydAkrR2Tap69d6lrOzmc9GUrVqyKPh+qaWLcjT1xOZz0WHlqq6OVUV5IFHq0TPwhT4js0YTJhZqwXvOLX1du7K7evVrPjZj/Jp0crGWzG99bKZr6veK1ObYfOBg/ey4CbrgpPH6y28P04plqY5OgCQp/4sk5Q6oV1afesXE+jX5jAotmZsSFLNkboqOO6dcktWQUdWqqXSrvIQk6Lsx8tvI/guXLhkJMsYMluS31n7T/NQISZv3vkaAtbbRGHOTpPXGmEOttV93YjO/E7/PpcfuHaZb7w1M6fzuW31VsDFFJ5+xUZL09hsDtPzjLOWNL9Y/Xnpv9xTZkpS/Ok2LPuilB55aIJ/PaMPaHnp7VutpOJ3F53fp/hcm6O7fvC2Xy2r2osHatD1N35u0WpI0a+FhSkup0d9ufF3JCQ3yW6Nzjlupn99yjmrq4nTr9HeVklyvJp9L9z9/lHbVxO/nFaOb3+/Sg8+N11+vfkcul9XbHw7SpsJUnT458JZ6c/6hSk2p0d9ueUNJiY2y1uic41fqFzeera83ZGrBJwP0xB9el89n9E1Buv67wLnTk/qsS39cdrSeOu4tuY3VK+sGa93ONP140CpJ0gtrD9dJfTfozIPXqsnvUp0vRr9ZeLwkoy+9WXpn80F6/bRX5fMbrS736KW1zv5i5Pe59NjtA3XbE4Epnef+J0cF65N1yg8DM2TOfjlXyxemacykMj359tLAZ+dNrad8xv/4fS49dv9w3Xb3osDPNczup4JNKTrle4Fz0exZA7R8SZbGjCvSk8+/q/p6t+77855iixtvXaqUlAY1NRk9ev9w7doVt7eXinp+n0uP3TFItz3+pVzuFsfmD5qPzZm5Wv5husZMKteTs5c0H5vO/WzcH7/P6JGbeuuO5zcE3usvpWnz2kSden5gsom3/u3RsnkpGjOlSv9c9LXqa12656o9F+uuf2STho3fpR5pTXr2k1X6993ZmvNierh2B1HA2C4otmwuhXtIUk9JTZLWSbrYWus1xkyWdI219rQW8fObn/uk+fHVkg6z1v5qX6/TIyHbTuh9fmfsgiPtOszZkzN0JFcjd8Z2pK3HcmWwIw38y5pwNyG6eJw9utehyneEuwVRxVdesf8gtMtS/3uqtOURf9Nc0sBedtD9+/z6HHZfnnbbp9bavK5+3a66J+hTSRP2smy+pPmtnpvc6vE9ndQ0AAAAAA7j7J8pBwAAAKIYM+yF5ux5gwEAAAA4DkkQAAAAAEehHA4AAACIUu39cXSnYSQIAAAAgKOQBAEAAABwFMrhAAAAgChkLeVwe8NIEAAAAABHIQkCAAAA4CiUwwEAAABRyk85XEiMBAEAAABwFJIgAAAAAI5CORwAAAAQpawNdwsiEyNBAAAAAByFJAgAAACAo1AOBwAAAEQpfiw1NEaCAAAAADgKSRAAAAAARyEJAgAAAOAoJEEAAABAFLIysjay/9rDGHOSMSbfGLPOGHN9iOWTjTE7jTFfNP/dvL9tMjECAAAAgIhkjHFLekTS8ZK2SlpujJllrV3dKvRDa+1p7d0uI0EAAAAAItWRktZZazdYaxskvSjpjO+6UZIgAAAAIErZCP+T5DHGfNLi7+JWu5AraUuLx1ubn2ttvDHmS2PM28aYw/fXL5TDAQAAAAgXr7U2bx/LQ904ZFs9/kxSP2vtLmPMKZJelzRwXy/KSBAAAACASLVVUp8Wj3tLKmwZYK2ttNbuav73bEmxxhjPvjbKSBAAAAAQjazaPQNbBFsuaaAxZoCkbZLOlfSTlgHGmGxJxdZaa4w5UoGBnrJ9bZQkCAAAAEBEstY2GWNmSJojyS3pKWvtKmPM9Oblj0s6R9IlxpgmSbWSzrXWti6ZC0ISBAAAACBiNZe4zW713OMt/v2wpIe/zTZJggAAAIBotc/xEOdiYgQAAAAAjkISBAAAAMBRKIcDAAAAolQUzA7XKRgJAgAAAOAoJEEAAAAAHIUkCAAAAICjcE8QAAAAEKX2/ZOhzhVdSVCTT7ZiZ7hbETW6X1Mf7iZEjabjy8LdhKiS7hkV7iZEFX9VVbibEFVcntRwNyF6NDaFuwUAohTlcAAAAAAcJbpGggAAAABIkqyYIntvGAkCAAAA4CgkQQAAAAAchXI4AAAAIBpZSZTDhcRIEAAAAABHIQkCAAAA4CiUwwEAAABRih9LDY2RIAAAAACOQhIEAAAAwFEohwMAAACiFeVwITESBAAAAMBRSIIAAAAAOApJEAAAAABH4Z4gAAAAICoZWWvC3YiIxEgQAAAAAEchCQIAAADgKJTDAQAAANGKKbJDYiQIAAAAgKOQBAEAAABwFMrhAAAAgGhkxexwe8FIEAAAAABHIQkCAAAA4CiUwwEAAADRitnhQmIkCAAAAICjkAQBAAAAcBTK4QAAAICoxexwoTASBAAAAMBRSIIAAAAAOArlcAAAAEC0Yna4kBgJAgAAAOAoJEEAAAAAHIUkCAAAAICjcE8QAAAAEK24JygkRoIAAAAAOApJEAAAAABHoRwOAAAAiEZWkjXhbkVEIgnqQKOPLtO069fJ5baa82qOZv6jX6sIq2k3rNOYSWWqr3Xr3huHaP3X3XcvdbmsHnj5U5UVx+kPlw3r2sZHIP/SOvkerpR8kuvUJLnP6xa8/PN6+W6qkLLdkiTXpAS5fx7oT9/MXfK/VStJMgfFyH1dT5l4Z38IjD5mpy65pUAut9U7L2bo5cdyWkVYXfKHAo05dqfqa12655oBWrcyWZ6cev32vo1KzWiU9Uuzn8/QG//MDss+RIpxgwt05fcWy+WymrVsiP79wcig5SeO/EbnH/uFJKmmPlZ/fW2i1m1PV1xMkx67ZJbiYnxyu6ze/2qA/jF3TBj2ILKMPmanLvnDFrnc0jsvevTyo62PL6tL/rhFY46tDBybV/fXupVJkqQr79qksVN3akdZjKYff3jXNz4CjT6yWNMuXyGXy2rOW/008/nBrSKspl2xQmPGFqu+3q177xyt9d/0lCSdcfY6nXjaJhkjvfPf/nrjlUO6vP2RZPTR5Zp244ZAX76SrZl/79MqwmrajRs0ZlK56utcuveGwVq/upti4/z667NfKjbOyu22+miuR8891Po7gfPkTa7U9D9tk9tl9fYL6Xr5kaxWEVaX/GmbjpxSqbpal+65su/u9/pV9xRo7HGV2uGN0bSpQ7q+8Yg6XVoOZ4y50RizyhizwhjzhTFmrDFmvjEm3xjzpTFmkTFmsDHmP83L1xljdjb/+wtjzISubO+34XJZXXrjN7p5+jBN/96ROuaUEvU5uDooJm9iuXL71erCk8fqwT8M0oyb1wYtP+P8rdqyIakrmx2xrM/K90ClYv6SpphnMuR/v1Z2U2ObOHNEnGKfzFDskxm7EyBb6pP/1RrF/M2j2KczJL9k36/t6l2IKC6X1WW3btZNPx+oi48bqsnfK1PfgcF9MubYneo1oF6/POYIPXBDf824bbMkye8z+vttfXTx1CP0mzMP0+k/K2mzrpO4jF/XnLVIVz55in589w91woh16p9ZERRTWN5dlzz2Pf303h/on++N0g3nLJQkNTS5NeNvp+v8+36g8+87W+MHb9XhfYvDsRsRw+Wyuuy2gsCxOfUwTf5eeYhjs1K9+tfrl5MO1wPX99WM2zfvXvbuzHTd9LOBXd3siOVyWV36my9187UTNP3nx+mYqVvVp19lUEze2GLl9q7WhecdrwfvHqkZV30hSeo3oFInnrZJV06frMt+NUVHji9Sr9xdYdiLyOByWV1683rdfNHhmn7aaB1zamnb8/qkisB5/cQ8PXjzQM24ZZ0kqbHB6IZfDNOMM0dpxlkjlXd0hQYPrwz1Mo7hcllddvtW3fTTg3TRsUN07JkV6juwLihmzJQq5Q6o1wVHH6oHruujy+/cunvZ3JfTdON5B3V1sxHFuiwJMsaMl3SapFHW2mGSjpO0pXnxedba4ZKekXSXtfYsa+0ISRdK+tBaO6L5b3FXtffbGnREpQq3JKpoa6KaGl1aODtT44/1BsWMm+LVvFlZkozyV/RQcvcmpXrqJUnpWXUaM6lMc15tfXXemeyaRplct0yvGJlYI9eURPkX1bd/Az4r1VvZJivVWcnj7rzGHgAGj6jW9k3xKtqSoKZGlxa8mabxxwd/cR9//A7NezVdktGaz7upW4pPaZkNKi+J07qVyZKk2mq3tqxLVHpWQxj2IjIc1rdEW70pKixPUZPPrXe/OESTDt8UFPPV5mxV1cZLklYWZCmjx/++SBrVNsRKkmLcfsW4/I6ftSdwbCaoqCC++dhM1fgTdgTFjD8h1LEZuCiycll3Ve1w9vu7pUGHlqtwW7KKtierqcmlhe/31vijtwfFjDt6u+bN6SPJKH91mpK7NSo1rU59+lUpf3Wa6utj5Pe5tPJLjyZMKgzPjkSAQcOqVFiQ0OK8nqHxU8uDYsZNLdO8NzIlGeV/maLklCalZjRIMqqrCRyXMTFW7hje64NH1qhwU/zu9/r8N1I1/sSdQTHjT9yp915Jk2S05rNkJfdo8V5f2o33+v+TtZH9Fy5dORKUI8lrra2XJGut11rb+tN1oaQDcuw9Pate3u3xux97i+OVnhX8pd2TWa/SouAYT3PMtOvX6al7Dpbf3zXtjXilPiljz4edyXAFnmvFrm5Q469K1XRtuezGxuZYt1w/6qamH5ao6ewSqZuRa0x8m3WdJD27QaXb43Y/9m6PU3p2Y9uYwj0xpUWxSs8KjsnqXa+DD69R/hfBpYlOkpFSo5Ide/a/ZGeyMnpU7zX+9CPXaMmavrsfu4xf/7ryFb19y7+07JtcrdrSuhzEWdKzG1VaGLv7sXd7XJvjLj27Mej4LS2KU3q2cxPxfUn31Mlbkrj7sbc0Ueme4KvtHk+tSlvFeDJqtXljdw0d7lX3lHrFxzcpb1yRPJnOHfVtc14vimt7Xs9qUGmrmP+d110uq4f+85meX7REny9OVf6KlK5peIRq+16PlafVecgTIqb1uQroKF2ZBM2V1McYs9YY86gx5pgQMadL+urbbNQYc7Ex5hNjzCcNtm7/K3SSUHeb2NY3ooUIstboyGO82lEep3Wru7cNwB6tu3NQrGJezFTskxlyfT9JTTcFRjZslV92UZ1iXsxQzKuZUq2Vf25NGBocOUIfn61iQh6fe/6dkOTTTY+v09/+1Ec1u5x7Nc6YEJet9nIla9TB2/S9MWv08Oyxu5/zW5d+dt85+t5tP9VhfUp1UFZ56JUdYn/HnSSZEB0czquHkSxkf7YJChFjpS2bUzTz+UG6/Z5FuvWuxdq4rod8Tc69l7I9n5uh3vz/i/H7jS4/a5R+NnmsBg2rUr+Be79Y4gTtea/v7dgEOkOXTYxgrd1ljBktaaKkYyW9ZIy5vnnxc8aYWkmbJF3+Lbf7hKQnJKlHTEbY3ire4nh5cvZcIfJk1au8JK5NTEZ2cExZSZyOPqFU4yZ7NWZimWLj/UpK9umaP6/W3dcf1mXtjzgZ7qCRH1vqb1PSZpL35PCucQny3Vcpu8Mv+0W9lOOW6blnwgS7qlE6oWuaHom8RXHKyNlz5dyT06Dy4tjgmO1xyui1JyYju1HlJYEYd4xfv398nT54PV2L3knrmkZHqJKdycrsuec+icwe1SqtTG4Td0hOmX73g4W68h8nq7Imoc3yXXXx+mxDjsYN2aINxc7tU+/2WGX02nOl15PTsPu42x3T6vjNyG5QeXHw5ysCvKUJQaM3noxalXsTWsUkKqNVTJk3MDI0d3Z/zZ3dX5L084tWyVuaKKdqc17PblB5SXybmIxWMWWtYqqrYvTVsh4aPbFCm79p+1nhFG3f640qa3MeahvT+lyF/wcSyZC6dGIEa63PWjvfWnuLpBmSzm5edF7zPT9nWmu37GMTEWvtyu7q1bdWWbm1ion1a9IpJVrygScoZukHHk39XrEkq8HDdqp6V4wqvPF6+v6D9LOpE3TBCeP1l2sO04qlPZ2dAEkyg2Nlt/pktzfJNlr536+Va0LwicWW+WSbLxH5v24IXC7qYaRMt+zqRtk6K2ut/J81SP2cPRFi/pfJ6jWgXll96hUT69cxp5drybupQTFL3uupqWeXSbIaMnKXqqvczYm81ZV/3aSCdYl67R/OnhVOkr7ekqk+np3KSa1UjNun40es04erg2d9yupZpTt/Nld/fOFYbfH23P18z+RadUsIfGGKj2nSmEO2aXNJTzlZ4Nisa3FsVmjJuz2DYpa8G+rY5ItRKGvXpKpX713Kyq5WTIxfk6Zs1ZJFwfeaLl2Uo6knbpFkNfiwclVXx6qiPJAo9egZOD4zMms0YWKhFrzXu6t3IWKs/aq7evWrU1ZuXfN5vVRL3g++YLH0/XRNPaNEktXg4ZWqrnKrojROKakNSu7eJEmKi/dpxPgd2rrBuQmlJOV/kaTcFuehyWdUaMnc4BLBJXNTdNw55ZKshoyqVk0l73V0ni77ZmiMGSzJb639pvmpEZI2SxraVW3oTH6fS4/dPlC3PRGYlnTuf3JUsD5Zp/xwmyRp9su5Wr4wTWMmlenJt5eqvs6t+25qPW0p/sfEGLl/naKm35ZLfsl1cqLMgFj53giUE7jPSJZ/QZ38s2okt2TijNw3p8oYI3NYnOwxCWq6qFRyG5mBsXKd5uxZ9/w+o0dv7qvb/5Uvl1ua+7JHm79J1CnnlUiSZj+XqWXv99CYY3fqqYVfqb7WpXuvGSBJOjxvl447u0wbv07UI7NXSpKevqu3ln/QM1y7E1Y+v0t3v360Hrhotlwuq/8uG6yNxWk6a9xqSdJ/lhymXx33mXok1em33/8osI7P6IIHz5YnpUa//9EHcrusjLGa9+XBWvS1s6fN9fuMHv19X93+72/kclvNfcmjzWsTdcpPSyVJs5/N0LL3UwLH5ocrm4/N/rvXv/6hDRo2vkopqU3699IVevbeXprzkmcvrxb9/D6XHrt/uG67e5FcLmnu7H4q2JSiU763UZI0e9YALV+SpTHjivTk8++qvt6t+/48avf6N966VCkpDWpqMnr0/uHatcu5I25+n9Fjtx6s255cGTivv5qlgnXJOuVHgYkmZr+Uo+ULUjVmUrmenPuJ6utcuu93gyRJaRmNuvrP+XK5rYyRPnzHo2Xz08O5O2Hn9xk9clNv3fF8YMrxuS+lafPaRJ16fmASqbf+7dGyeSkaM6VK/1z0dWA6/Kv23E95/SObNGz8LvVIa9Kzn6zSv+/O1pwXnd2n+G6M7aJiy+ZSuIck9ZTUJGmdpIslvSLpGmvtJyHWmdy87LT2vEaPmAw7vsdZHdRiuP7TtoQH/z9Nx5eFuwlRZccPR+0/CO3W86U2H7/4DlwD+u4/CO1T7N1/DNrNV1UV7iZEjaX+91RpyyP+prn4/r1t9k2/Dncz9qngoms/tdbmdfXrduU9QZ9KCvU7P5P3sc58SfM7p0UAAAAAnKhL7wkCAAAAgHAjCQIAAADgKM6eMgsAAACIYqF+3g6MBAEAAABwGJIgAAAAAI5CORwAAAAQjWzzH9pgJAgAAACAo5AEAQAAAHAUyuEAAACAqGQka8LdiIjESBAAAAAARyEJAgAAAOAolMMBAAAA0YrZ4UJiJAgAAACAo5AEAQAAAHCUvZbDGWMe0j4G0Ky1V3RKiwAAAAB0DMrhQtrXPUGfdFkrAAAAAKCL7DUJstY+0/KxMSbZWlvd+U0CAAAAgM6z33uCjDHjjTGrJX3d/Hi4MebRTm8ZAAAAgO/GRvhfmLRnYoT7JZ0oqUySrLVfSprUiW0CAAAAgE7TrtnhrLVbWj3l64S2AAAAAECna8+PpW4xxkyQZI0xcZKuUHNpHAAAAAAcaNqTBE2X9ICkXEnbJM2RdFlnNgoAAADAd2QlWRPuVkSk/SZB1lqvpPO6oC0AAAAA0OnaMzvcQcaYN40xpcaYEmPMG8aYg7qicQAAAADQ0dozMcLzkl6WlCOpl6SZkl7ozEYBAAAA+O6Mjey/cGlPEmSstf+21jY1/z2rsM7qDQAAAAD/f3u9J8gYk9b8zw+MMddLelGB5OdHkt7qgrYBAAAAQIfb18QInyqQ9PxvSolpLZZZSbd2VqMAAAAAdADqt0LaaxJkrR3QlQ0BAAAAgK7Qnt8JkjFmqKTDJCX87zlr7b86q1EAAAAA0Fn2mwQZY26RNFmBJGi2pJMlfSSJJAgAAADAAac9s8OdI2mqpCJr7QWShkuK79RWAQAAAEAnaU8SVGut9UtqMsakSCqRxI+lAgAAADggteeeoE+MMT0l/V2BGeN2SVrWmY0CAAAA8N2F8wdJI9l+kyBr7aXN/3zcGPOOpBRr7YrObRYAAAAAdI59/VjqqH0ts9Z+1jlNAgAAAIDOs6+RoHv2scxKmtLBbfnO/Enxqh/J7Uodxd5h9h+EdklIrA53E6JK8WRfuJsQVXquPTTcTYgu+ZvD3YKoYZuawt2E6GKpi8KByRhzkqQHJLkl/cNa++e9xI2RtETSj6y1r+xrm/v6sdRjv0NbAQAAAISbPbAvahtj3JIekXS8pK2SlhtjZllrV4eI+4ukOe3ZbntmhwMAAACAcDhS0jpr7QZrbYOkFyWdESLuckmvKjCT9X6RBAEAAAAIF48x5pMWfxe3Wp4raUuLx1ubn9vNGJMr6SxJj7f3RdszRTYAAACAA41t/otsXmtt3j6Wh6rna71X90u6zlrrM6Z95X/7TYJMYEvnSTrIWvsnY0xfSdnWWn4rCAAAAEBn2iqpT4vHvSUVtorJk/RicwLkkXSKMabJWvv63jbannK4RyWNl/Tj5sdVCtycBAAAAACdabmkgcaYAcaYOEnnSprVMsBaO8Ba299a21/SK5Iu3VcCJLWvHG6stXaUMebz5hepaG4AAAAAgEgW+eVw+2StbTLGzFBg1je3pKestauMMdObl7f7PqCW2pMENTZPOWclyRiTIcn//3kxAAAAAPg2rLWzJc1u9VzI5Mda+4v2bLM95XAPSvqPpExjzO2SPpJ0R3s2DgAAAACRZr8jQdba54wxn0qaqsDsDGdaa7/u9JYBAAAA+E7MAV4O11naMztcX0k1kt5s+Zy1tqAzGwYAAAAAnaE99wS9pcD9QEZSgqQBkvIlHd6J7QIAAACATtGecrgjWj42xoySNK3TWgQAAACgY1AOF1J7JkYIYq39TNKYTmgLAAAAAHS69twTdFWLhy5JoySVdlqLAAAAAKATteeeoO4t/t2kwD1Cr3ZOcwAAAACgc+0zCWr+kdRu1trfdlF7AAAAAHQU7gkKaa/3BBljYqy1PgXK3wAAAAAgKuxrJGiZAgnQF8aYWZJmSqr+30Jr7Wud3DYAAAAA6HDtuScoTVKZpCna83tBVhJJEAAAABChjA38oa19JUGZzTPDrdSe5Od/6E4AAAAAB6R9JUFuSd0UnPz8D0kQAAAAgAPSvpKg7dbaP3VZSwAAAAB0LBtqPAN7nR1OoUeAAAAAAOCAtq8kaGqXtQIAAAAAushey+GsteVd2RAAAAAAHYw7+UPa10gQAAAAAEQdkiAAAAAAjtKeH0sFAAAAcADix1JDYyQIAAAAgKOQBAEAAABwFMrhAAAAgGhFOVxIjAQBAAAAcBSSIAAAAACOQhIEAAAAwFG4JwgAAACIRpYpsveGkSAAAAAAjsJIUAcaM2yrLjt/iVwuq9nzB+nFN4cHLe+Ts0PXXvyhDulfpqdmjtbM2UfsXpacVK9rLlyk/r0rZK10998navW6zK7ehYgy5oitmvGTJXK5/Jq9cLBeeCtEf/5qoQb2K9NTr+bp5XcC/dkne4d+f+kHu+NyMqr09H9G6dW5Q7u0/ZFm9NHlmnbjBrlcVnNeydbMv/dpFWE17cYNGjOpXPV1Lt17w2CtX91NsXF+/fXZLxUbZ+V2W30016PnHuoXln2IFEkrdyrzxQLJb7VzYoYqTs4JGRe/cZf63vm1tk87WLtGp0mSBlz/pfwJblkjyW1UcNPhXdjyyDR6ZKEuuWi5XC6rd949RC+/Gvxe7Z27U1df8bEOPrhczzw7Qq++fpgkKTbWp7vvmKvYWJ/cbqsPF/fVsy8MD/USjsJ7veOMnlSh6Tdtkstt9c7LWZr5t9xWEVbTf79JYyZXqL7WrXuuO1jrV3WTJ6de19y1TqmeRlkrvf1ilt54JvTnhJPkTa7U9FsL5XZZvf1Cml5+OKtVhNUltxbqyCmVqqt16Z4r+2jdV0ntXBf4djo1CTLG3CjpJ5J8kvySpkn6i6QcSXWSdkn6pbU23xgzX9I11tpPjDGbJH1qrT27eTvnSDrNWvuLzmzvd+Eyfl3x84917Z9PVGl5sh790yx9/GlfbS5M3R1TVR2vh/89TkeN3txm/RnnL9XyFbn644NTFOP2KT6+qSubH3Fcxq9fn79Yv73rJJWWJ+uxW2Zp8eet+nNXvB5+bryOGhXcn1uKeurim8/avZ2X739RH33q7BO5y2V16c3rdeMvh8pbHK/7Z36hJe+nacv65N0xeZMqlNuvVheemKfBw6s045Z1uvJHI9TYYHTDL4aprsYtd4xfdz+3Qp8sTFX+lylh3KMw8ltlPr9Z264cpMbUOPW7fbWqh/dUQ6/ENnEZr25VzeE92mxiy9WD5e8e20UNjmwul1+XTVum390yVd6yJD1499tasqy3Crb03B1TtStej/09T+PHbQ1at7HRpet+f5zq6mLldvt1z5/n6JNPe2nN2owu3ovIwXu947hcVpf9YaN+9/PD5C2K0wOvfaWl81JVsC5pd8yYY3aoV/86/WrqSA0ZsUsz/rhRV55zhHxNRn+/s5/Wr+qmxGSfHnx9hT5f1CNoXadxuawuu2Obbjj3IHm3x+qh2d9oyZweKvgmYXfMmClVyh1QrwuOGqIho2p0+Z3b9OvTBrZrXewD5XAhdVo5nDFmvKTTJI2y1g6TdJykLc2Lz7PWDpf0jKS79rKJPGPMAXOJdMjBXm0rTtH20hQ1+dz6YMlBmjC6IChmR2Wi8jdkqMkX3O1JiQ06YnCRZs8fJElq8rlVXRPfZW2PREMOKg3qz/eXHqQJI1v1Z1Wi8jdmyOfb+2E86rBCFZZ0V3FZ985uckQbNKxKhQUJKtqaqKZGlxbOztD4qeVBMeOmlmneG5mSjPK/TFFySpNSMxokGdXVuCVJMTFW7hi/oz9QEzZWqzEjXo0ZCVKMS5Vj0pT8RUWbuJ7vF6tqdKqaujPgvi+DB5Zpe1F3FRV3V1OTWws+7K/xRwYnOzt3JmjtOo98TabV2kZ1dYFkMsbtV4zbL6vWMc7Ce73jDBq+S4WbE1S0JUFNjS4teMujcccFv9fHHVeuef/JkGS05ovu6tbclxWlcVq/qpskqbbarS3rE5We1RCGvYgcg0fWqHBTnIoK4tXU6NL8N3pq/Ik7g2LGn7hT772SKslozWfJSu7hU1pmY7vWBb6tzrwnKEeS11pbL0nWWq+1trBVzEJJh+xl/bsl/a4T29ehPKnVKi3fc6WttDxZntSadq2bk1GlnVUJuvbiD/X4ba/r6gs/UkJ8Y2c19YDgSa1RSYv+9FYkKSO1+ltv59ixG/T+koM7smkHpPSsenm370msvUVxSs+qD4rxZDWotFWMpznG5bJ66D+f6flFS/T54lTlr3DmlWFJitnRoKa0uN2Pm1LjFLsj+P0aU9Ggbp/v0M5jQpe09r5/rfreuko9FpZ0alsPBOnpNSr17rk67i1LUnp6+z47pcBI0iP3vaUX//WKPvsiR/lrPZ3RzAMG7/WOE6qfWvdlelaDvNvjgmI8rZKdzNw6HXxYtfK/7Na5DY5w6dmNKi1s0VfbY+XJCf7s9GQ3qrRwzyi5tzBW6dmN7VoX+LY6MwmaK6mPMWatMeZRY8wxIWJOl/TVXtZ/WdIoY8zekiRJkjHmYmPMJ8aYTxobv/2X5A4T4uJjey+gud1WA/uXada8IZp+05mqq4/Ruaev6NDmHWhMyP78dld4Y9w+TRhZoAXLB3RQqw5coXrOtjlA2x6x/4vx+40uP2uUfjZ5rAYNq1K/gWF8r4VbiDd266cyXiqQ9/u9JVfbni+4/lAV/P5wbfv1IPX8oESJa6s6p50HiNDHZvvf636/S5ddeap++qvva/CgMvXru6PD2nYg4r3egUJ2ZvCTIc9VLbo3Icmnmx5Zq7/d1l81u5w9Kry/vgoEhY5p17rYOxvhf2HSaUmQtXaXpNGSLpZUKuklY8wvmhc/Z4z5QtJRkq7ZyyZ8CpTK3bCf13nCWptnrc2LjU3eV2in8pYnKyNtz8kiI61aZRXtq/0tLU9SaXmy1qwPXDVeuKy/BvYv65R2HihKy5OU2aI/Pak18razP//nyGFb9c3mdFVUJu4/OMp5i+PlydlzBdOT3aDykvg2MRmtYspaxVRXxeirZT00emLb8i+naEqNU0z5niu9MRUNauoZfH9PwqZq5fx9vQZc/6W6f1ahzOc2K/nzQJ/5egauZvpSYrVrZKoSNu7qusZHIG9ZkjI8e0Z+POk1Ki//9u/Z6uo4rfgqS3mjWhccOAvv9Y7jLYoL0U9xbWI8OQ0hY9wxft30SL4+mOXR4rnpXdPoCObdHquMXi36KqdRZUWxIWL2jPB4ejWqvDi2XesC31anTpFtrfVZa+dba2+RNEPS2c2LzrPWjrDWnmmt3bKPTfxb0iRJfTuznR1hzQaPcrN3KjujSjFun44dt0GLP2tfsyt2BpKg3jmB+taRhxdq87aendjayLdmY4ZysyqV7Qn055SxG/Tx59/uMJgybj2lcM3WftVdvfrVKSu3TjGxfk06pVRL3k8Liln6frqmnlEiyWrw8EpVV7lVURqnlNQGJXcPTNQRF+/TiPE7tHWDcxPLuv7Jii2pV0xpvdTkV8ryclUPTw2K2fjn4bv/qkalquS8fqoemSpT75Op80mSTL1PSat3qj7XuTdKS1L+N+nqlVOlrMxdionx6ZiJm7RkWe92rdsjpU7JyYEvRnFxTRo5fLu2bHVu+ZbEe70jrV3RLdCXvQN9ecypXi2ZF/xeXzIvTVPPKpVkNWRE1e6+lKx+c+d6bVmXqP881Sss7Y80+V8kKXdAg7L61Csm1q/JZ+zQkrnBE8csmdtDx51TIclqyKhq1VS6VF4S2651gW+r08ZmjTGDJfmttd80PzVC0mZJ7Z6n2FrbaIy5T9L1kt7v8EZ2IL/fpYeeGa+/XDtHLpfV2wsGavO2VJ02ZY0k6b/vD1Fqjxo9dussJSU2yvqNzj5plX553fdVUxunh54Zp99dMl+xMX5tL+muvz4xMcx7FF5+v0sPPTtef7nmncB0mB8O0qbCVJ1+7NeSpDc/OFSpPWr0+C1vBPrTGp19wkpd8LuzVVMXp/i4Jo0+vFD3PX10mPckMvh9Ro/derBue3KlXC6rua9mqWBdsk750XZJ0uyXcrR8QarGTCrXk3M/UX2dS/f9LjBRR1pGo67+c75cbitjpA/f8WjZfAdf1XQblf6kr3rfny9ZqfIojxpyE9VjfuD+np2T9z61fUxlo3o9ui7wwGdVNTZdNUOdfSL3+1169Ikxuv0P8wLH5ryDtXlLT51y0lpJ0ux3Bim1Z60evOdtJSU1yvqlM09fo2kzTlNaaq2u/s1iuV1WxlgtXNRPyz5pXwIVrXivdxy/z+ixPw7Qbf/8Wm631dyZmSr4Jkmn/LhIkjT7hWwtn99TYyZX6Kn3P1ddrUv3XReo4D98dJWOO8urjWuS9PCsLyVJz9zTV8sXpO719aKd32f0yI25uuP5DXK5pbkvpmnz2gSder5XkvTWvz1aNq+7xkyt1D8Xr1F98xTZ+1oX7cOPpYZmbCcVVRpjRkt6SFJPSU2S1ilQGveKmqfCbhU/X8FTZOdZa73GmHhJGyXN3d8U2d1Tetu8I2d08J44l41x9ixLHSlhydpwNyGqfH3P4HA3IaoMfqIu3E2IKq78tj+DgP8f2+Tsn4voaP6a9k86gn1bauep0pZH/BelhNw+tt/0q8LdjH1ae/NVn1pr87r6dTttJMha+6mkCSEWTd5L/OQW/+7f4t/1khhLBgAAANAhOvWeIAAAAACINCRBAAAAAByFJAgAAACAo5AEAQAAAHAUZ/98MQAAABDNmCI7JEaCAAAAADgKSRAAAAAAR6EcDgAAAIhGVjKUw4XESBAAAAAARyEJAgAAAOAolMMBAAAA0YpyuJAYCQIAAADgKCRBAAAAAByFcjgAAAAgWlEOFxIjQQAAAAAchSQIAAAAgKNQDgcAAABEISN+LHVvGAkCAAAA4CgkQQAAAAAchXI4AAAAIFpRDhcSI0EAAAAAHIUkCAAAAICjkAQBAAAAcBTuCQIAAACikWWK7L1hJAgAAACAo5AEAQAAAHAUyuEAAACAaEU5XEiMBAEAAABwFJIgAAAAAI5CORwAAAAQrSiHC4mRIAAAAACOQhIEAAAAwFEohwMAAACiFD+WGhojQQAAAAAchSQIAAAAgKNQDgcAAABEK8rhQoqqJMhU1Sjm/U/D3QygDV+4GxBlBl20PNxNiCqcHzvW7MIvwt2EqHHKkEnhbkJUaZoyOtxNiBp22cfhbgK+I8rhAAAAADgKSRAAAAAAR4mqcjgAAAAAzayoed4LRoIAAAAAOApJEAAAAABHoRwOAAAAiFKGcriQGAkCAAAA4CgkQQAAAAAchXI4AAAAIFpRDhcSI0EAAAAAHIUkCAAAAICjUA4HAAAARClmhwuNkSAAAAAAjkISBAAAAMBRKIcDAAAAohXlcCExEgQAAADAUUiCAAAAAEQsY8xJxph8Y8w6Y8z1IZafYYxZYYz5whjziTHm6P1tk3I4AAAAABHJGOOW9Iik4yVtlbTcGDPLWru6Rdg8SbOstdYYM0zSy5KG7Gu7JEEAAABANLKKhnuCjpS0zlq7QZKMMS9KOkPS7iTIWrurRXyy2rHXlMMBAAAACBdPcwnb//4ubrU8V9KWFo+3Nj8XxBhzljFmjaS3JP1yfy/KSBAAAACAcPFaa/P2sdyEeK7NSI+19j+S/mOMmSTpVknH7etFSYIAAACAKGQUOoM4wGyV1KfF496SCvcWbK1daIw52BjjsdZ69xZHORwAAACASLVc0kBjzABjTJykcyXNahlgjDnEGGOa/z1KUpyksn1tlJEgAAAAABHJWttkjJkhaY4kt6SnrLWrjDHTm5c/LulsST8zxjRKqpX0I2vtPidHIAkCAAAAotWBPzucrLWzJc1u9dzjLf79F0l/+TbbpBwOAAAAgKOQBAEAAABwFMrhAAAAgChloqAcrjMwEgQAAADAUUiCAAAAADgK5XAAAABAtKIcLiRGggAAAAA4CkkQAAAAAEehHA4AAACIVpTDhcRIEAAAAABHIQkCAAAA4CiUw3WgvMmVmn5rodwuq7dfSNPLD2e1irC65NZCHTmlUnW1Lt1zZR+t+yqpnes6D/3ZsejPjkNfdiz6s2Mt/6C7Hv99rnx+o5N/XKYfXV4StLy60qW/zOinksI4+Zqkc6aX6sRzyyVJ91zZR0vfS1FPT5Oe+CA/HM2PKKOPLte0GzfI5bKa80q2Zv69T6sIq2k3btCYSeWqr3Pp3hsGa/3qboqN8+uvz36p2Dgrt9vqo7kePfdQv7DsQyQZM2yrLjt/iVwuq9nzB+nFN4cHLe+Ts0PXXvyhDulfpqdmjtbM2UfsXpacVK9rLlyk/r0rZK10998navW6zK7eBUSRsIwEGWN8xpgvjDErjTEzjTFJzc/vahGztDmmwBhT2vzvL4wx/cPR5v1xuawuu2ObbjpvgC6aPFjHnrFDfQfWBcWMmVKl3AH1uuCoIXrg2t66/M5t7V7XaejPjkV/dhz6smPRnx3L55Me+V1v3fbcBv19/hp98EaqNq+ND4qZ9bRHfQfV6fH38nXXq+v0xJ96qbHBSJJO+FG5bn9uQziaHnFcLqtLb16vmy86XNNPG61jTi1Vn4Org2LyJlUot1+tLjwxTw/ePFAzblknSWpsMLrhF8M048xRmnHWSOUdXaHBwyvDsRsRw2X8uuLnH+uGv56gX177fU0Zt0H9elUExVRVx+vhf4/TzNlD26w/4/ylWr4iVxdce7Yu/t2Z2lzYo6uafmCzkonwv3AJVzlcrbV2hLV2qKQGSdNbB1hrx1prR0i6WdJLzfEjrLWburap7TN4ZI0KN8WpqCBeTY0uzX+jp8afuDMoZvyJO/XeK6mSjNZ8lqzkHj6lZTa2a12noT87Fv3ZcejLjkV/dqz8z5PUq3+9cvo1KDbOavIZFfp4TvCXRWOk2mq3rJXqqt3q3tMnd0zgm8gR46rVPdUXjqZHnEHDqlRYkKCirYlqanRp4ewMjZ9aHhQzbmqZ5r2RKcko/8sUJac0KTWjQZJRXY1bkhQTY+WO8Tv+5vQhB3u1rThF20tT1ORz64MlB2nC6IKgmB2VicrfkKEmX/DX06TEBh0xuEiz5w+SJDX53KquCU7ugW8rEu4J+lDSIeFuxHeVnt2o0sK43Y+922PlyWkMivFkN6q0MHZPTGGs0rMb27Wu09CfHYv+7Dj0ZceiPztWWVGsMnrt6QNPTqO822ODYr53gVcF38TrJyMP17Qpg3XJn7bJFQnfBiJMela9vNv3fNH2FsUpPas+KMaT1aDSVjGe5hiXy+qh/3ym5xct0eeLU5W/IqVrGh6hPKnVKi1P3v24tDxZntSadq2bk1GlnVUJuvbiD/X4ba/r6gs/UkK8s9/r+O7C+rFnjImRdLKkr8LZjo5gTNvnbOurPnuJade6DkN/diz6s+PQlx2L/uxYofa/dT99Or+7Dj68Vs9/vkqPvpuvR27MVXUVWVBrIQ6vEP3btsP/F+P3G11+1ij9bPJYDRpWpX4Dq9vEOkqo92s7V3W7rQb2L9OseUM0/aYzVVcfo3NPX9GhzYtqNsL/wiRcn3qJxpgvJH0iqUDSk//fDRljLjbGfGKM+aRR9ftfoZN4t8cqo1fD7seenEaVFcWGiGlxha5Xo8qLY9u1rtPQnx2L/uw49GXHoj87lien1ajZ9sCoWUtzX0rTUafslDFS7oAGZfdt0JZ1CV3d1IjnLY6XJ2fP9wpPdoPKS+LbxGS0iilrFVNdFaOvlvXQ6InB9784jbc8WRlpexLBjLRqlVUktWvd0vIklZYna836wEQIC5f118D+ZZ3STjhHuO8JGmGtvdxa27D/VUKz1j5hrc2z1ubFKnz1oflfJCl3QIOy+tQrJtavyWfs0JK5wXXYS+b20HHnVEiyGjKqWjWVLpWXxLZrXaehPzsW/dlx6MuORX92rMEjarRtY7yKCuLU2GA0/41UjTsh+Ib8jNxGffFhd0lSRWmMtq6PV07f8F1EjFRrv+quXv3qlJVbp5hYvyadUqol76cFxSx9P11TzyiRZDV4eKWqq9yqKI1TSmqDkrs3SZLi4n0aMX6Htm5IDMNeRI41GzzKzd6p7Iwqxbh9OnbcBi3+rG+71q3YGUiCeucE7vkbeXihNm/r2YmthRMwRXYH8fuMHrkxV3c8v0EutzT3xTRtXpugU8/3SpLe+rdHy+Z115iplfrn4jWqb57mdV/rOhn92bHoz45DX3Ys+rNjuWOky27fqt/95CD5fUYnnFuu/oPr9N9/pUuSTvtZmc77TZHu/k1fTZsyWNZKv7pxu3qkByZDuPOSflrxcTftLI/ReaMP0/lXF+mkn5Tv6yWjlt9n9NitB+u2J1fK5bKa+2qWCtYl65QfbZckzX4pR8sXpGrMpHI9OfcT1de5dN/vAjfup2U06uo/58vltjJG+vAdj5bNTw/n7oSd3+/SQ8+M11+unSOXy+rtBQO1eVuqTpuyRpL03/eHKLVHjR67dZaSEhtl/UZnn7RKv7zu+6qpjdNDz4zT7y6Zr9gYv7aXdNdfn5gY5j06cIRzBrZIZmwYCqiNMbustd1CPO+XVNjiqXsllUvKs9bO2N92U0yaHWumdlxDAQD4luYUfhHuJkSNU4ZMCncTokp93sBwNyFqfLLsYVVVbg1161hEScrsYwf/4KpwN2Ofvnj0qk+ttXld/bphGQkKlQA1P7+38rynO681AAAAAJyEcjgAAAAgWlEOFxJzYgIAAABwFJIgAAAAAI5CORwAAAAQpZgdLjRGggAAAAA4CkkQAAAAAEchCQIAAADgKNwTBAAAAEQjK6bI3gtGggAAAAA4CkkQAAAAAEehHA4AAACIVpTDhcRIEAAAAABHIQkCAAAA4CiUwwEAAABRyEgylMOFxEgQAAAAAEchCQIAAADgKJTDAQAAANGKcriQGAkCAAAA4CgkQQAAAAAchXI4AAAAIEoZSz1cKIwEAQAAAHAUkiAAAAAAjkI5HAAAABCNrJgdbi8YCQIAAADgKCRBAAAAAByFJAgAAACAo3BPEAAAABClDPcEhcRIEAAAAABHIQkCAAAA4CiUwwEAAADRinK4kBgJAgAAAOAoJEEAAAAAHIVyOAAAACBKMTtcaIwEAQAAAHAUkiAAAAAAjkI5HAAAABCtKIcLKbqSoO5J8o0ZFe5WRI34b4rD3YToERcb7hZEFX9SQribEFX8K9eEuwlR5ZRjzwl3E6LG1/f2DHcTosqhNxaEuwlRw1XbEO4m4DuiHA4AAACAo0TXSBAAAACAAMvscHvDSBAAAAAARyEJAgAAAOAoJEEAAAAAHIV7ggAAAIBoxT1BITESBAAAAMBRSIIAAAAAOArlcAAAAEAUMmKK7L1hJAgAAACAo5AEAQAAAHAUyuEAAACAaGWphwuFkSAAAAAAjkISBAAAAMBRKIcDAAAAohSzw4XGSBAAAAAARyEJAgAAAOAolMMBAAAA0cg2/6ENRoIAAAAAOApJEAAAAABHIQkCAAAA4CjcEwQAAABEKeMPdwsiEyNBAAAAAByFJAgAAACAo1AOBwAAAEQrpsgOiZEgAAAAAI5CEgQAAADAUSiHAwAAAKKUoRwuJEaCAAAAADgKSRAAAAAAR6EcDgAAAIhGVpKlHi4URoIAAAAAOApJEAAAAABHoRwOAAAAiFLMDhcaI0EAAAAAIpYx5iRjTL4xZp0x5voQy88zxqxo/ltsjBm+v22SBAEAAACISMYYt6RHJJ0s6TBJPzbGHNYqbKOkY6y1wyTdKumJ/W2XcjgAAAAgWh345XBHSlpnrd0gScaYFyWdIWn1/wKstYtbxC+R1Ht/GyUJ6kBjhm3Vpecvlctl9fb8QXrxzWFBy/vk7NBvp32kQ/qX6Z8vj9LM2UfsXpacVK+rL1qk/r13yFrp7ieO1tfrMrt6FyLK6HGluvjq1XK5rOa+0Ucz/3VwqwiraVevVt6EUtXXuXXfn4ZpfX4P5fbdpevv+Hx3VHavWj37xEC98eKArt2BCDN6bLEu/vVXcrmkuf/tq5nPDmoVYTXt118pb3xJoD/vGKn1a3tKks784XqdcPpmWStt3pCi++4YqcYGd5fvQ6QYnbdd0y/5XC6X1TvvHKSZLx0atLx3n0pddfUyHXJIhZ55+gi9+sqQ3cuuvGqZjhxXqB074nXJxSd3ddMjUt7kSk2/tVBul9XbL6Tp5YezWkVYXXJroY6cUqm6WpfuubKP1n2V1M51nWf0mCJNm/GlXG6rOW8N0MwXBreKsJp2+ZcaM7ZI9XVu3fuXPK3/JlWSdMbZ3+jEUzfJGKt3/jtAb7w6sOt3IIIkrdypzBcKJL+0c6JHFafkhIyL31itvnd8re3TDtKuvDRJ0oDrVsif4JZ1SXIZFfy+9YVr5xk9watpv82Xy2U15/Vczfxn6/Oy1bRr8zXmKG/g2LzlcK1fkyJJ+udbH6q2OkY+v+T3Gf36vHFdvwMIl1xJW1o83ipp7D7ifyXp7f1tNCKSIGOMT9JXCrRno6TzJc2RFC8pTVKipG3N4WdaazeFoZn75DJ+Xf6LJbruzhNVWp6kR259U4s/66uCbT13x1RVx+uRf43VhNEFbda/7PylWv5lb/3pgSmKcfsUH9/Uha2PPC6X1SXXrtJNM46UtyRB9z2zSEs+zNSWjd13x+RNKFWvPjW66OxjNHjoDl123Upd9cujtK2gmy7/6cTd2/nXW/O0eH52uHYlIrhcVpdctUI3XTlB3pJE3fePBVryUba2bErZHZM3rkS9+lTronOnavDhFbrsmi911cXHKN1Tq9PP2aBLfjpFDQ1uXf+n5Tpm6ja993bfMO5R+Lhcfl0241P97vrJ8noT9cBD72rpx71UUNBjd0xVVZwef3Skxk/Y1mb9d9/tr1mzDtE11y7tymZHLJfL6rI7tumGcw+Sd3usHpr9jZbM6aGCbxJ2x4yZUqXcAfW64KghGjKqRpffuU2/Pm1gu9Z1GpfL6tJff6Ebf3u0vKVJuv/x97VkcY62bG7xXh9bpNzcXbrwpydq8KHlmnHl57ry0inq13+nTjx1k6685Fg1Nrp0618/0vIl2Src1n0frxjF/FaZzxVo21WD1Jgaq363fa3qET3V0CuxTVzGq1tVc3hKm01suWaQ/N1ju6jBkc3lsrr0+jW68ZJR8hYn6P7nlmrJggxt2dBtd0ze0V7l9q3RhWccpcFH7NSM332tK3+257vu9RePVuWOuHA0H53LY4z5pMXjJ6y1LcvZTIh1Qo5vGWOOVSAJOnp/Lxop9wTVWmtHWGuHSiqXdJm1dqy1doSkmyW91Lx8RCQmQJI0+GCvCou7a3tpdzX53Jq/5CAd1SrZ2VGZqPwNGfL5grs9KbFBRwwp1tvzA1fcmnxuVdfEd1nbI9Ggw3eocGuSigqT1NTk0sK5ORo3qTgoZtykYr0/O1eSUf7KVCV3b1Jqel1QzPAxXm3fmqzSolYnLYcZdGiFCrcmq6gwOdCf7+Vq3NFFQTHjJm7X++/0kWSUvypNyd0ad/en2+1XXLxPLrdf8fE+lXmd+yVz0OByFRZ2V1FRNzU1ubVgQV+Na5Xs7NyRoLVr09Xka/sRu/KrTFVVOfv93dLgkTUq3BSnooJ4NTW6NP+Nnhp/4s6gmPEn7tR7r6RKMlrzWbKSe/iUltnYrnWdZtCQchUWJqtoe7fAe/393hp/VGFQzLijtmve3H6SjPK/TldycqNS02rVp1+V8lenqb4+Rn6/Syu/zNCEiYWhX8gBEjZWqzEzXo0Z8VKMS5VHpin5ix1t4nrOK1HVqFQ1pZDs7MugoTtVuCVJRduaz+tzsjV+cmlQzLhjSjXvvzmSjPK/6hk4r3vqw9NgdCWvtTavxV/r+3m2SurT4nFvSW0+nIwxwyT9Q9IZ1tqy/b1opCRBLX2swLDXAcWTVqOSsuTdj0vLk5SeWt2udXMyq7SzKkG/nfaRHr/9DV114UdKiG/srKYeENIz6uQt3vNF21uSqPSM4A/C9Mw6lQbFJCg9MzgJmnT8di2YG7p8wUnSM+rkLdmTCHpLE5WeEdxX6Z46lbaMKUlUuqdWZd5EvfbiIXr61bl69vU5qq6O1efLnVuq6fHUqrS0ZV8mKT29NowtOrClZzeqtHDPlV3v9lh5coI//zzZjSot3PMF01sYq/Tsxnat6zTpnlp5S5J2P/aWBt7HLXk8tcHvdW+iPJ46bd6YoqHDvOqeUq/4+CbljS2SJ8O5x3ZMRYOaUvccX02pcYqtaGgT0+3zCu2cnNF2A0bqfd836vun1eqxoLTtcodJz6yXt3jPBSBvcXyb87ons16lRS3O68UJ8jSf162Vbnv0Mz3w3BKd9P2tXdPoKGAUmCI7kv/aYbmkgcaYAcaYOEnnSpoVtJ/G9JX0mqTzrbVr27PRiCiH+5/m2R+mSnryW6xzsaSLJSk+vmfnNKw97Qg1KmdDjd615XZZDexfpoefGac16zN06flLdO7pX+npV0Z1cCsPHKYdXRcypEWfx8T4NXZSsZ55tHU9vPOYUJ8ytnVMyDXVrXuDxh1dpF/+8HhVV8XqhluX69gTtuiDuX1CreBMB/5Np2ET6rizrftzLzHtWtdhQvdJqydDxUjaUpCimS8O0u13faS62hhtXN9DPl/7zmNOYVt1cMaLW+Q9u7fkattPBdcPka9nnNyVjep971o15CSodpBDSwvVznqmfRy/11wwRuWlCeqR2qDbH/9UWzcla+VnqR3dTEQga22TMWaGArfKuCU9Za1dZYyZ3rz8cQUqx9IlPWoC79Mma23evrYbKUlQojHmC0n9JX0q6d32rtg8ZPaEJKWk9A7b6a+0PFmZ6XtGfjLSalS2I2kfa7RcN0ml5clasz5wJWnhsv768elfdUo7DxTekgR5svaMVHgya1VWGt8mJiMopi4oJm9Cqdav6aEd5ZQeeUsS5cncc0XXk1HbpqTNW5qgjJYxmYGYEXmlKt6epModgX5cvDBHhx5R7tgkyOtNVEZGy76sUVm5s8stvwvv9lhl9Npzdd2T06iyotgQMXtGeDy9GlVeHKvYOLvfdZ3GW5ooT2bN7seejFqVl7V+rycGv9c9ez4P5s4eoLmzAzer//zClfKWOvfYbkqNU0yLkZ+YigY19Qw+vhI2VyvniQ2SJPeuJiV/tVPWbVQ9MlW+noFRJF9KrHaN7KmEjdWOToK8JfHyZO0Z+fFk1au89Xm9OF4Z2S3O61l7zuvlpYFjdGdFnD5+P1ODDt9JEuQg1trZkma3eu7xFv++UNKF32abkVIOV9t8/08/SXGSLgtvc769/A0e5WZXKjujSjFunyaP26DFn7bvS2LFziSVliWrd06gln3U4du1ucWECk60dnUP5fapVlavGsXE+DXphO1a+mHwrE9LP8zSlFO2SbIaPLRC1btiVNHiZD/phEJK4ZqtXdMz0J851YH+PG6bli4Knixi6UfZmnLSFklWgw8vV/WuWFWUJai0OFGDD69onqzDavhor7Zscu6JfG1+mnrlVikre5diYnw65pgCLfn4gKvgjRj5XyQpd0CDsvrUKybWr8ln7NCSuT2CYpbM7aHjzqmQZDVkVLVqKl0qL4lt17pOs3ZNqnrl7lJWdvN7fcpWLVncKyhm6eIcTT1hsySrwYeWqbo6VhXNiXyPnoEvoBmZNZowcZsWzHPmxQ5JquufrNjiOsWU1ktNfqUsK1f18J5BMRv/PEwb/xL4qxqdqpLz+qp6ZKpMvU+mzidJMvU+Ja2uVH2ucxNKSVq7KkW9+tYoq1dt4Ng8sUhL5geXES5dkKGpp22XZDX4iB2B87o3XvEJPiUmBSaMik/waeT4Mm1e3y3Eq6ANayP/L0wiZSRIkmSt3WmMuULSG8aYx6y1B0xxt9/v0kNPj9Ofr5sbmDZ3wUBt3paq06aukST9d94Qpfao0aO3vamkxEZZv9H3T16tX117lmpq4/Twv8bqhksXKDbGr+0l3XXX3/Y7qUVU8/tceuyuw3Xrg8vkcknvvtlbBRu66+Tvb5Ykvf1aPy1flKG8CSX6x2sLVF/n0n237pmSPD7ep5FjvXr4zqHh2oWI4ve59Ni9w3TrvR/L5bJ6962+KtiYopPP2ChJevuNAVr+cZbyxhfrHy+9t3uKbEnKX52mRR/00gNPLZDPZ7RhbQ+9PatfOHcnrPx+lx57eJRuu2OB3C6ruXMOUsHmHjrl1HWSpNlvHaLU1Fo9+PC7SkpqlN8anXnWWk276GTV1MTquhs+1rBhJUrpUa9/PzdL//73UM1956Aw71X4+H1Gj9yYqzue3yCXW5r7Ypo2r03Qqed7JUlv/dujZfO6a8zUSv1z8RrVN0+Rva91nczvd+mxB0fotr9+FPh5gbf7q2BTik45PTBaMfvNg7R8SbbGjC3Sk8/OUX29W/f9ZU/FyI1/XKKUlAY1+Vx69IGR2rXLwTNxuY1Kf9JXve9fq/9r7+6jLavr+46/P4zDMwwPM/JswIg8hLQDGYQZGh1iVEANaGlDw2qNrRKyRGsqzbKF1abVlbQxahqDEopKYjQkghhUAlTiBOQhwuCA8jCEICoiDwPIg0xgmPvtH2cPHIZz71yYfe859+z3a62zOGfv397ne7/rMvd+7/e792ECHjtqV57eaxsWrHgAgEeXT35t5Msee4Y9z+r9m8BE8fhrduHJQ7pdoE+s34JP/e8D+PAnb2w++mJPfnDX9hx3Yu/Ox5dcsA/Xf3Mhh/+LNXz64qt7P4d+p3db8Z13fYozP3YTAPPmFSv+ZndWXrNwaF+LxkNqBAaokzxRVdv3vf4K8FdV9bkkvw4sqarTNnWeHXfcu5YcPueaSCNrq3+4f9OLND1bdntEp20T23b7F922TXz39mGHMFbmHfCqYYcwNm77zzsNO4SxctAZL/yIDr001675Io+ue2DkL5rbYae9a/Hy/zjsMKb0zb/+7ZWbun5nJoxEJ6i/AGpev7Xv+XnAebMckiRJkjTnTfMObJ0zKtcESZIkSdKssAiSJEmS1CkjMQ4nSZIkaQY4DjeQnSBJkiRJnWIRJEmSJKlTHIeTJEmSxpR3hxvMTpAkSZKkTrEIkiRJktQpFkGSJEmSOsVrgiRJkqRxVMCEFwUNYidIkiRJUqdYBEmSJEnqFMfhJEmSpHHlNNxAdoIkSZIkdYpFkCRJkqROcRxOkiRJGlNxHG4gO0GSJEmSOsUiSJIkSVKnOA4nSZIkjatyHm4QO0GSJEmSOsUiSJIkSVKnOA4nSZIkjSnvDjeYnSBJkiRJnWIRJEmSJKlTHIeTJEmSxlE1D72AnSBJkiRJnWIRJEmSJKlTLIIkSZIkdYrXBEmSJEljKEDKi4IGsRMkSZIkqVMsgiRJkiR1iuNwkiRJ0riaGHYAo8lOkCRJkqROsQiSJEmS1CmOw0mSJEljyrvDDWYnSJIkSVKnjFcn6PEnmfeNG4cdxdh4ZtgBSNIctH71ncMOYWy8+l3DjmC8rB92AGOkyt+S5rrxKoIkSZIk9VTz0As4DidJkiSpUyyCJEmSJHWK43CSJEnSWCrw7nAD2QmSJEmS1CkWQZIkSZI6xSJIkiRJUqd4TZAkSZI0puIlQQPZCZIkSZLUKRZBkiRJkjrFcThJkiRpXHmL7IHsBEmSJEnqFIsgSZIkSZ3iOJwkSZI0jgoyMewgRpOdIEmSJEmdYhEkSZIkqVMch5MkSZLGlXeHG8hOkCRJkqROsQiSJEmS1CmOw0mSJEnjymm4gewESZIkSeoUiyBJkiRJnWIRJEmSJKlTvCZIkiRJGlPxFtkD2QmSJEmS1CkWQZIkSZI6xXE4SZIkaVw5DjeQnSBJkiRJnWIRJEmSJKlTHIeTJEmSxlEBE8MOYjTZCZIkSZLUKRZBkiRJkjrFcThJkiRpDIXyw1InYSdIkiRJUqdYBEmSJEnqFMfhJEmSpHHlONxAdoIkSZIkdYpFUIuWLH+Mc6+6nc9efRv/+rT7B6wofvNDP+KzV9/Gp76+mlf9/JMv4tjuMZ/tMp/tMZftMp/tMp/tMZftMp8aJTNaBCVZn2RV32PfJMuTfLVvzYeTXJbkoiQn9G1fneTMvtcXJnn7TMa7ObbYonjP7/6IM0/ej3cvP4Cjj/8Jr9j/n5635vBfepy99nuKdx51IP/nt/fmvb/3o2kf2zXms13msz3msl3ms13msz3msl3mc4iqRvsxJDPdCVpbVYv7Hnf370xyBnAUcAJwDbCs2b4r8ASwtG/50mbNSDrg0Ce59+4tue8HW/HMui1Y8dc7sfRNjz5vzdI3PcrXL9gZCLffuB3bLVjPLi9fN61ju8Z8tst8tsdctst8tst8tsdctst8atQMbRwuyQeA44C3VtVa4GqaIqj571eBRenZj15Bdd9wot20XXdfx4P3bvns6zU/ns/CPdY9b83C3dfx4L3zn1tz73x23X3dtI7tGvPZLvPZHnPZLvPZLvPZHnPZLvOpUTPTd4fbJsmq5vn3quptzfOjgAOAX6iqJ5ptK4FDkmxJrwj6O+CVwEHAofSKpBdIcgpwCsDWbDsTX8O0JC/c9oIO3yRrpnVsx5jPdpnP9pjLdpnPdpnP9pjLdplPjZqZLoLWVtXiAdvvBHYG3ghcAFBVTyW5BTgMOBL4fXpF0DJ6RdDAUbiqOgc4B2DH7DK0/yXW/Hg+i/Z8+tnXC/dYx0P3zR+w5rm/XCzccx0P3z+f+VvWJo/tGvPZLvPZHnPZLvPZLvPZHnPZLvM5JAVMDDuI0TSscbj76Y3CfTzJ0X3brwFeC+xQVY8A19ErgpYxSSdoVKxetS177fc0u+3zFC+bP8Hy43/CdZcveN6a6y5fwC+f+AhQHHjYT3nysS14+IH50zq2a8xnu8xne8xlu8xnu8xne8xlu8ynRs3QPiy1qu5o7vb25SRvrqpV9AqdjwIrmmU30+sK7QbcMow4p2tifTjrjL343S/cxRbz4PLzd+H7d2zNm//tGgC+9rmFfOuKHTj89Y/x2Wtu56m1W/DR39pnymO7zHy2y3y2x1y2y3y2y3y2x1y2y3xq1KRmcKgyyRNVtf1G25YDp1fVW5rXbwTOBY4GHqfXJXp3VZ3b7F8BPFVVb9rU++2YXeqIvL7NL0GSJEl6nr+vK3isHh5wtdJoWbDtnrX01e8adhhTuuymD62sqiWz/b4z2gnauABqtq3guU4PVXU58Iq+Jdlo/fKZiU6SJElSFw3tFtmSJEmSNAxDuyZIkiRJ0gzzfuID2QmSJEmS1CkWQZIkSZI6xSJIkiRJGkvVG4cb5cc0JDkmyeokdyb54ID9Bya5NslTSU6fzjm9JkiSJEnSSEoyDzgLeANwD3B9kour6ta+ZQ8D7wNOmO557QRJkiRJGlWvAe6sqruq6mngfOD4/gVV9UBVXQ+sm+5J7QRJkiRJ46gYh7vD7QX8sO/1PcARm3tSiyBJkiRJw7IwyQ19r8+pqnP6XmfAMZtd2VkESZIkSRqWNVW1ZIr99wD79L3eG7h3c9/Ua4IkSZIkjarrgf2T7JdkS+Ak4OLNPamdIEmSJGlcTQw7gM1TVc8kOQ24DJgHfKaqbklyarP/7CS7AzcAOwITSd4PHFxVj012XosgSZIkSSOrqi4BLtlo29l9z++jNyY3bY7DSZIkSeoUO0GSJEnSmMrcv0X2jLATJEmSJKlTLIIkSZIkdYrjcJIkSdK4chxuIDtBkiRJkjrFIkiSJElSpzgOJ0mSJI2jAiYchxvETpAkSZKkTrEIkiRJktQpjsNJkiRJY6m8O9wk7ARJkiRJ6hSLIEmSJEmd4jicJEmSNK4chxvITpAkSZKkTrEIkiRJktQpFkGSJEmSOsVrgiRJkqRx5TVBA9kJkiRJktQpFkGSJEmSOsVxOEmSJGkcFTDhONwgdoIkSZIkdYpFkCRJkqROGatxuMd5ZM3X64LvDzuOaVgIrBl2EGPCXLbLfLbLfLbHXLbLfLbLfLZrLuTzZ4YdwPQU1MSwgxhJY1UEVdWiYccwHUluqKolw45jHJjLdpnPdpnP9pjLdpnPdpnPdplPzQbH4SRJkiR1ylh1giRJkiT18cNSB7ITNBznDDuAMWIu22U+22U+22Mu22U+22U+22U+NeNSVoeSJEnS2Fmw1W61bI9fG3YYU7r0+3+4chjXgDkOJ0mSJI0jPyx1Uo7DSZIkSeoUi6AZkmR9klVJbkpyY5JlzfZ9k6xN8u0ktyX5VpJ3DDveuSDJ7knOT/KPSW5NckmSV5vP6UtyRpJbktzcfH9+o/nvnUkebZ6vSrIsyYokq5vv4euTLB52/KNmQD6P2ChvVyc5IMlFk+V52F/DKJhuHpu1K5IsaZ7fneTCvvOcmOS8IX0ZI6fv59B3k3wxybbN9if61vx9s+YHSR7s+97cd2iBj7iN8vqVJDuZx+npy92z+UmyPMlX+9Z8OMllzb+bJ/RtX53kzL7XFyZ5+yx/CRojjsPNnLVVtRggyZuA3wNe1+z7x6o6tNn3SuBLSbaoqs8OJdI5IEmAi4A/raqTmm2Lgd0wn9OSZCnwFuCwqnoqyUJgy6q6N8ly4PSqekvfeoCTq+qGJO8EPgK8YfYjH02T5bPZvSFvpwAfqapfaY5ZzkZ57roXk0fgVwacYkmSn6uqW2Yp5Lmk/+fQ54FTgY/1L6iqI5r9vw4sqarTZjnGuag/r38KvMc8Ttuzudugv1BMcgZwFHAccBqwDPhykl2BJ4ClfYcuBd4zw/FqjNkJmh07Ao8M2lFVdwH/CXjfrEY09xwNrKuqszdsqKpVwA/7F5nPKe0BrKmqpwCqak1V3TvNY68F9pqxyOam6eTzSuBVsx7Z3LK5efwD4L/OYHzj4ir8XpwJ/tvYkiQfoFf8vLWq1gJX0yuCaP77VWBRevajV1DdN5xo55iq0X4MiUXQzNmmafXeDpwLfGiKtTcCB85OWHPWIcDKaa41n4NdDuyT5I4kn0zyuk0e8ZxjgC/PTFhz1nTy+VbgO7Mc11yzuXn8K+CwJP6CP4kkLwOOxe/FViWZB7weuHjYscwhG343WpXkor7tR9HrVB5bVRvGNVcChyTZkl4RdC2wGjioeX31LMatMeQ43Mzpb5cvBf4sySGTrM2sRdUN5nOAqnoiyS8Av0ivs/aXST5YVedNcdjnk2wHzAMOm4Uw54zJ8tns/nyStcDdwHuHFOKc0EIe19MblfsvwN/McLhzzTZJVjXPrwI+PcRYxsmGvO5L7xf1/zfUaOaWF4zDNe4EdgbeCFwA0IzH3kLvZ8+RwO8Dr6RXAB0KXDMbAWt8WQTNgqq6tplzXzTJkkOB22YxpLnoFuDEaa41n5OoqvXACmBFku8A7wDOm+KQk4GbgP8FnAV4EWqfSfIJzbUsQwtsjmkhj5+jVwR5XdDzTfYLpzbP2qpanGQBvRGt9wB/NOSY5rr76f28uSLJQ1X1jWb7NcBrgR2q6pEk19G7VuhQ4OzBp9IL+JmgAzkONwuSHEjvL+kPDdi3L72Z9k/Mclhzzd8CWyV594YNSQ4HfqZ/kfmcXHp3Kdu/b9Ni4PubOq6q1gFnAkcmOWiGwptzXmo+9Xxt5LH5Hv048P72IpOmVlWP0rv+9PQk84cdz1xXVXfQ+0Pbn+e5u5FeDfwGvT/GAdxMryv0CvyjhzaTnaCZ0z+GEOAdVbW+uePWzyb5NrA18DjwCe9kNrWqqiRvA/6wGZX5J3ojMu/HfE7X9sAnkuwEPENv/OCU6RxYVWuTfBQ4HfgPMxbh3DJZPi8YZlBzUFt5/DS9Yl2btm2Se/pefwx4eFjBzGVV9e0kNwEn0etIajNU1fXN3UgvTnI0vU7QK+ndYZeqeibJA8APq2piiKFqDKRskUmSJEljZ8GWL69li3512GFM6dJ7/3hlVS2Z7fd1HE6SJElSp1gESZIkSeoUrwmSJEmSxlEBE14+NYidIEmSJEmdYhEkSZIkqVMsgiRpFiVZn2RVku8m+WKSbTfjXOclObF5fm6Sg6dYuzzJspfwHnc3H/Y8re0brXniRb7X7yQ5/cXGKEmaQtVoP4bEIkiSZtfaqlpcVYcATwOn9u9MMu+lnLSq3lVVt06xZDnwoosgSZLGkUWQJA3PVcCrmi7NN5J8AfhOknlJPpLk+iQ3J/kNgPT8cZJbk3wNePmGEyVZkWRJ8/yYJDcmuSnJFUn2pVds/VbThfrFJIuSXNi8x/VJjmqO3TXJ5Um+neRP6H3Y85SSfDnJyiS3JDllo30fbWK5IsmiZtvPJrm0OeaqJAe2kk1JkqbJu8NJ0hAkeRlwLHBps+k1wCFV9b2mkHi0qg5PshVwdZLLgUOBA4CfB3YDbgU+s9F5FwH/F3htc65dqurhJGcDT1TVHzTrvgB8vKq+meQVwGXAQcB/B75ZVf8zyZuB5xU1k/j3zXtsA1yf5MKqegjYDrixqj6Q5L815z4NOAc4tar+IckRwCeBX3oJaZQk6SWxCJKk2bVNklXN86uAT9MbU/tWVX2v2f5G4J9tuN4HWADsD7wW+IuqWg/cm+RvB5z/SODKDeeqqocnieOXgYOTZxs9OybZoXmPtzfHfi3JI9P4mt6X5G3N832aWB8CJoC/bLb/OfClJNs3X+8X+957q2m8hyTppRjidTejzCJIkmbX2qpa3L+hKQZ+2r8JeG9VXbbRuuPoferDVDKNNdAbh15aVWsHxDLtn5hJltMrqJZW1ZNJVgBbT7K8mvf9ycY5kCRpNnlNkCSNnsuA30wyHyDJq5NsB1wJnNRcM7QHcPSAY68FXpdkv+bYXZrtjwM79K27nN5oGs26xc3TK4GTm23HAjtvItYFwCNNAXQgvU7UBlsAG7pZv0ZvzO4x4HtJ/lXzHknyzzfxHpIktcpOkCSNnnOBfYEb02vNPAicAFxE79qZ7wB3AH+38YFV9WBzTdGXkmwBPAC8AfgKcEGS44H3Au8DzkpyM72fBVfSu3nC/wD+IsmNzfl/sIlYLwVObc6zGriub99PgZ9LshJ4FPjVZvvJwKeSnAnMB84HbppWZiRJL0LBhONwg6ScE5QkSZLGzoL5i2rZTv9y2GFM6dI1f7KyqpbM9vs6DidJkiSpUxyHkyRJksZRQdXEsKMYSXaCJEmSJHWKRZAkSZKkTnEcTpIkSRpX3h1uIDtBkiRJkjrFIkiSJElSpzgOJ0mSJI0rPxN0IDtBkiRJkjrFIkiSJElSpzgOJ0mSJI2jKpjww1IHsRMkSZIkqVMsgiRJkiR1ikWQJEmSpE7xmiBJkiRpXHmL7IHsBEmSJEnqFIsgSZIkSZ3iOJwkSZI0pspbZA9kJ0iSJElSp1gESZIkSeoUx+EkSZKksVTeHW4SdoIkSZIkdYpFkCRJkqROcRxOkiRJGkcFTDgON4idIEmSJEmdYhEkSZIkqVMch5MkSZLGVflhqYPYCZIkSZLUKRZBkiRJkjrFIkiSJElSp3hNkCRJkjSGCihvkT2QnSBJkiRJnWIRJEmSJKlTHIeTJEmSxlGVt8iehJ0gSZIkSZ1iESRJkiSpUxyHkyRJksaUd4cbzE6QJEmSpE6xCJIkSZLUKRZBkiRJ0riqidF+TEOSY5KsTnJnkg8O2J8kf9TsvznJYZs6p0WQJEmSpJGUZB5wFnAscDDwb5IcvNGyY4H9m8cpwKc2dV6LIEmSJEmj6jXAnVV1V1U9DZwPHL/RmuOBP6ue64Cdkuwx1Um9O5wkSZI0hh7nkcu+XhcsHHYcm7B1khv6Xp9TVef0vd4L+GHf63uAIzY6x6A1ewE/nuxNLYIkSZKkMVRVxww7hhZkwLaN7/s9nTXP4zicJEmSpFF1D7BP3+u9gXtfwprnsQiSJEmSNKquB/ZPsl+SLYGTgIs3WnMx8O+au8QdCTxaVZOOwoHjcJIkSZJGVFU9k+Q04DJgHvCZqrolyanN/rOBS4DjgDuBJ4F3buq8qZpyXE6SJEmSxorjcJIkSZI6xSJIkiRJUqdYBEmSJEnqFIsgSZIkSZ1iESRJkiSpUyyCJEmSJHWKRZAkSZKkTvn/4DMNGUdyMD4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=[15, 15])\n",
    "disp2.plot(include_values=True,\n",
    "                     cmap='viridis', ax=ax, xticks_rotation='horizontal',\n",
    "                     values_format='.2f', colorbar=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.metrics import classification_report\n",
    "# >>> target_names = ['class 0', 'class 1', 'class 2']\n",
    "print(classification_report(label_test, np.argmax(label_pred, axis=1), target_names=list(range(num_species))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## top k accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import top_k_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1:  \n",
      "0.3969706058788242\n",
      "k=2:  \n",
      "0.5826334733053389\n",
      "k=3:  \n",
      "0.7009598080383923\n",
      "k=4:  \n",
      "0.8032393521295741\n",
      "k=5:  \n",
      "0.8837732453509298\n",
      "k=6:  \n",
      "0.9377624475104979\n",
      "k=7:  \n",
      "0.9733053389322136\n",
      "k=8:  \n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ys587/miniconda3/envs/whistle_classifier/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1693: UndefinedMetricWarning: 'k' (8) greater than or equal to 'n_classes' (8) will result in a perfect score and is therefore meaningless.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "top_k = []\n",
    "for kk in range(1, num_species+1):\n",
    "    print('k='+str(kk)+':  ')\n",
    "    this_acc = top_k_accuracy_score(label_test, label_pred, k=kk, labels=list(range(num_species)))\n",
    "    print(this_acc)\n",
    "    top_k.append(this_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %matplotlib inline\n",
    "fig = plt.figure()\n",
    "ax = fig.subplots()\n",
    "ax.bar(list(range(1, num_species+1)), top_k)\n",
    "ax.grid(axis='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## average_precision_score"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "average_precision_score(to_categorical(label_test, num_classes=8), label_pred)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from collections import Counter\n",
    "Counter(label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STAR2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STAR2003\n"
     ]
    }
   ],
   "source": [
    "ee = deployment[1]\n",
    "print(ee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "fea_temp = np.load(os.path.join(feature_path, 'train_oswald_no_'+ee+'.npz'))\n",
    "fea_train = fea_temp['fea_train']\n",
    "label_train_list = fea_temp['label_train']\n",
    "del fea_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train = np.zeros(len(label_train_list))\n",
    "for ii in range(len(label_train_list)):\n",
    "    label_train[ii] = species_dict[label_train_list[ii]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing data\n",
    "fea_temp = np.load(os.path.join(feature_path, 'oswald_'+ee+'_orig.npz'))\n",
    "fea_test = fea_temp['feas_orig']\n",
    "label_test_list = fea_temp['labels_orig']\n",
    "\n",
    "fea_test = fea_test[:,:100,:]\n",
    "label_test = np.zeros(len(label_test_list))\n",
    "for ii in range(len(label_test_list)):\n",
    "    label_test[ii] = species_dict[label_test_list[ii]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_train = fea_train[:,:100,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train = np.zeros(len(label_train_list))\n",
    "for ii in range(len(label_train_list)):\n",
    "    label_train[ii] = species_dict[label_train_list[ii]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'BD': 10080,\n",
       "         'CD': 23928,\n",
       "         'PLT': 12042,\n",
       "         'RT': 7866,\n",
       "         'SPIN': 5904,\n",
       "         'SPT': 11154,\n",
       "         'STR': 14868,\n",
       "         'FKW': 17460})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(label_train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0.0: 231, 1.0: 752, 7.0: 270, 4.0: 51, 3.0: 412, 2.0: 54})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(label_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_result_path2 = os.path.join(fit_result_path1, ee)\n",
    "if not os.path.exists(fit_result_path2):\n",
    "    makedirs(fit_result_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature train shape: (103302, 100, 128)\n",
      "feature test shape: (1770, 100, 128)\n",
      "label train shape: (103302,)\n",
      "label test shape: (1770,)\n",
      "dim_time: 100\n",
      "dim_freq: 128\n"
     ]
    }
   ],
   "source": [
    "print('feature train shape: '+str(fea_train.shape))\n",
    "print('feature test shape: '+str(fea_test.shape))\n",
    "print('label train shape: '+str(label_train.shape))\n",
    "print('label test shape: '+str(label_test.shape))\n",
    "\n",
    "dim_time = fea_train.shape[1]\n",
    "dim_freq = fea_train.shape[2]\n",
    "print('dim_time: '+str(dim_time))\n",
    "print('dim_freq: '+str(dim_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle features & labels\n",
    "fea_train, label_train = shuffle(fea_train, label_train, random_state=0)\n",
    "fea_test, label_test = shuffle(fea_test, label_test, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class weight\n",
    "weights = compute_class_weight(class_weight='balanced', classes=np.unique(label_train), y=label_train)\n",
    "\n",
    "class_weights = dict()\n",
    "for ii in range(num_species):\n",
    "    class_weights[ii] = weights[ii]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_train = np.expand_dims(fea_train, axis=3)\n",
    "fea_test = np.expand_dims(fea_test, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_train, fea_validate, label_train, label_validate = train_test_split(fea_train, label_train, test_size=0.10, random_state=42)\n",
    "\n",
    "train_generator = DataGenerator(fea_train, label_train, batch_size=batch_size, num_classes=num_species)\n",
    "del fea_train\n",
    "validate_generator = DataGenerator(fea_validate, label_validate, batch_size=batch_size, num_classes=num_species)\n",
    "del fea_validate\n",
    "\n",
    "# test_generator = DataGenerator(fea_test, label_test, batch_size=batch_size, num_classes=num_species)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "   2/5810 [..............................] - ETA: 12:32 - loss: 9.0337 - accuracy: 0.1562WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.122654). Check your callbacks.\n",
      "5807/5810 [============================>.] - ETA: 0s - loss: 0.7601 - accuracy: 0.1227\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.21618, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2003/epoch_01_valloss_0.4861_valacc_0.2162.hdf5\n",
      "5810/5810 [==============================] - 102s 18ms/step - loss: 0.7600 - accuracy: 0.1227 - val_loss: 0.4861 - val_accuracy: 0.2162\n",
      "Epoch 2/200\n",
      "5809/5810 [============================>.] - ETA: 0s - loss: 0.4866 - accuracy: 0.1242\n",
      "Epoch 00002: val_accuracy did not improve from 0.21618\n",
      "5810/5810 [==============================] - 101s 17ms/step - loss: 0.4866 - accuracy: 0.1242 - val_loss: 0.4391 - val_accuracy: 0.1151\n",
      "Epoch 3/200\n",
      "5807/5810 [============================>.] - ETA: 0s - loss: 0.4568 - accuracy: 0.1363\n",
      "Epoch 00003: val_accuracy did not improve from 0.21618\n",
      "5810/5810 [==============================] - 101s 17ms/step - loss: 0.4568 - accuracy: 0.1363 - val_loss: 0.4323 - val_accuracy: 0.0961\n",
      "Epoch 4/200\n",
      "5808/5810 [============================>.] - ETA: 0s - loss: 0.4348 - accuracy: 0.1790\n",
      "Epoch 00004: val_accuracy did not improve from 0.21618\n",
      "5810/5810 [==============================] - 101s 17ms/step - loss: 0.4348 - accuracy: 0.1791 - val_loss: 0.4271 - val_accuracy: 0.1207\n",
      "Epoch 5/200\n",
      "5809/5810 [============================>.] - ETA: 0s - loss: 0.4103 - accuracy: 0.2366\n",
      "Epoch 00005: val_accuracy did not improve from 0.21618\n",
      "5810/5810 [==============================] - 104s 18ms/step - loss: 0.4103 - accuracy: 0.2366 - val_loss: 0.4275 - val_accuracy: 0.1542\n",
      "Epoch 6/200\n",
      "5807/5810 [============================>.] - ETA: 0s - loss: 0.3849 - accuracy: 0.3016\n",
      "Epoch 00006: val_accuracy improved from 0.21618 to 0.25688, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2003/epoch_06_valloss_0.3824_valacc_0.2569.hdf5\n",
      "5810/5810 [==============================] - 101s 17ms/step - loss: 0.3848 - accuracy: 0.3017 - val_loss: 0.3824 - val_accuracy: 0.2569\n",
      "Epoch 7/200\n",
      "5808/5810 [============================>.] - ETA: 0s - loss: 0.3653 - accuracy: 0.3496\n",
      "Epoch 00007: val_accuracy improved from 0.25688 to 0.32442, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2003/epoch_07_valloss_0.3549_valacc_0.3244.hdf5\n",
      "5810/5810 [==============================] - 101s 17ms/step - loss: 0.3653 - accuracy: 0.3496 - val_loss: 0.3549 - val_accuracy: 0.3244\n",
      "Epoch 8/200\n",
      "5807/5810 [============================>.] - ETA: 0s - loss: 0.3493 - accuracy: 0.3897\n",
      "Epoch 00008: val_accuracy improved from 0.32442 to 0.34496, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2003/epoch_08_valloss_0.3775_valacc_0.3450.hdf5\n",
      "5810/5810 [==============================] - 101s 17ms/step - loss: 0.3494 - accuracy: 0.3897 - val_loss: 0.3775 - val_accuracy: 0.3450\n",
      "Epoch 9/200\n",
      "5809/5810 [============================>.] - ETA: 0s - loss: 0.3371 - accuracy: 0.4210\n",
      "Epoch 00009: val_accuracy improved from 0.34496 to 0.37897, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2003/epoch_09_valloss_0.3516_valacc_0.3790.hdf5\n",
      "5810/5810 [==============================] - 101s 17ms/step - loss: 0.3371 - accuracy: 0.4210 - val_loss: 0.3516 - val_accuracy: 0.3790\n",
      "Epoch 10/200\n",
      "5809/5810 [============================>.] - ETA: 0s - loss: 0.3272 - accuracy: 0.4419\n",
      "Epoch 00010: val_accuracy improved from 0.37897 to 0.45136, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2003/epoch_10_valloss_0.3118_valacc_0.4514.hdf5\n",
      "5810/5810 [==============================] - 101s 17ms/step - loss: 0.3272 - accuracy: 0.4419 - val_loss: 0.3118 - val_accuracy: 0.4514\n",
      "Epoch 11/200\n",
      "5810/5810 [==============================] - ETA: 0s - loss: 0.3195 - accuracy: 0.4603\n",
      "Epoch 00011: val_accuracy did not improve from 0.45136\n",
      "5810/5810 [==============================] - 101s 17ms/step - loss: 0.3195 - accuracy: 0.4603 - val_loss: 0.3190 - val_accuracy: 0.4275\n",
      "Epoch 12/200\n",
      "5808/5810 [============================>.] - ETA: 0s - loss: 0.3117 - accuracy: 0.4774\n",
      "Epoch 00012: val_accuracy improved from 0.45136 to 0.50484, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2003/epoch_12_valloss_0.2954_valacc_0.5048.hdf5\n",
      "5810/5810 [==============================] - 101s 17ms/step - loss: 0.3116 - accuracy: 0.4774 - val_loss: 0.2954 - val_accuracy: 0.5048\n",
      "Epoch 13/200\n",
      "5808/5810 [============================>.] - ETA: 0s - loss: 0.3053 - accuracy: 0.4943\n",
      "Epoch 00013: val_accuracy did not improve from 0.50484\n",
      "5810/5810 [==============================] - 101s 17ms/step - loss: 0.3053 - accuracy: 0.4943 - val_loss: 0.3060 - val_accuracy: 0.4963\n",
      "Epoch 14/200\n",
      "5809/5810 [============================>.] - ETA: 0s - loss: 0.2995 - accuracy: 0.5089\n",
      "Epoch 00014: val_accuracy improved from 0.50484 to 0.51492, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2003/epoch_14_valloss_0.2961_valacc_0.5149.hdf5\n",
      "5810/5810 [==============================] - 104s 18ms/step - loss: 0.2995 - accuracy: 0.5089 - val_loss: 0.2961 - val_accuracy: 0.5149\n",
      "Epoch 15/200\n",
      "5809/5810 [============================>.] - ETA: 0s - loss: 0.2945 - accuracy: 0.5204\n",
      "Epoch 00015: val_accuracy did not improve from 0.51492\n",
      "5810/5810 [==============================] - 101s 17ms/step - loss: 0.2945 - accuracy: 0.5204 - val_loss: 0.2870 - val_accuracy: 0.5123\n",
      "Epoch 16/200\n",
      "5809/5810 [============================>.] - ETA: 0s - loss: 0.2897 - accuracy: 0.5303\n",
      "Epoch 00016: val_accuracy did not improve from 0.51492\n",
      "5810/5810 [==============================] - 101s 17ms/step - loss: 0.2898 - accuracy: 0.5302 - val_loss: 0.3153 - val_accuracy: 0.4755\n",
      "Epoch 17/200\n",
      "5808/5810 [============================>.] - ETA: 0s - loss: 0.2853 - accuracy: 0.5395\n",
      "Epoch 00017: val_accuracy improved from 0.51492 to 0.54002, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2003/epoch_17_valloss_0.2763_valacc_0.5400.hdf5\n",
      "5810/5810 [==============================] - 101s 17ms/step - loss: 0.2854 - accuracy: 0.5395 - val_loss: 0.2763 - val_accuracy: 0.5400\n",
      "Epoch 18/200\n",
      "5809/5810 [============================>.] - ETA: 0s - loss: 0.2815 - accuracy: 0.5478\n",
      "Epoch 00018: val_accuracy improved from 0.54002 to 0.54012, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2003/epoch_18_valloss_0.2771_valacc_0.5401.hdf5\n",
      "5810/5810 [==============================] - 101s 17ms/step - loss: 0.2815 - accuracy: 0.5478 - val_loss: 0.2771 - val_accuracy: 0.5401\n",
      "Epoch 19/200\n",
      "5807/5810 [============================>.] - ETA: 0s - loss: 0.2781 - accuracy: 0.5551\n",
      "Epoch 00019: val_accuracy did not improve from 0.54012\n",
      "5810/5810 [==============================] - 101s 17ms/step - loss: 0.2781 - accuracy: 0.5551 - val_loss: 0.2813 - val_accuracy: 0.5320\n",
      "Epoch 20/200\n",
      "5809/5810 [============================>.] - ETA: 0s - loss: 0.2746 - accuracy: 0.5637\n",
      "Epoch 00020: val_accuracy improved from 0.54012 to 0.54884, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2003/epoch_20_valloss_0.2717_valacc_0.5488.hdf5\n",
      "5810/5810 [==============================] - 101s 17ms/step - loss: 0.2746 - accuracy: 0.5637 - val_loss: 0.2717 - val_accuracy: 0.5488\n",
      "Epoch 21/200\n",
      "5810/5810 [==============================] - ETA: 0s - loss: 0.2714 - accuracy: 0.5712\n",
      "Epoch 00021: val_accuracy did not improve from 0.54884\n",
      "5810/5810 [==============================] - 101s 17ms/step - loss: 0.2714 - accuracy: 0.5712 - val_loss: 0.2811 - val_accuracy: 0.5400\n",
      "Epoch 22/200\n",
      "5808/5810 [============================>.] - ETA: 0s - loss: 0.2687 - accuracy: 0.5759\n",
      "Epoch 00022: val_accuracy improved from 0.54884 to 0.62122, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2003/epoch_22_valloss_0.2365_valacc_0.6212.hdf5\n",
      "5810/5810 [==============================] - 101s 17ms/step - loss: 0.2687 - accuracy: 0.5759 - val_loss: 0.2365 - val_accuracy: 0.6212\n",
      "Epoch 23/200\n",
      "5808/5810 [============================>.] - ETA: 0s - loss: 0.2666 - accuracy: 0.5811\n",
      "Epoch 00023: val_accuracy did not improve from 0.62122\n",
      "5810/5810 [==============================] - 101s 17ms/step - loss: 0.2666 - accuracy: 0.5810 - val_loss: 0.2833 - val_accuracy: 0.5344\n",
      "Epoch 24/200\n",
      "5809/5810 [============================>.] - ETA: 0s - loss: 0.2641 - accuracy: 0.5858\n",
      "Epoch 00024: val_accuracy did not improve from 0.62122\n",
      "5810/5810 [==============================] - 101s 17ms/step - loss: 0.2642 - accuracy: 0.5858 - val_loss: 0.2606 - val_accuracy: 0.5733\n",
      "Epoch 25/200\n",
      "5808/5810 [============================>.] - ETA: 0s - loss: 0.2619 - accuracy: 0.5920\n",
      "Epoch 00025: val_accuracy did not improve from 0.62122\n",
      "5810/5810 [==============================] - 101s 17ms/step - loss: 0.2619 - accuracy: 0.5920 - val_loss: 0.2436 - val_accuracy: 0.6015\n",
      "Epoch 26/200\n",
      "5809/5810 [============================>.] - ETA: 0s - loss: 0.2588 - accuracy: 0.5970\n",
      "Epoch 00026: val_accuracy did not improve from 0.62122\n",
      "5810/5810 [==============================] - 102s 17ms/step - loss: 0.2588 - accuracy: 0.5971 - val_loss: 0.2927 - val_accuracy: 0.5181\n",
      "Epoch 27/200\n",
      "5807/5810 [============================>.] - ETA: 0s - loss: 0.2565 - accuracy: 0.5998\n",
      "Epoch 00027: val_accuracy did not improve from 0.62122\n",
      "5810/5810 [==============================] - 101s 17ms/step - loss: 0.2565 - accuracy: 0.5997 - val_loss: 0.2414 - val_accuracy: 0.6054\n",
      "Epoch 28/200\n",
      "5810/5810 [==============================] - ETA: 0s - loss: 0.2543 - accuracy: 0.6055\n",
      "Epoch 00028: val_accuracy did not improve from 0.62122\n",
      "5810/5810 [==============================] - 101s 17ms/step - loss: 0.2543 - accuracy: 0.6055 - val_loss: 0.2518 - val_accuracy: 0.5895\n",
      "Epoch 29/200\n",
      "5808/5810 [============================>.] - ETA: 0s - loss: 0.2533 - accuracy: 0.6071\n",
      "Epoch 00029: val_accuracy did not improve from 0.62122\n",
      "5810/5810 [==============================] - 101s 17ms/step - loss: 0.2533 - accuracy: 0.6071 - val_loss: 0.2834 - val_accuracy: 0.5364\n",
      "Epoch 30/200\n",
      "5810/5810 [==============================] - ETA: 0s - loss: 0.2520 - accuracy: 0.6120\n",
      "Epoch 00030: val_accuracy did not improve from 0.62122\n",
      "5810/5810 [==============================] - 101s 17ms/step - loss: 0.2520 - accuracy: 0.6120 - val_loss: 0.2567 - val_accuracy: 0.5905\n",
      "Epoch 31/200\n",
      "5809/5810 [============================>.] - ETA: 0s - loss: 0.2497 - accuracy: 0.6155\n",
      "Epoch 00031: val_accuracy did not improve from 0.62122\n",
      "5810/5810 [==============================] - 101s 17ms/step - loss: 0.2497 - accuracy: 0.6155 - val_loss: 0.2638 - val_accuracy: 0.5666\n",
      "Epoch 32/200\n",
      "5808/5810 [============================>.] - ETA: 0s - loss: 0.2486 - accuracy: 0.6175\n",
      "Epoch 00032: val_accuracy did not improve from 0.62122\n",
      "5810/5810 [==============================] - 101s 17ms/step - loss: 0.2485 - accuracy: 0.6175 - val_loss: 0.2481 - val_accuracy: 0.5895\n",
      "Epoch 33/200\n",
      "5808/5810 [============================>.] - ETA: 0s - loss: 0.2472 - accuracy: 0.6199\n",
      "Epoch 00033: val_accuracy did not improve from 0.62122\n",
      "5810/5810 [==============================] - 101s 17ms/step - loss: 0.2472 - accuracy: 0.6199 - val_loss: 0.2552 - val_accuracy: 0.5840\n",
      "Epoch 34/200\n",
      "5809/5810 [============================>.] - ETA: 0s - loss: 0.2450 - accuracy: 0.6252\n",
      "Epoch 00034: val_accuracy did not improve from 0.62122\n",
      "5810/5810 [==============================] - 102s 17ms/step - loss: 0.2449 - accuracy: 0.6252 - val_loss: 0.2387 - val_accuracy: 0.6209\n",
      "Epoch 35/200\n",
      "5808/5810 [============================>.] - ETA: 0s - loss: 0.2441 - accuracy: 0.6266\n",
      "Epoch 00035: val_accuracy improved from 0.62122 to 0.64632, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2003/epoch_35_valloss_0.2263_valacc_0.6463.hdf5\n",
      "5810/5810 [==============================] - 101s 17ms/step - loss: 0.2441 - accuracy: 0.6266 - val_loss: 0.2263 - val_accuracy: 0.6463\n",
      "Epoch 36/200\n",
      "5810/5810 [==============================] - ETA: 0s - loss: 0.2424 - accuracy: 0.6306\n",
      "Epoch 00036: val_accuracy improved from 0.64632 to 0.67006, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2003/epoch_36_valloss_0.2130_valacc_0.6701.hdf5\n",
      "5810/5810 [==============================] - 102s 17ms/step - loss: 0.2424 - accuracy: 0.6306 - val_loss: 0.2130 - val_accuracy: 0.6701\n",
      "Epoch 37/200\n",
      "5810/5810 [==============================] - ETA: 0s - loss: 0.2421 - accuracy: 0.6315\n",
      "Epoch 00037: val_accuracy did not improve from 0.67006\n",
      "5810/5810 [==============================] - 102s 17ms/step - loss: 0.2421 - accuracy: 0.6315 - val_loss: 0.2185 - val_accuracy: 0.6577\n",
      "Epoch 38/200\n",
      "5809/5810 [============================>.] - ETA: 0s - loss: 0.2399 - accuracy: 0.6368\n",
      "Epoch 00038: val_accuracy did not improve from 0.67006\n",
      "5810/5810 [==============================] - 101s 17ms/step - loss: 0.2399 - accuracy: 0.6368 - val_loss: 0.2706 - val_accuracy: 0.5770\n",
      "Epoch 39/200\n",
      "5808/5810 [============================>.] - ETA: 0s - loss: 0.2393 - accuracy: 0.6372\n",
      "Epoch 00039: val_accuracy did not improve from 0.67006\n",
      "5810/5810 [==============================] - 101s 17ms/step - loss: 0.2393 - accuracy: 0.6372 - val_loss: 0.2460 - val_accuracy: 0.6071\n",
      "Epoch 40/200\n",
      "5809/5810 [============================>.] - ETA: 0s - loss: 0.2379 - accuracy: 0.6390\n",
      "Epoch 00040: val_accuracy did not improve from 0.67006\n",
      "5810/5810 [==============================] - 101s 17ms/step - loss: 0.2379 - accuracy: 0.6390 - val_loss: 0.2691 - val_accuracy: 0.5675\n",
      "Epoch 41/200\n",
      "5809/5810 [============================>.] - ETA: 0s - loss: 0.2370 - accuracy: 0.6439\n",
      "Epoch 00041: val_accuracy did not improve from 0.67006\n",
      "5810/5810 [==============================] - 101s 17ms/step - loss: 0.2370 - accuracy: 0.6439 - val_loss: 0.2370 - val_accuracy: 0.6267\n",
      "Epoch 42/200\n",
      "5807/5810 [============================>.] - ETA: 0s - loss: 0.2362 - accuracy: 0.6442\n",
      "Epoch 00042: val_accuracy did not improve from 0.67006\n",
      "5810/5810 [==============================] - 102s 17ms/step - loss: 0.2362 - accuracy: 0.6442 - val_loss: 0.2182 - val_accuracy: 0.6580\n",
      "Epoch 43/200\n",
      "5809/5810 [============================>.] - ETA: 0s - loss: 0.2347 - accuracy: 0.6486\n",
      "Epoch 00043: val_accuracy did not improve from 0.67006\n",
      "5810/5810 [==============================] - 102s 17ms/step - loss: 0.2347 - accuracy: 0.6486 - val_loss: 0.2269 - val_accuracy: 0.6346\n",
      "Epoch 44/200\n",
      "5809/5810 [============================>.] - ETA: 0s - loss: 0.2336 - accuracy: 0.6490\n",
      "Epoch 00044: val_accuracy improved from 0.67006 to 0.68643, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2003/epoch_44_valloss_0.2075_valacc_0.6864.hdf5\n",
      "5810/5810 [==============================] - 102s 18ms/step - loss: 0.2336 - accuracy: 0.6490 - val_loss: 0.2075 - val_accuracy: 0.6864\n",
      "Epoch 45/200\n",
      "5808/5810 [============================>.] - ETA: 0s - loss: 0.2334 - accuracy: 0.6506\n",
      "Epoch 00045: val_accuracy did not improve from 0.68643\n",
      "5810/5810 [==============================] - 102s 18ms/step - loss: 0.2334 - accuracy: 0.6506 - val_loss: 0.2400 - val_accuracy: 0.6161\n",
      "Epoch 46/200\n",
      "5808/5810 [============================>.] - ETA: 0s - loss: 0.2320 - accuracy: 0.6533\n",
      "Epoch 00046: val_accuracy did not improve from 0.68643\n",
      "5810/5810 [==============================] - 102s 17ms/step - loss: 0.2320 - accuracy: 0.6533 - val_loss: 0.2133 - val_accuracy: 0.6745\n",
      "Epoch 47/200\n",
      "5810/5810 [==============================] - ETA: 0s - loss: 0.2312 - accuracy: 0.6539\n",
      "Epoch 00047: val_accuracy did not improve from 0.68643\n",
      "5810/5810 [==============================] - 102s 17ms/step - loss: 0.2312 - accuracy: 0.6539 - val_loss: 0.2393 - val_accuracy: 0.6203\n",
      "Epoch 48/200\n",
      "5808/5810 [============================>.] - ETA: 0s - loss: 0.2309 - accuracy: 0.6562\n",
      "Epoch 00048: val_accuracy did not improve from 0.68643\n",
      "5810/5810 [==============================] - 102s 18ms/step - loss: 0.2308 - accuracy: 0.6562 - val_loss: 0.2234 - val_accuracy: 0.6588\n",
      "Epoch 49/200\n",
      "5809/5810 [============================>.] - ETA: 0s - loss: 0.2296 - accuracy: 0.6585\n",
      "Epoch 00049: val_accuracy did not improve from 0.68643\n",
      "5810/5810 [==============================] - 102s 17ms/step - loss: 0.2296 - accuracy: 0.6586 - val_loss: 0.2318 - val_accuracy: 0.6379\n",
      "Epoch 50/200\n",
      "5808/5810 [============================>.] - ETA: 0s - loss: 0.2289 - accuracy: 0.6582\n",
      "Epoch 00050: val_accuracy did not improve from 0.68643\n",
      "5810/5810 [==============================] - 102s 18ms/step - loss: 0.2289 - accuracy: 0.6582 - val_loss: 0.2279 - val_accuracy: 0.6526\n",
      "Epoch 51/200\n",
      "5810/5810 [==============================] - ETA: 0s - loss: 0.2284 - accuracy: 0.6603\n",
      "Epoch 00051: val_accuracy did not improve from 0.68643\n",
      "5810/5810 [==============================] - 102s 18ms/step - loss: 0.2284 - accuracy: 0.6603 - val_loss: 0.2254 - val_accuracy: 0.6437\n",
      "Epoch 52/200\n",
      "5808/5810 [============================>.] - ETA: 0s - loss: 0.2270 - accuracy: 0.6634\n",
      "Epoch 00052: val_accuracy did not improve from 0.68643\n",
      "5810/5810 [==============================] - 102s 18ms/step - loss: 0.2271 - accuracy: 0.6634 - val_loss: 0.2138 - val_accuracy: 0.6783\n",
      "Epoch 53/200\n",
      "5808/5810 [============================>.] - ETA: 0s - loss: 0.2267 - accuracy: 0.6655\n",
      "Epoch 00053: val_accuracy did not improve from 0.68643\n",
      "5810/5810 [==============================] - 102s 18ms/step - loss: 0.2267 - accuracy: 0.6655 - val_loss: 0.2170 - val_accuracy: 0.6659\n",
      "Epoch 54/200\n",
      "5808/5810 [============================>.] - ETA: 0s - loss: 0.2257 - accuracy: 0.6657\n",
      "Epoch 00054: val_accuracy did not improve from 0.68643\n",
      "5810/5810 [==============================] - 102s 17ms/step - loss: 0.2257 - accuracy: 0.6657 - val_loss: 0.2330 - val_accuracy: 0.6392\n",
      "Epoch 55/200\n",
      "5810/5810 [==============================] - ETA: 0s - loss: 0.2257 - accuracy: 0.6661\n",
      "Epoch 00055: val_accuracy did not improve from 0.68643\n",
      "5810/5810 [==============================] - 102s 18ms/step - loss: 0.2257 - accuracy: 0.6661 - val_loss: 0.2176 - val_accuracy: 0.6703\n",
      "Epoch 56/200\n",
      "5809/5810 [============================>.] - ETA: 0s - loss: 0.2240 - accuracy: 0.6699\n",
      "Epoch 00056: val_accuracy did not improve from 0.68643\n",
      "5810/5810 [==============================] - 102s 18ms/step - loss: 0.2240 - accuracy: 0.6699 - val_loss: 0.2765 - val_accuracy: 0.5643\n",
      "Epoch 57/200\n",
      "5807/5810 [============================>.] - ETA: 0s - loss: 0.2239 - accuracy: 0.6715\n",
      "Epoch 00057: val_accuracy did not improve from 0.68643\n",
      "5810/5810 [==============================] - 102s 18ms/step - loss: 0.2239 - accuracy: 0.6715 - val_loss: 0.2276 - val_accuracy: 0.6471\n",
      "Epoch 58/200\n",
      "5810/5810 [==============================] - ETA: 0s - loss: 0.2233 - accuracy: 0.6715\n",
      "Epoch 00058: val_accuracy did not improve from 0.68643\n",
      "5810/5810 [==============================] - 102s 18ms/step - loss: 0.2233 - accuracy: 0.6715 - val_loss: 0.2474 - val_accuracy: 0.6167\n",
      "Epoch 59/200\n",
      "5808/5810 [============================>.] - ETA: 0s - loss: 0.2230 - accuracy: 0.6721\n",
      "Epoch 00059: val_accuracy did not improve from 0.68643\n",
      "5810/5810 [==============================] - 102s 18ms/step - loss: 0.2230 - accuracy: 0.6721 - val_loss: 0.2110 - val_accuracy: 0.6795\n",
      "Epoch 60/200\n",
      "5810/5810 [==============================] - ETA: 0s - loss: 0.2220 - accuracy: 0.6734\n",
      "Epoch 00060: val_accuracy did not improve from 0.68643\n",
      "5810/5810 [==============================] - 102s 18ms/step - loss: 0.2220 - accuracy: 0.6734 - val_loss: 0.2475 - val_accuracy: 0.6114\n",
      "Epoch 61/200\n",
      "5808/5810 [============================>.] - ETA: 0s - loss: 0.2206 - accuracy: 0.6755\n",
      "Epoch 00061: val_accuracy did not improve from 0.68643\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.2206 - accuracy: 0.6755 - val_loss: 0.2283 - val_accuracy: 0.6590\n",
      "Epoch 62/200\n",
      "5810/5810 [==============================] - ETA: 0s - loss: 0.2213 - accuracy: 0.6761\n",
      "Epoch 00062: val_accuracy did not improve from 0.68643\n",
      "5810/5810 [==============================] - 102s 18ms/step - loss: 0.2213 - accuracy: 0.6761 - val_loss: 0.2290 - val_accuracy: 0.6499\n",
      "Epoch 63/200\n",
      "5810/5810 [==============================] - ETA: 0s - loss: 0.2201 - accuracy: 0.6772\n",
      "Epoch 00063: val_accuracy did not improve from 0.68643\n",
      "5810/5810 [==============================] - 102s 18ms/step - loss: 0.2201 - accuracy: 0.6772 - val_loss: 0.2562 - val_accuracy: 0.6023\n",
      "Epoch 64/200\n",
      "5809/5810 [============================>.] - ETA: 0s - loss: 0.2199 - accuracy: 0.6794\n",
      "Epoch 00064: val_accuracy did not improve from 0.68643\n",
      "5810/5810 [==============================] - 102s 18ms/step - loss: 0.2199 - accuracy: 0.6793 - val_loss: 0.2186 - val_accuracy: 0.6661\n",
      "Epoch 65/200\n",
      "5808/5810 [============================>.] - ETA: 0s - loss: 0.2187 - accuracy: 0.6799\n",
      "Epoch 00065: val_accuracy did not improve from 0.68643\n",
      "5810/5810 [==============================] - 102s 18ms/step - loss: 0.2187 - accuracy: 0.6800 - val_loss: 0.2301 - val_accuracy: 0.6504\n",
      "Epoch 66/200\n",
      "5809/5810 [============================>.] - ETA: 0s - loss: 0.2186 - accuracy: 0.6795\n",
      "Epoch 00066: val_accuracy did not improve from 0.68643\n",
      "5810/5810 [==============================] - 102s 18ms/step - loss: 0.2185 - accuracy: 0.6795 - val_loss: 0.2285 - val_accuracy: 0.6484\n",
      "Epoch 67/200\n",
      "5808/5810 [============================>.] - ETA: 0s - loss: 0.2184 - accuracy: 0.6808\n",
      "Epoch 00067: val_accuracy did not improve from 0.68643\n",
      "5810/5810 [==============================] - 102s 18ms/step - loss: 0.2184 - accuracy: 0.6808 - val_loss: 0.2262 - val_accuracy: 0.6576\n",
      "Epoch 68/200\n",
      "5807/5810 [============================>.] - ETA: 0s - loss: 0.2169 - accuracy: 0.6847\n",
      "Epoch 00068: val_accuracy did not improve from 0.68643\n",
      "5810/5810 [==============================] - 102s 18ms/step - loss: 0.2169 - accuracy: 0.6846 - val_loss: 0.2318 - val_accuracy: 0.6477\n",
      "Epoch 69/200\n",
      "5807/5810 [============================>.] - ETA: 0s - loss: 0.2169 - accuracy: 0.6850\n",
      "Epoch 00069: val_accuracy did not improve from 0.68643\n",
      "5810/5810 [==============================] - 102s 18ms/step - loss: 0.2169 - accuracy: 0.6850 - val_loss: 0.2208 - val_accuracy: 0.6698\n",
      "Epoch 70/200\n",
      "5809/5810 [============================>.] - ETA: 0s - loss: 0.2161 - accuracy: 0.6854\n",
      "Epoch 00070: val_accuracy did not improve from 0.68643\n",
      "5810/5810 [==============================] - 102s 18ms/step - loss: 0.2161 - accuracy: 0.6855 - val_loss: 0.2162 - val_accuracy: 0.6713\n",
      "Epoch 71/200\n",
      "5810/5810 [==============================] - ETA: 0s - loss: 0.2159 - accuracy: 0.6865\n",
      "Epoch 00071: val_accuracy improved from 0.68643 to 0.69409, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2003/epoch_71_valloss_0.2056_valacc_0.6941.hdf5\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.2159 - accuracy: 0.6865 - val_loss: 0.2056 - val_accuracy: 0.6941\n",
      "Epoch 72/200\n",
      "5810/5810 [==============================] - ETA: 0s - loss: 0.2153 - accuracy: 0.6888\n",
      "Epoch 00072: val_accuracy did not improve from 0.69409\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.2153 - accuracy: 0.6888 - val_loss: 0.2451 - val_accuracy: 0.6235\n",
      "Epoch 73/200\n",
      "5810/5810 [==============================] - ETA: 0s - loss: 0.2148 - accuracy: 0.6895\n",
      "Epoch 00073: val_accuracy did not improve from 0.69409\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.2148 - accuracy: 0.6895 - val_loss: 0.2404 - val_accuracy: 0.6348\n",
      "Epoch 74/200\n",
      "5809/5810 [============================>.] - ETA: 0s - loss: 0.2145 - accuracy: 0.6909\n",
      "Epoch 00074: val_accuracy did not improve from 0.69409\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.2145 - accuracy: 0.6909 - val_loss: 0.2132 - val_accuracy: 0.6775\n",
      "Epoch 75/200\n",
      "5809/5810 [============================>.] - ETA: 0s - loss: 0.2136 - accuracy: 0.6910\n",
      "Epoch 00075: val_accuracy did not improve from 0.69409\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.2136 - accuracy: 0.6910 - val_loss: 0.2242 - val_accuracy: 0.6600\n",
      "Epoch 76/200\n",
      "5807/5810 [============================>.] - ETA: 0s - loss: 0.2132 - accuracy: 0.6943\n",
      "Epoch 00076: val_accuracy did not improve from 0.69409\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.2132 - accuracy: 0.6943 - val_loss: 0.2573 - val_accuracy: 0.6003\n",
      "Epoch 77/200\n",
      "5809/5810 [============================>.] - ETA: 0s - loss: 0.2135 - accuracy: 0.6922\n",
      "Epoch 00077: val_accuracy did not improve from 0.69409\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.2135 - accuracy: 0.6922 - val_loss: 0.2193 - val_accuracy: 0.6672\n",
      "Epoch 78/200\n",
      "5810/5810 [==============================] - ETA: 0s - loss: 0.2123 - accuracy: 0.6956\n",
      "Epoch 00078: val_accuracy did not improve from 0.69409\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.2123 - accuracy: 0.6956 - val_loss: 0.2148 - val_accuracy: 0.6741\n",
      "Epoch 79/200\n",
      "5807/5810 [============================>.] - ETA: 0s - loss: 0.2127 - accuracy: 0.6928\n",
      "Epoch 00079: val_accuracy did not improve from 0.69409\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.2128 - accuracy: 0.6927 - val_loss: 0.2061 - val_accuracy: 0.6938\n",
      "Epoch 80/200\n",
      "5810/5810 [==============================] - ETA: 0s - loss: 0.2114 - accuracy: 0.6966\n",
      "Epoch 00080: val_accuracy did not improve from 0.69409\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.2114 - accuracy: 0.6966 - val_loss: 0.2407 - val_accuracy: 0.6359\n",
      "Epoch 81/200\n",
      "5807/5810 [============================>.] - ETA: 0s - loss: 0.2118 - accuracy: 0.6966\n",
      "Epoch 00081: val_accuracy improved from 0.69409 to 0.69680, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2003/epoch_81_valloss_0.2055_valacc_0.6968.hdf5\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.2118 - accuracy: 0.6966 - val_loss: 0.2055 - val_accuracy: 0.6968\n",
      "Epoch 82/200\n",
      "5808/5810 [============================>.] - ETA: 0s - loss: 0.2112 - accuracy: 0.6969\n",
      "Epoch 00082: val_accuracy did not improve from 0.69680\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.2112 - accuracy: 0.6968 - val_loss: 0.2204 - val_accuracy: 0.6737\n",
      "Epoch 83/200\n",
      "5810/5810 [==============================] - ETA: 0s - loss: 0.2099 - accuracy: 0.7002\n",
      "Epoch 00083: val_accuracy did not improve from 0.69680\n",
      "5810/5810 [==============================] - 102s 18ms/step - loss: 0.2099 - accuracy: 0.7002 - val_loss: 0.2195 - val_accuracy: 0.6652\n",
      "Epoch 84/200\n",
      "5809/5810 [============================>.] - ETA: 0s - loss: 0.2095 - accuracy: 0.7001\n",
      "Epoch 00084: val_accuracy did not improve from 0.69680\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.2095 - accuracy: 0.7001 - val_loss: 0.2228 - val_accuracy: 0.6641\n",
      "Epoch 85/200\n",
      "5809/5810 [============================>.] - ETA: 0s - loss: 0.2102 - accuracy: 0.6993\n",
      "Epoch 00085: val_accuracy improved from 0.69680 to 0.70165, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2003/epoch_85_valloss_0.2016_valacc_0.7016.hdf5\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.2102 - accuracy: 0.6993 - val_loss: 0.2016 - val_accuracy: 0.7016\n",
      "Epoch 86/200\n",
      "5809/5810 [============================>.] - ETA: 0s - loss: 0.2092 - accuracy: 0.7014\n",
      "Epoch 00086: val_accuracy did not improve from 0.70165\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.2092 - accuracy: 0.7015 - val_loss: 0.2184 - val_accuracy: 0.6750\n",
      "Epoch 87/200\n",
      "5807/5810 [============================>.] - ETA: 0s - loss: 0.2093 - accuracy: 0.7002\n",
      "Epoch 00087: val_accuracy did not improve from 0.70165\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.2092 - accuracy: 0.7003 - val_loss: 0.2075 - val_accuracy: 0.6963\n",
      "Epoch 88/200\n",
      "5810/5810 [==============================] - ETA: 0s - loss: 0.2089 - accuracy: 0.7006\n",
      "Epoch 00088: val_accuracy did not improve from 0.70165\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.2089 - accuracy: 0.7006 - val_loss: 0.2242 - val_accuracy: 0.6603\n",
      "Epoch 89/200\n",
      "5807/5810 [============================>.] - ETA: 0s - loss: 0.2078 - accuracy: 0.7042\n",
      "Epoch 00089: val_accuracy did not improve from 0.70165\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.2077 - accuracy: 0.7042 - val_loss: 0.2164 - val_accuracy: 0.6806\n",
      "Epoch 90/200\n",
      "5808/5810 [============================>.] - ETA: 0s - loss: 0.2072 - accuracy: 0.7034\n",
      "Epoch 00090: val_accuracy did not improve from 0.70165\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.2072 - accuracy: 0.7034 - val_loss: 0.2129 - val_accuracy: 0.6855\n",
      "Epoch 91/200\n",
      "5809/5810 [============================>.] - ETA: 0s - loss: 0.2078 - accuracy: 0.7043\n",
      "Epoch 00091: val_accuracy did not improve from 0.70165\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.2078 - accuracy: 0.7043 - val_loss: 0.2163 - val_accuracy: 0.6777\n",
      "Epoch 92/200\n",
      "5809/5810 [============================>.] - ETA: 0s - loss: 0.2071 - accuracy: 0.7049\n",
      "Epoch 00092: val_accuracy did not improve from 0.70165\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.2071 - accuracy: 0.7049 - val_loss: 0.2581 - val_accuracy: 0.6106\n",
      "Epoch 93/200\n",
      "5809/5810 [============================>.] - ETA: 0s - loss: 0.2066 - accuracy: 0.7064\n",
      "Epoch 00093: val_accuracy did not improve from 0.70165\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.2066 - accuracy: 0.7064 - val_loss: 0.2360 - val_accuracy: 0.6446\n",
      "Epoch 94/200\n",
      "5810/5810 [==============================] - ETA: 0s - loss: 0.2057 - accuracy: 0.7079\n",
      "Epoch 00094: val_accuracy improved from 0.70165 to 0.71434, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2003/epoch_94_valloss_0.1984_valacc_0.7143.hdf5\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.2057 - accuracy: 0.7079 - val_loss: 0.1984 - val_accuracy: 0.7143\n",
      "Epoch 95/200\n",
      "5809/5810 [============================>.] - ETA: 0s - loss: 0.2058 - accuracy: 0.7089\n",
      "Epoch 00095: val_accuracy did not improve from 0.71434\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.2058 - accuracy: 0.7089 - val_loss: 0.2120 - val_accuracy: 0.6868\n",
      "Epoch 96/200\n",
      "5810/5810 [==============================] - ETA: 0s - loss: 0.2057 - accuracy: 0.7084\n",
      "Epoch 00096: val_accuracy did not improve from 0.71434\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.2057 - accuracy: 0.7084 - val_loss: 0.2185 - val_accuracy: 0.6736\n",
      "Epoch 97/200\n",
      "5809/5810 [============================>.] - ETA: 0s - loss: 0.2057 - accuracy: 0.7079\n",
      "Epoch 00097: val_accuracy did not improve from 0.71434\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.2057 - accuracy: 0.7079 - val_loss: 0.2187 - val_accuracy: 0.6760\n",
      "Epoch 98/200\n",
      "5808/5810 [============================>.] - ETA: 0s - loss: 0.2045 - accuracy: 0.7110\n",
      "Epoch 00098: val_accuracy did not improve from 0.71434\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.2045 - accuracy: 0.7110 - val_loss: 0.2348 - val_accuracy: 0.6578\n",
      "Epoch 99/200\n",
      "5807/5810 [============================>.] - ETA: 0s - loss: 0.2048 - accuracy: 0.7111\n",
      "Epoch 00099: val_accuracy did not improve from 0.71434\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.2048 - accuracy: 0.7112 - val_loss: 0.2367 - val_accuracy: 0.6401\n",
      "Epoch 100/200\n",
      "5810/5810 [==============================] - ETA: 0s - loss: 0.2034 - accuracy: 0.7145\n",
      "Epoch 00100: val_accuracy did not improve from 0.71434\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.2034 - accuracy: 0.7145 - val_loss: 0.2311 - val_accuracy: 0.6561\n",
      "Epoch 101/200\n",
      "5810/5810 [==============================] - ETA: 0s - loss: 0.2035 - accuracy: 0.7129\n",
      "Epoch 00101: val_accuracy did not improve from 0.71434\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.2035 - accuracy: 0.7129 - val_loss: 0.2249 - val_accuracy: 0.6636\n",
      "Epoch 102/200\n",
      "5810/5810 [==============================] - ETA: 0s - loss: 0.2039 - accuracy: 0.7134\n",
      "Epoch 00102: val_accuracy did not improve from 0.71434\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.2039 - accuracy: 0.7134 - val_loss: 0.2409 - val_accuracy: 0.6441\n",
      "Epoch 103/200\n",
      "5808/5810 [============================>.] - ETA: 0s - loss: 0.2026 - accuracy: 0.7151\n",
      "Epoch 00103: val_accuracy did not improve from 0.71434\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.2026 - accuracy: 0.7150 - val_loss: 0.2284 - val_accuracy: 0.6575\n",
      "Epoch 104/200\n",
      "5809/5810 [============================>.] - ETA: 0s - loss: 0.2025 - accuracy: 0.7161\n",
      "Epoch 00104: val_accuracy did not improve from 0.71434\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.2025 - accuracy: 0.7160 - val_loss: 0.2506 - val_accuracy: 0.6189\n",
      "Epoch 105/200\n",
      "5809/5810 [============================>.] - ETA: 0s - loss: 0.2019 - accuracy: 0.7162\n",
      "Epoch 00105: val_accuracy did not improve from 0.71434\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.2019 - accuracy: 0.7162 - val_loss: 0.2614 - val_accuracy: 0.6091\n",
      "Epoch 106/200\n",
      "5810/5810 [==============================] - ETA: 0s - loss: 0.2014 - accuracy: 0.7179\n",
      "Epoch 00106: val_accuracy did not improve from 0.71434\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.2014 - accuracy: 0.7179 - val_loss: 0.2182 - val_accuracy: 0.6827\n",
      "Epoch 107/200\n",
      "5810/5810 [==============================] - ETA: 0s - loss: 0.2013 - accuracy: 0.7177\n",
      "Epoch 00107: val_accuracy did not improve from 0.71434\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.2013 - accuracy: 0.7177 - val_loss: 0.2352 - val_accuracy: 0.6492\n",
      "Epoch 108/200\n",
      "5809/5810 [============================>.] - ETA: 0s - loss: 0.2014 - accuracy: 0.7177\n",
      "Epoch 00108: val_accuracy did not improve from 0.71434\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.2014 - accuracy: 0.7177 - val_loss: 0.2020 - val_accuracy: 0.7063\n",
      "Epoch 109/200\n",
      "5810/5810 [==============================] - ETA: 0s - loss: 0.2003 - accuracy: 0.7186\n",
      "Epoch 00109: val_accuracy did not improve from 0.71434\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.2003 - accuracy: 0.7186 - val_loss: 0.2266 - val_accuracy: 0.6595\n",
      "Epoch 110/200\n",
      "5808/5810 [============================>.] - ETA: 0s - loss: 0.2009 - accuracy: 0.7188\n",
      "Epoch 00110: val_accuracy did not improve from 0.71434\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.2009 - accuracy: 0.7188 - val_loss: 0.2264 - val_accuracy: 0.6717\n",
      "Epoch 111/200\n",
      "5810/5810 [==============================] - ETA: 0s - loss: 0.2005 - accuracy: 0.7186\n",
      "Epoch 00111: val_accuracy did not improve from 0.71434\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.2005 - accuracy: 0.7186 - val_loss: 0.2369 - val_accuracy: 0.6422\n",
      "Epoch 112/200\n",
      "5809/5810 [============================>.] - ETA: 0s - loss: 0.1998 - accuracy: 0.7207\n",
      "Epoch 00112: val_accuracy did not improve from 0.71434\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.1998 - accuracy: 0.7207 - val_loss: 0.2188 - val_accuracy: 0.6821\n",
      "Epoch 113/200\n",
      "5810/5810 [==============================] - ETA: 0s - loss: 0.2001 - accuracy: 0.7217\n",
      "Epoch 00113: val_accuracy did not improve from 0.71434\n",
      "5810/5810 [==============================] - 105s 18ms/step - loss: 0.2001 - accuracy: 0.7217 - val_loss: 0.2122 - val_accuracy: 0.6807\n",
      "Epoch 114/200\n",
      "5809/5810 [============================>.] - ETA: 0s - loss: 0.1990 - accuracy: 0.7216\n",
      "Epoch 00114: val_accuracy did not improve from 0.71434\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.1990 - accuracy: 0.7216 - val_loss: 0.2251 - val_accuracy: 0.6725\n",
      "Epoch 115/200\n",
      "5810/5810 [==============================] - ETA: 0s - loss: 0.1995 - accuracy: 0.7211\n",
      "Epoch 00115: val_accuracy did not improve from 0.71434\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.1995 - accuracy: 0.7211 - val_loss: 0.2359 - val_accuracy: 0.6446\n",
      "Epoch 116/200\n",
      "5807/5810 [============================>.] - ETA: 0s - loss: 0.1983 - accuracy: 0.7246\n",
      "Epoch 00116: val_accuracy did not improve from 0.71434\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.1982 - accuracy: 0.7246 - val_loss: 0.2698 - val_accuracy: 0.5845\n",
      "Epoch 117/200\n",
      "5808/5810 [============================>.] - ETA: 0s - loss: 0.1983 - accuracy: 0.7230\n",
      "Epoch 00117: val_accuracy did not improve from 0.71434\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.1983 - accuracy: 0.7230 - val_loss: 0.2692 - val_accuracy: 0.5994\n",
      "Epoch 118/200\n",
      "5808/5810 [============================>.] - ETA: 0s - loss: 0.1982 - accuracy: 0.7234\n",
      "Epoch 00118: val_accuracy did not improve from 0.71434\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.1982 - accuracy: 0.7233 - val_loss: 0.2849 - val_accuracy: 0.6033\n",
      "Epoch 119/200\n",
      "5808/5810 [============================>.] - ETA: 0s - loss: 0.1983 - accuracy: 0.7257\n",
      "Epoch 00119: val_accuracy did not improve from 0.71434\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.1983 - accuracy: 0.7257 - val_loss: 0.2751 - val_accuracy: 0.5964\n",
      "Epoch 120/200\n",
      "5810/5810 [==============================] - ETA: 0s - loss: 0.1979 - accuracy: 0.7236\n",
      "Epoch 00120: val_accuracy did not improve from 0.71434\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.1979 - accuracy: 0.7236 - val_loss: 0.2467 - val_accuracy: 0.6298\n",
      "Epoch 121/200\n",
      "5810/5810 [==============================] - ETA: 0s - loss: 0.1968 - accuracy: 0.7275\n",
      "Epoch 00121: val_accuracy did not improve from 0.71434\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.1968 - accuracy: 0.7275 - val_loss: 0.2190 - val_accuracy: 0.6758\n",
      "Epoch 122/200\n",
      "5808/5810 [============================>.] - ETA: 0s - loss: 0.1967 - accuracy: 0.7290\n",
      "Epoch 00122: val_accuracy did not improve from 0.71434\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.1967 - accuracy: 0.7290 - val_loss: 0.2707 - val_accuracy: 0.5980\n",
      "Epoch 123/200\n",
      "5808/5810 [============================>.] - ETA: 0s - loss: 0.1972 - accuracy: 0.7280\n",
      "Epoch 00123: val_accuracy did not improve from 0.71434\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.1972 - accuracy: 0.7279 - val_loss: 0.2512 - val_accuracy: 0.6296\n",
      "Epoch 124/200\n",
      "5810/5810 [==============================] - ETA: 0s - loss: 0.1965 - accuracy: 0.7287\n",
      "Epoch 00124: val_accuracy did not improve from 0.71434\n",
      "5810/5810 [==============================] - 104s 18ms/step - loss: 0.1965 - accuracy: 0.7287 - val_loss: 0.2656 - val_accuracy: 0.6183\n",
      "Epoch 125/200\n",
      "5807/5810 [============================>.] - ETA: 0s - loss: 0.1962 - accuracy: 0.7286\n",
      "Epoch 00125: val_accuracy did not improve from 0.71434\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.1962 - accuracy: 0.7286 - val_loss: 0.2099 - val_accuracy: 0.6925\n",
      "Epoch 126/200\n",
      "5808/5810 [============================>.] - ETA: 0s - loss: 0.1957 - accuracy: 0.7294\n",
      "Epoch 00126: val_accuracy did not improve from 0.71434\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.1957 - accuracy: 0.7294 - val_loss: 0.2582 - val_accuracy: 0.6177\n",
      "Epoch 127/200\n",
      "5808/5810 [============================>.] - ETA: 0s - loss: 0.1958 - accuracy: 0.7296\n",
      "Epoch 00127: val_accuracy did not improve from 0.71434\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.1958 - accuracy: 0.7296 - val_loss: 0.2251 - val_accuracy: 0.6703\n",
      "Epoch 128/200\n",
      "5810/5810 [==============================] - ETA: 0s - loss: 0.1952 - accuracy: 0.7315\n",
      "Epoch 00128: val_accuracy did not improve from 0.71434\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.1952 - accuracy: 0.7315 - val_loss: 0.2655 - val_accuracy: 0.6097\n",
      "Epoch 129/200\n",
      "5810/5810 [==============================] - ETA: 0s - loss: 0.1947 - accuracy: 0.7315\n",
      "Epoch 00129: val_accuracy did not improve from 0.71434\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.1947 - accuracy: 0.7315 - val_loss: 0.2858 - val_accuracy: 0.5732\n",
      "Epoch 130/200\n",
      "5808/5810 [============================>.] - ETA: 0s - loss: 0.1954 - accuracy: 0.7304\n",
      "Epoch 00130: val_accuracy did not improve from 0.71434\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.1955 - accuracy: 0.7303 - val_loss: 0.2856 - val_accuracy: 0.5960\n",
      "Epoch 131/200\n",
      "5807/5810 [============================>.] - ETA: 0s - loss: 0.1943 - accuracy: 0.7326\n",
      "Epoch 00131: val_accuracy did not improve from 0.71434\n",
      "5810/5810 [==============================] - 104s 18ms/step - loss: 0.1943 - accuracy: 0.7326 - val_loss: 0.2744 - val_accuracy: 0.6005\n",
      "Epoch 132/200\n",
      "5810/5810 [==============================] - ETA: 0s - loss: 0.1944 - accuracy: 0.7325\n",
      "Epoch 00132: val_accuracy did not improve from 0.71434\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.1944 - accuracy: 0.7325 - val_loss: 0.2595 - val_accuracy: 0.6178\n",
      "Epoch 133/200\n",
      "5810/5810 [==============================] - ETA: 0s - loss: 0.1939 - accuracy: 0.7326\n",
      "Epoch 00133: val_accuracy did not improve from 0.71434\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.1939 - accuracy: 0.7326 - val_loss: 0.2415 - val_accuracy: 0.6533\n",
      "Epoch 134/200\n",
      "5809/5810 [============================>.] - ETA: 0s - loss: 0.1936 - accuracy: 0.7328\n",
      "Epoch 00134: val_accuracy did not improve from 0.71434\n",
      "5810/5810 [==============================] - 103s 18ms/step - loss: 0.1936 - accuracy: 0.7328 - val_loss: 0.2575 - val_accuracy: 0.6271\n",
      "Epoch 00134: early stopping\n"
     ]
    }
   ],
   "source": [
    "# model = model_cnn14_attention_multi(dim_time, dim_freq, num_species, model_type='feature_level_attention', conv_dim=conv_dim, pool_size=pool_size, pool_stride=pool_stride, hidden_units=hidden_units, l2_regu=l2_regu, drop_rate=drop_rate)\n",
    "model = model_cnn14_spp(dim_time, dim_freq, num_species, conv_dim=conv_dim, pool_size=pool_size, pool_stride=pool_stride, hidden_units=hidden_units, l2_regu=l2_regu, drop_rate=drop_rate)\n",
    "# loss = CategoricalCrossentropy()\n",
    "loss = binary_crossentropy\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate_fn), loss=loss, metrics=['accuracy'])\n",
    "\n",
    "# With classes\n",
    "# history = model.fit(fea_train, to_categorical(label_train), class_weight=class_weights, validation_split=0.3, batch_size=batch_size, epochs=num_epoch, callbacks=[EarlyStopping(patience=num_patience), ModelCheckpoint(filepath=os.path.join(fit_result_path, '{epoch:02d}-{val_loss:.4f}.hdf5'), verbose=1, monitor=\"val_loss\", save_best_only=True)])\n",
    "# history = model.fit(train_generator, validation_data=validate_generator, class_weight=class_weights, epochs=num_epoch, callbacks=[EarlyStopping(patience=num_patience, monitor='val_loss', mode='min', verbose=1), TensorBoard(log_dir=fit_result_path1), ModelCheckpoint(filepath=os.path.join(fit_result_path1, '{epoch:02d}-{val_loss:.4f}.hdf5'), verbose=1, monitor=\"val_loss\", save_best_only=True)])\n",
    "# history = model.fit(train_generator, validation_data=validate_generator, class_weight=class_weights, epochs=num_epoch, callbacks=[EarlyStopping(patience=num_patience, monitor='val_loss', mode='min', verbose=1), TensorBoard(log_dir=fit_result_path2), ModelCheckpoint(filepath=os.path.join(fit_result_path2, 'epoch_{epoch:02d}_valloss_{val_loss:.4f}_valacc_{val_accuracy:.4f}.hdf5' ), verbose=1, monitor=\"val_accuracy\", save_best_only=True)])\n",
    "history = model.fit(train_generator, validation_data=validate_generator, class_weight=class_weights, epochs=num_epoch, callbacks=[EarlyStopping(patience=num_patience, monitor='val_accuracy', mode='max', verbose=1), TensorBoard(log_dir=fit_result_path2), ModelCheckpoint(filepath=os.path.join(fit_result_path2, 'epoch_{epoch:02d}_valloss_{val_loss:.4f}_valacc_{val_accuracy:.4f}.hdf5' ), verbose=1, monitor=\"val_accuracy\", save_best_only=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model:0.7143\n",
      "/home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2003/epoch_94_valloss_0.1984_valacc_0.7143.hdf5\n"
     ]
    }
   ],
   "source": [
    "# fit_result_path1 = '/home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210210_224527'\n",
    "the_best_model, _ = find_best_model(fit_result_path2, purge=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 100, 128, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 100, 128, 16)      160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 100, 128, 16)      64        \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 100, 128, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 100, 128, 16)      2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 100, 128, 16)      64        \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 100, 128, 16)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 50, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 50, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 50, 64, 32)        4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 50, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 50, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 50, 64, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 50, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 50, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 25, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 25, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 25, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 25, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 25, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 25, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 25, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 25, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 13, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 13, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 13, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 13, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 13, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 13, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 13, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 13, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 7, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 7, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 7, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 7, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 7, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 7, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 7, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 7, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "spatial_pyramid_pooling2d_1  (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               1376512   \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 8)                 2056      \n",
      "=================================================================\n",
      "Total params: 2,695,672\n",
      "Trainable params: 2,692,152\n",
      "Non-trainable params: 3,520\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_model(the_best_model)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pred = model.predict(fea_test)\n",
    "# label_pred = model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=200, precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "['BD', 'CD', 'STR', 'SPT', 'SPIN', 'PLT', 'RT', 'FKW']\n",
      "\n",
      "[[  8   5  44 110  33  12  17   2]\n",
      " [ 13 318 154 159   7  39  56   6]\n",
      " [  1   1  21   8   2   5  15   1]\n",
      " [  0  38 112 217   4  28  11   2]\n",
      " [  1   5  12  26   4   0   1   2]\n",
      " [  0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   2   1  14  55 198]]\n",
      "\n",
      "[[0.03 0.02 0.19 0.48 0.14 0.05 0.07 0.01]\n",
      " [0.02 0.42 0.2  0.21 0.01 0.05 0.07 0.01]\n",
      " [0.02 0.02 0.39 0.15 0.04 0.09 0.28 0.02]\n",
      " [0.   0.09 0.27 0.53 0.01 0.07 0.03 0.  ]\n",
      " [0.02 0.1  0.24 0.51 0.08 0.   0.02 0.04]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.01 0.   0.05 0.2  0.73]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix:\")\n",
    "cm = confusion_matrix(label_test, np.argmax(label_pred, axis=1), labels=species_id)\n",
    "\n",
    "print(species_list)\n",
    "print('')\n",
    "print(cm)\n",
    "print('')\n",
    "\n",
    "cm2 = cm*1.0\n",
    "for ii in range(cm.shape[0]):\n",
    "    cm_row = cm[ii, :]*1.0\n",
    "\n",
    "    cm_row_sum = cm_row.sum()\n",
    "    if cm_row_sum != 0:\n",
    "        cm2[ii, :] = cm_row / cm_row_sum\n",
    "    else:\n",
    "        cm2[ii, :] = np.zeros(cm.shape[1])\n",
    "\n",
    "print(cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics._plot.confusion_matrix import ConfusionMatrixDisplay\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=species_list)\n",
    "disp2 = ConfusionMatrixDisplay(confusion_matrix=cm2, display_labels=species_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fb9bb02e190>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=[15, 15])\n",
    "disp.plot(include_values=True,\n",
    "                     cmap='viridis', ax=ax, xticks_rotation='horizontal',\n",
    "                     values_format=None, colorbar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fb9bb02e2b0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0EAAANDCAYAAABrNRTSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAACC50lEQVR4nOzdd5xcVfnH8e+Z2ZrN9tmaDoGEloQUklBCGh0ERP2pgP5QIVQVREVBLDSVplJ/iCCCCAREWiChJbQkJIEQCCmkl82W2d7LzPn9McvuzmZ2s8jszmTu5/167YvM3OfeOfMw7Znz3DPGWisAAAAAcApXpAcAAAAAAAOJIggAAACAo1AEAQAAAHAUiiAAAAAAjkIRBAAAAMBR4iI9AAAAAADhd9KsFFte4Yv0MHq1ak3zQmvtyQN9uxRBAAAAQAwqr/Dp/YXDIz2MXrkLPvNE4nZphwMAAADgKBRBAAAAAByFdjgAAAAgBllJfvkjPYyoxEwQAAAAAEehCAIAAADgKLTDAQAAADHJymdphwuFmSAAAAAAjkIRBAAAAMBRaIcDAAAAYlBgdTgb6WFEJWaCAAAAADgKRRAAAAAAR6EIAgAAAOAonBMEAAAAxCi/WCI7FGaCAAAAADgKRRAAAAAAR6EdDgAAAIhBVlY+yxLZoTATBAAAAMBRKIIAAAAAOArtcAAAAECM8ot2uFCYCQIAAADgKBRBAAAAAByFdjgAAAAgBllJPtrhQmImCAAAAICjUAQBAAAAcBTa4QAAAIAYxepwoTETBAAAAMBRKIIAAAAAOApFEAAAAABH4ZwgAAAAIAZZST7LOUGhMBMEAAAAwFEoggAAAAA4Cu1wAAAAQIzyR3oAUYqZIAAAAABRyxhzsjFmgzFmkzHmmhDbf2qMWd3+94kxxmeMyertmBRBAAAAAKKSMcYt6R5Jp0g6VNK3jDGHdo2x1t5qrZ1grZ0g6ReSllhrK3o7Lu1wAAAAQAyysvJpv18d7ihJm6y1WyTJGPOEpDMlfdpD/Lck/WtfB2UmCAAAAECkeIwxK7v8XdRt+xBJO7tc3tV+3V6MMYMknSzpmX3dKDNBAAAAACLFa62d3Mt2E+K6nqa3zpD07r5a4SSKIAAAACA2Wcm333fDaZekYV0uD5VU1EPsN9WHVjiJdjgAAAAA0WuFpIOMMaOMMQkKFDrPdw8yxqRLOl7Sc305KDNBAAAAAKKStbbNGHO5pIWS3JIestauNcZc3L79/vbQsyUtstbW9+W4FEEAAABADLKKjR9LtdYukLSg23X3d7v8d0l/7+sxaYcDAAAA4CgUQQAAAAAchXY4AAAAICYZ+UKuMA1mggAAAAA4CkUQAAAAAEehCAIAAADgKJwTBAAAAMQgK8lvIz2K6MRMEAAAAABHoQgCAAAA4Ci0wwEAAAAxiiWyQ2MmCAAAAICjUAQBAAAAcBTa4QAAAIAYZEU7XE+YCQIAAADgKBRBAAAAAByFdjgAAAAgRvkt7XChMBMEAAAAwFEoggAAAAA4Cu1wAAAAQAxidbieMRMEAAAAwFEoggAAAAA4CkUQAAAAAEfhnCAAAAAgBlkZ+ZjzCImsAAAAAHAUiiAAAAAAjkI7HAAAABCj/JYlskNhJggAAACAo1AEAQAAAHAU2uEAAACAGGQl+UQ7XCjMBAEAAABwlJiaCUpwJdlkV2qkhxE7rI30CGKGLz050kOIKf7stkgPIabElbgjPYSYYppaIj2E2OHiu9pwsi08NsOlydarxTYzxbIfi6kiKNmVqunpZ0d6GDHDNjdHeggxo3bOEZEeQkxp+G5VpIcQU7LuSIn0EGJK4oaiSA8hdiQnRXoEMcW3Y1ekhxAzlrUtjPQQ+sjIZ/kyIRSyAgAAAMBRKIIAAAAAOEpMtcMBAAAACLCS/Mx5hERWAAAAADgKRRAAAAAAR6EIAgAAAOAonBMEAAAAxCif+DmjUJgJAgAAAOAoFEEAAAAAHIV2OAAAACAGWWvks8x5hEJWAAAAADgKRRAAAAAAR6EdDgAAAIhRflaHC4mZIAAAAACOQhEEAAAAwFFohwMAAABikJXkY84jJLICAAAAwFEoggAAAAA4Cu1wAAAAQEzix1J7QlYAAAAAOApFEAAAAABHoR0OAAAAiEFWkp85j5DICgAAAABHoQgCAAAA4CgUQQAAAAAchXOCAAAAgBjlsybSQ4hKzAQBAAAAcBSKIAAAAACOQjscAAAAEIOsjHzMeYREVgAAAAA4CkUQAAAAAEehHQ4AAACIUX7LnEcoZAUAAACAo1AEAQAAAHAU2uEAAACAGGQlVofrAVkBAAAA4CjMBIXRpGPLNe+aTXK5rRY+U6D5D47oFmE17xebNGVGuZob3brj2rHavC5V8Qk+/fEfqxWf4JfbbfXOohz9855REbkP0WTSjEpdfN02udxWrzyVp/n/N6RbhNXFv9qmKTMr1dzo1u0/P1Cb1w6Wp6BZV9+6SZmeVlkrvfxEnp57pCAi9yGaTD1kp350zntyuaxeXDpWj706IWj78Lwq/fLcxTp4qFd/fXGK/vXG+I5tXz/+Y51x9HoZIz3/3ljNX3zEAI8+usSvqtfgB0tkfFLjielq/Fp2yLi4zxqV8dMdqvlpoVqOSZUkJT9XoaRF1ZKR2kYkqvZH+VKCs7+PmjJuly79znK5XFYvv3mwnnhhXND2YYVV+um8dzR6ZLkefmqi5r8U/PhzGb/uvekFeSsG6brbThjIoUelSdPLdNHV6+VyWy36z1DN//sB3SKs5v10vSYfU6bmJrfu/M0R2rw+TZL00AtL1NgQJ7/PyOcz+vH50wf+DkSRSVNLdNGPPpbLJS16cbjmP3ZwtwireT/6WJOnlwZyefOR2rwxQ0OG1eqa363siMovbNBjD47Vc/MPHNg7EGUmHV+tS36zUy639MoTHj11b363CKtLfrtTU2bVqLnRpdt/MlKbPhkkSbry1m2aOqdaVeVxuviEwwZ+8Ig5ESuCjDE+SR9LMpJ8ki631r5njBkpaZ2k9ZKSJNVKusda+0ikxtoXLpfVpdd+pmsvHC9vSaL+9OQqLXvTo52bUzpiJh9XoSEjGvWDU6ZqzLgaXX79Rl35rUlqbXHpF98br6aGOLnj/Lrt0Q+18u0sbViTHsF7FFkul9Vlv9mqX373UHmLE/Tnf3+s5a9nasemQR0xU46vUuHIJn1/zpEaO6FOl/92q6782hHytRn99ZYR2rx2sJJTfPrLf9bow3fTg/Z1Gpfx66qvv6Mr7zlNpVUpevCnz+qdj0doW3FmR0xNfaL+9PTRmjFuW9C+owoqdMbR63XhbWerzefS7Ze+rKVrh2tXmUMfnz6r1P8rUdXvhsqfHa/Mn2xXy1GD5RueuFdcyt+9ajmy8zXAVd6q5BeqVHHPSCnRpdQ/FCnx7Vo1z3FoLhV4bF5xwTL9/JaTVFY+SPfc+ILe+2C4duzO6IiprUvUPY9M1dGTd4Q8xtmnfKoduzM0KLllgEYdvVwuq0uuWafrLp0sb0mS7nx0qZYtydXOrYM7YiYf41XhsAZdeNZxGnN4tS77xae66rvTOrb/Yt4U1VQlRGL4UcXlsrrkqjW67sqj5S1N1p0PLtGyd/K1c1taR8zkaaUqHFavC785R2MOq9RlV3+kqy46Xrt3puqKC2Z1HOcfzy7Ue285+8s4l8vqsht36JfnHizvnnj95YX1WvZqunZ8ltwRM2VWjQpHNut7Mw7T2CPrdflN2/XjMw+RJL06P1svPJKrq+/cGqm7sF+yMvJZE+lhRKVIfv3YaK2dYK0dL+kXkm7psm2ztfZIa+0hkr4p6UpjzAURGWUfHXxEjYp2Jqt4V7LaWl16a0Gups/yBsVMm+3V68/nSTLasCZdKaltyvQ0SzJqagjUo3FxVu44Kzn8AXvw+DoVbU9S8c4ktbW6tOQlj6bNrQyKmTa3Qq8/myPJaP3qVA1Oa1NmTosqyxK0eW3gDb+x3q2dm5OVnefsD0eHjCjTLm+6isrT1OZz67VVB+rYI7YFxVTVJWv9jly1+YJfFkbmVWnttlw1t8bJ53fpw88KNGOcc9+E4j5rkq8gXv78BCneqOm4VCUsr9srLvnFSjUfPVg23R28wW9lWqzkszLNfvmznD0hP2a0V0UlqdpTmqo2n1uLlx6gYyYFFztVNcnasCVHPt/eb1merHpNnbBLC948aKCGHNUOPqxaRTsHqXj3ILW1ufTWogJNm1kaFDPt+FK98VKhJKMNn2QoZXBr+3sRujr4kEoV7UpRcVFKIJevDdG0Y4uDYqYdt0dvvDJMktGGtVmBXGY3BcWMn1SmPbtTVFbi3C/iJGnMhHrt2Zak4h2Jgff1FzI1/cSqoJjpJ1bp9WeyJRmt/3CwBqf5lJXbKkn65P1U1Va59z4w8F+Klh6MNEmVoTZYa7dIukrSDwd0RF9Qdl6zvHs6vwn2liQqOy/4TcWT26yy4uAYT3uMy2V11zMr9Pjb7+rDpZna8HGanMyT16KyrvksTtgrn9l5LfLuSQiK8XQrdnKHNOnAQ+u14aPBcrKcjHqVVnbOSJRVpSgno75P+27Zk6kJo4uVNqhJifFtmn7YDuVm9m3fWOQqb5PPE99x2e+Jk7u8rVtMqxKW1anp5Iyg6/3Z8Wo8K0vZ39+s7O9ulk1xqbXLTJETeTIbVFre5bFZMUjZWX1/fF16/nL99V+TZR3+xdHnsnOb5C1J6rjsLUlSdk5Tt5hmlXWNKe2MsdbohntW6s+PLdXJZ+8cmEFHqeycJnlLO2cpvGXJe+fS06SyrjGlycr2NAbFzJi7W0te697O7TzZ+a0qK+p87fTuSVB2XuveMV3e18uKE5Sd7+wvMdF/IvkVZLIxZrUCLW8Fkmb3EvuBpLGhNhhjLpJ0kSQluSL3QTfU2+9eb8ohgj6P8fuNrjhnilJSW3XdX9ZqxOg6bd/k4A/uIRMafKUJmc/OfycN8um6ezbq/24cqYY6Z3/b3qfHZw+2l2TqsVfH687LX1Jjc7w27c6Wz+/gD5w2xHXd0jH4r6Wq/26O5O72mK3zKWF5ncr/eoBsiltpfyhS4pvVap7l3HY4Y0IktI+PzalH7lRVTbI+2+rR+EP2hHlk+6dQr4t7v3aGynngPz/93lGq8CYpPbNZN967Uju3pWjth1nhH+h+oLc8dcaE3LPjX3Fxfk09pliP3H9IWMe2P9rXe7YkmRAvsN1jgHCJ5CfDRmvtBEkyxkyX9A9jzOE9xPb4jmitfUDSA5KUHpcTsaeKtyRRnoLOmQpPXrMqShP2isnJD44p7xZTXxuvj9/P0KRjKxxdBHmLE5TTNZ/5LXvlylucIE9BS8gYd5xf192zQW8+79F7i0KftO4kpVUpQbM3ORn18lb3vTXjpWVj9dKywPcQF53xvsqqnDt74ffEye3t/PbS5W2Tr1tLW9ymZqXdVhTYXuNTwqp61boltUm+vHjZ9EB88/TBil/f5OgiqKwiRbnZXR6bWQ0qr+zbY/Pwg0s0feIOHTVhlxLifRqU3KJrLl2i3997fH8NN+p5S5LkyeucrfDkNancm7hXTE7XmNwmlXsDM0MV7f+trkzU0jfzNObwascWQd7SZHlyO2d1PDmNHXnqiClLUk7XmNzgmMnTSrR5Y7qqKoP3cyLvnnjlFHa+dnoKWlRRGh8cU5ygnC7v6zn5Laoo4fy0L8sfNY1f0SUqsmKtXSrJIymnh5AjFVgsIWpt/CRVhcMblTekUXHxfs04tVTL3vQExSx/06M5XymRZDVmXLXq6+JU6U1UWmaLUlIDLwwJiT5NmF6pXVud3Tu8cc1gFY5oUt7QJsXF+3X8aV4tez0zKGbZ61mac3aZJKuxE2pVX+tWZVmCJKsf37JZOzcl69mHCiMy/mizfkeOhuVUqyC7RnFun+ZO2qx3P+6+emHPMgYH3uTzMut0/Pitem3l6P4aatRrOyhJ7qJWuYpbpFarpLdr1TI1+AuLigcPUMWDB6riwQPVfHSqai/OU8u0VPlz4hS/oVFq9kvWKuGjBrUNc/Yb/IbNHg3Jr1F+Tq3i3D7NnL5F760a1qd9//bkZH3riv/ReT/6um6663itXlvg6AJIkjZ+mqYhwxqUV9iguDi/Zpy4R8uX5AbFLH8rV7NPK5JkNebwqo73osSkNiUPCrR2Jia1aeK0ckd/GbdxfYaGDKtXXkF9IJdzd2v5u8GrmS1/J1+zT94pyWrMYRWqr4tXZXlnwUMrXKcNH6WocFST8oY1B97Xz6jUslczgmKWvZqhOeeUS7Iae2Sd6mvdexVKQLhERY+QMWasJLekckmDum0bKek2SXcN/Mj6zu9z6b6bDtKND6yRy2W16NkC7dicolO/sVuStOCpIVrxVpamzCjX315eHlhK87oxkqSsnBb95Ob1crmsjMvq7YW5en+Jp7ebi3l+n9F9vx2lGx9eJ7fbatH8XO34bJBO/VbgpNQF/8rXisUZmjKzUg+98aGaGl268+eBD+aHTarV3LO92rp+kO5+/iNJ0iO3D9eKJZk93l6s8/ldumP+Mbrj0pflMn69tGyMthZn6cxjPpUkPffuocpKbdCDP31WKUkt8lujr8/8ROfd/HU1NCXoph+8qrRBTYHjPHWsahsT93GLMcxtVDcvV+m/2SXjl5rmpss3PFFJL1dJkppOyehx17YxyWo+JlWZP94uuaW2A5LUdJJzZ4Ekye936a6/T9Pvr1kkl8vqlcUHafvuTJ0+Z70k6cXXxyozvUH33viCBiW3ylqjr578qb7/s7PV0OjsAjIUv8+l+/54iG64e5VcbqtXnxuiHVsG65RzAuf3vPzMMK14x6PJx5Tpwefebl8iO9CEkZndomtv+1CS5HZbLXmlQKuW9vTdZOzz+1y6745xuuGOpXK5rF59abh2bE3TKWcGFoZ5+blRWrE0T5Onl+jBJ1/rWCL7c4mJbTpySqnuvnV8TzfhKH6f0b2/Gq6bHv0ssHz7kx5t35isU88rkyQteCxH77+RpimzqvXQ25+oudGlO64e2bH/NXdt0bjptUrLbNOjy9fosTsKtfBJZ39WwpdjbISaLbsskS0F2t1+aa19qYclsu+z1j68r2Omx+XY6eln99OIncc2s1pQuNSe4uzf1Qm3hu9WRXoIMSXrDue2N/aHxA1FkR5C7EimjSycfDt2RXoIMWNZ20LV+Cui/gTZkYcPttf/e0Kkh9Gr7495d5W1dvJA327EZoKstSHXObTWbpOUHGobAAAAAHxZUXFOEAAAAAAMlKg4JwgAAABAuBn5e15k2dGYCQIAAADgKBRBAAAAAByFdjgAAAAgBllJPsucRyhkBQAAAICjUAQBAAAAcBTa4QAAAIAY5WPOIySyAgAAAMBRKIIAAAAAOArtcAAAAEAMsjLyW34sNRRmggAAAAA4CkUQAAAAAEehCAIAAADgKJwTBAAAAMQolsgOjawAAAAAcBSKIAAAAACOQjscAAAAEIOsJL9lziMUsgIAAADAUSiCAAAAADgK7XAAAABATDLyyUR6EFGJmSAAAAAAjkIRBAAAAMBRaIcDAAAAYhCrw/WMrAAAAACIWsaYk40xG4wxm4wx1/QQM9MYs9oYs9YYs2Rfx2QmCAAAAEBUMsa4Jd0j6QRJuyStMMY8b639tEtMhqR7JZ1srd1hjMnd13EpggAAAIAYFQOrwx0laZO1doskGWOekHSmpE+7xHxb0r+ttTskyVpbuq+D0g4HAAAAIFoNkbSzy+Vd7dd1dbCkTGPMYmPMKmPMd/Z1UGaCAAAAAESKxxizssvlB6y1D3S5HGoqy3a7HCdpkqQ5kpIlLTXGLLPWbuzpRimCAAAAAESK11o7uZftuyQN63J5qKSiEDFea229pHpjzFuSxkuiCAIAAACcxFoTC0tkr5B0kDFmlKTdkr6pwDlAXT0n6W5jTJykBElTJd3Z20EpggAAAABEJWttmzHmckkLJbklPWStXWuMubh9+/3W2nXGmFckrZHkl/SgtfaT3o5LEQQAAAAgallrF0ha0O26+7tdvlXSrX09JkUQAAAAEKN8+387XL8gKwAAAAAchSIIAAAAgKPEVjuc3y/b2BjpUcSMDf93aKSHEDPyX97vf605qiQ+kRnpIcSUuHdW7jsIfZfjifQIgJCsv/tPq+C/tp+k0kryh/yZHTATBAAAAMBRKIIAAAAAOEpstcMBAAAAaGdYHa4HZAUAAACAo1AEAQAAAHAU2uEAAACAGGQl+S2rw4XCTBAAAAAAR6EIAgAAAOAoFEEAAAAAHIVzggAAAIAY5WPOIySyAgAAAMBRKIIAAAAAOArtcAAAAEAMsjIskd0DZoIAAAAAOApFEAAAAABHoR0OAAAAiFF+5jxCIisAAAAAHIUiCAAAAICj0A4HAAAAxCBrJR+rw4XETBAAAAAAR6EIAgAAAOAotMMBAAAAMYofSw2NmSAAAAAAjkIRBAAAAMBRaIcDAAAAYpCVkd8y5xEKWQEAAADgKBRBAAAAAByFIggAAACAo3BOEAAAABCjfGKJ7FCYCQIAAADgKBRBAAAAAByFdjgAAAAgBllJfks7XCjMBAEAAABwFIogAAAAAI5COxwAAAAQk4z8ljmPUMgKAAAAAEehCAIAAADgKLTDhdGkGVW6+PrtcrmsXnkqV/PvL+wWYXXx9ds1ZWaVmptcuv2nB2rz2hR5Cpp19W2blZnTKus3evmJXD339/yI3IdoMmhNtXL+uUvySzXHZ6vy9NA5SdxSr2G/26Diy0apbkqm4spblPfANsVVt8oao5pZHlWdmDvAo48+U8fu0I/Pek9ul9ULy8bq0TeODNp+4sTPdN7s1ZKkxuZ43frMcdpUlN2nfZ1m2pgd+vGZgXw8v3ysHn2zWy6P/Eznz1otSWpsidcfnzlOm/YEcnntNxbr6EO3q7IuWefd9o2BHnpUmnR8tS75zU653NIrT3j01L3dn+tWl/x2p6bMqlFzo0u3/2SkNn0ySJJ05a3bNHVOtarK43TxCYcN/OCj0KTpZbro6vVyua0W/Weo5v/9gG4RVvN+ul6TjylTc5Nbd/7mCG1enyZJeuiFJWpsiJPfZ+TzGf34/OkDfweiyKSpJbroRx/L5ZIWvThc8x87uFuE1bwffazJ00sDubz5SG3emKEhw2p1ze9WdkTlFzbosQfH6rn5Bw7sHYgyk2dW6+Lf7pLbLb38r2w9dU+I5/rvdumo2TVqajS6/crO5/pVt23X1LnVqvLGad7cQwd+8PsxPz+WGlJEZ4KMMfnGmCeMMZuNMZ8aYxYYYw42xjQaYz40xqwzxrxvjPluJMfZFy6X1WW/3aZfXTBG804ap5lnlGv46IagmCkzq1U4sknfnz1ef/nlKF1+w1ZJkq/N6K83j9C8E8frynMO0+nnl+y1r+P4rXL+sVO7fzJa2285RKnLKpWwuzFknOep3Wo4Iq3jKus28n5rqLb//jDtvH6M0l8rC72vg7iMX1d/9V395IFT9e0/fENzJ27SyLzKoJiiilRdds9X9J3bvq6HX52on3/9rT7v6yQu49dPzn5XVz14qr516zd0wpF752NPRaouve8rOv+Or+uh1ybqmvZcStJLKw/WlX89daCHHbVcLqvLbtyh6757kC6ac6hmfqVCww8Kfr5OmVWjwpHN+t6Mw/Tna4br8pu2d2x7dX62rvvOQQM97Kjlclldcs06/fqHk3TJ147VjJP2aNiouqCYycd4VTisQReedZzuuvEwXfaLT4O2/2LeFF3x7aMdXwC5XFaXXLVGv756ui45b7ZmzN2tYSNrgmImTytV4bB6XfjNObrr1vG67OqPJEm7d6bqigtm6YoLZulH35+p5ia33nurIBJ3I2oEnus7dd35o3XhrEM068zKvZ/rs2s0ZFSzLjj2UP355yN0xS07OrYtmp+la88bPdDDRgyLWBFkjDGSnpW02Fp7oLX2UEm/lJQnabO19khr7SGSvinpSmPMBZEaa18cPL5ORduTVLwzSW2tLi15MUvTTgj+YDRtbqVef9YjyWj96lQNTvMpM6dFlWUJ2rw2RZLUWO/Wzk1Jys5vjcC9iB5JW+rVmpeottxEKc6l2qmZSvmgeq+4jFfLVDc5U760zklNX0a8mkcGvjmyyW61FCYprtLZ+Tx0eKl2edNUVJGmNp9br304Wscdvi0o5pNt+aptTJQkrd2ep9yMuj7v6ySHDi/VrvIu+Vg9WjMO2xYU8/H2brlM7/wQunpLoWoakgZyyFFtzIR67dmWpOIdiYHXzhcyNf3EqqCY6SdW6fVnsiUZrf9wsAan+ZSVG3hOf/J+qmqr3AM/8Ch18GHVKto5SMW7B6mtzaW3FhVo2szSoJhpx5fqjZcKJRlt+CRDKYNblelpjsyAo9jBh1SqaFeKiotSArl8bYimHVscFDPtuD1645Vhkow2rM0K5DK7KShm/KQy7dmdorKSQQM4+ugzZkK9irYldjzXFz+XqeknBr+vTz+xWq89nSXJaP0HKUrp+lxfznMd4RXJmaBZklqttfd/foW1drWknV2DrLVbJF0l6YcDOrovyJPforI9CR2XvXsSlJ0X/ME7O79F3j2JnTHFCfLktwTF5A5p1oGHNWjD6pT+HXCUi6tsVVtWZz7bsuL3KmTcFS1KWVWl6tmeno9T1qzE7Q1qOtDZ+cxJb1BJ1eCOy2VVKcpJr+8x/vSp67V03fD/at9Yl5PeoNIu+SjdRz7OOGq9lq4fPhBD2y9l57eqrCi+43Lo187WoNfXsuIEZXd77URAdm6TvCWdRba3JEnZOU3dYppV1jWmtDPGWqMb7lmpPz+2VCefHfR27DjZOU3yliZ3XPaWJe+dS0+TyrrGlCYr2xM8uzFj7m4teW1I/w52P5BdEPw89hbHy1MQ/Fz35LeorKjbZyme61+KtZLPmqj+i5RInhN0uKRVfYz9QNLYUBuMMRdJukiSkkyUfdC1wRdNiP/Ptsv//KRBPl1370b93w0j1FDn8NO1bIjruuUv5/FdKv/GEMkV+glkmnwquGuLys4dKn+yw789Mnsn1IbKsaSJo3frjKnrdfFdZ37hfZ3AhHhw9pjLA3frjKPWa949Z/bzqPZfoV8Xu8V8gZw7Xah8qtuHDBPiOf15in/6vaNU4U1Semazbrx3pXZuS9HaD7PCP9D9QG956owJuWfHv+Li/Jp6TLEeuf+QsI5tfxTyodk9xfv4nASE0/7ySbvHZ4C19gFJD0hSuis7Ym+L3uIE5RR0flvhKWhReWl8cMyeBHkKmiWlBmLyW1ReEohxx/l13b2f6c3nPXpvoTPfcLpqy4pXXEVnPuMqWtWWEZzPpK0Nyr8vcF6Vu7ZNgz6qkXUZ1U/KkNqsCu7aotqjs1Q/OXMghx6VyqpSlJfR2ZKVk1Evb83eXxocWFCuX3zjLV3111M6Wrb6uq9TlFandLQKSlJub7n8+lu66sFTaH/rhXdPvHIKO78N9hS0qKL7a2e319ec/BZVlCQIe/OWJMmT1zlb4clrUrk3ca+YnK4xuU0q9wYeoxXt/62uTNTSN/M05vBqxxZB3tJkeXI7Z3U8OY0deeqIKUtSTteY3OCYydNKtHljuqoqeQ3w7okP/pyU36ry4r0/J+UUBn+WqigJjgHCJZLtcGslTepj7JGS1vXjWL60jWsGq3Bkk/KGNiku3q/jT6/QsteCP3wvez1Dc872SrIaO6FW9bVuVZYlSLL68e+3aufmZD37N2efOPm5plEpSihpVlxZs9TmV+ryStUfmR4Us+32wzv+6qZkqOy7wwIFkLXK+9t2tRQmqerkvMjcgSizbmeuhuZUqyCrRnFun+YeuUnvfDIiKCYvo1a3XLBIv318lnaWZXyhfZ1k3c5cDfN0yceETXp77d65/P13F+l3/5qlnd6MyAx0P7HhoxQVjmpS3rDmwGvnGZVa9mpGUMyyVzM055xySVZjj6xTfa17r0IJARs/TdOQYQ3KK2xQXJxfM07co+VLglfHXP5WrmafViTJaszhVaqvi1OlN1GJSW1KHtQmSUpMatPEaeXavmlwiFtxho3rMzRkWL3yCuoDuZy7W8vfDV7NbPk7+Zp98k5JVmMOq1B9XbwqyzsLHlrhOm34KEVDRjV3PNdnnlmpZa8Gv68vW5SuuV+rkGQ1dmK9Gniuox9FciboDUk3G2MutNb+VZKMMVMkBZ05aIwZKek2SXcN+Ai/AL/P6L7fjNSNj2yQ22W1aH6Odnw2SKd+u0SStODxPK14M0NTZlbpoTc/UlOTS3f+LLBs6WGT6zT3q15tXZ+su1/8WJL0yG3DtGJxRqTuTuS5jUrPH6Yht26S/FY1M7LVMjRZ6W+USZKqZ+f0uGvSZ/VKe69CzUOTNPxXgdrZ+7VCNYxP73GfWOfzu3THv4/VnRctkNtl9eL7Y7S1JEtnTQ+sCvWfpYfqghM/UNqgJl19zjvt+xh9/85zetzXqXx+l25/9lj96cIFchmrF1cE8nF2ey6fXXqovndCey6/2pnL7/35HEnSb899TRMP3KOMlCY9d91jenDRZL3wfshuX0fw+4zu/dVw3fToZ4ElnZ/0aPvGZJ16XuC5vuCxHL3/RpqmzKrWQ29/ouZGl+64emTH/tfctUXjptcqLbNNjy5fo8fuKNTCJ3s+TzDW+X0u3ffHQ3TD3avkclu9+twQ7dgyWKecEzi/5+VnhmnFOx5NPqZMDz73dvsS2YdLkjKzW3TtbR9KktxuqyWvFGjV0p5fa2Od3+fSfXeM0w13LJXLZfXqS8O1Y2uaTjkz0IHw8nOjtGJpniZPL9GDT77WsUT25xIT23TklFLdfev4SN2FqOL3Gd3zq2G6+Z+b5HJZLXoyW9s3Juu09uf6S58/12dX6+F31gZ+SuSqzi+Yrrl7q8ZNr1V6VpseW/GxHr29QAufcO5z/YvwW34WNBRjI9hYbYwplPQnBWaEmiRtk/RjSWskrZeUJKlW0n3W2of3dbx0V7adlsTSs+Gy4f9Yhz9c8l+mdSeceD0Pr/SnVu47CH3mzuGDWdgk00YWTm3bnL3YRTgt9y1Sja2I+hOWPId47GmPRPd5qf+Y+tAqa+3kgb7diJ4TZK0tkhTq1wKTQ1wHAAAAAF/a/rIwAgAAAIAvwMrIzwp7IdFUAgAAAMBRKIIAAAAAOArtcAAAAECM8vf8c5uOxkwQAAAAAEehCAIAAADgKLTDAQAAADHISqwO1wNmggAAAAA4CkUQAAAAAEehHQ4AAACIUX7LnEcoZAUAAACAo1AEAQAAAHAU2uEAAACAWGQNq8P1gJkgAAAAAI5CEQQAAADAUSiCAAAAADgK5wQBAAAAMchK8otzgkJhJggAAACAo1AEAQAAAHAU2uEAAACAGMUS2aExEwQAAADAUSiCAAAAADgK7XAAAABADLKiHa4nzAQBAAAAcBSKIAAAAACOQjscAAAAEKNohwuNmSAAAAAAjkIRBAAAAMBRaIcDAAAAYpCVoR2uB8wEAQAAAHAUiiAAAAAAjkIRBAAAAMBROCcIAAAAiFF+cU5QKMwEAQAAAHAUiiAAAAAAjkI7HHo0Zt6nkR5CzFh/x7hIDyGmHPC0L9JDiCmu1NRIDyGm2Kz0SA8hZuw+MTvSQ4gphfcVR3oIMcM07SctZlYskd0DZoIAAAAAOApFEAAAAABHoR0OAAAAiEFWtMP1hJkgAAAAAI5CEQQAAADAUWiHAwAAAGIU7XChMRMEAAAAwFEoggAAAAA4Cu1wAAAAQAyyMrTD9YCZIAAAAACOQhEEAAAAwFEoggAAAAA4CucEAQAAADHKck5QSMwEAQAAAHAUiiAAAAAAjkI7HAAAABCj/KIdLhRmggAAAABELWPMycaYDcaYTcaYa0Jsn2mMqTbGrG7/u35fx2QmCAAAAEBUMsa4Jd0j6QRJuyStMMY8b639tFvo29ba0/t6XIogAAAAIAZZK/n3/9XhjpK0yVq7RZKMMU9IOlNS9yLoC6EdDgAAAECkeIwxK7v8XdRt+xBJO7tc3tV+XXfTjTEfGWNeNsYctq8bZSYIAAAAQKR4rbWTe9keairLdrv8gaQR1to6Y8ypkv4j6aDebpQiCAAAAIhRMfBjqbskDetyeaikoq4B1tqaLv9eYIy51xjjsdZ6ezoo7XAAAAAAotUKSQcZY0YZYxIkfVPS810DjDH5xhjT/u+jFKhxyns7KDNBAAAAAKKStbbNGHO5pIWS3JIestauNcZc3L79fklfk3SJMaZNUqOkb1pru7fMBaEIAgAAAGKSiYXV4WStXSBpQbfr7u/y77sl3f1Fjkk7HAAAAABHoQgCAAAA4Ci0wwEAAAAxKgZWh+sXzAQBAAAAcBSKIAAAAACOQhEEAAAAwFE4JwgAAACIQVaKiSWy+wMzQQAAAAAchSIIAAAAgKPQDgcAAADEIitZG+lBRCdmggAAAAA4CkUQAAAAAEehHS6MJs2o0sXXb5fLZfXKU7maf39htwiri6/frikzq9Tc5NLtPz1Qm9emyFPQrKtv26zMnFZZv9HLT+Tqub/nR+Q+RBPyGV6D1lYpd/4OyVpVH52jypOC85nyUaU8L+ySdRnJJZV+bYSaRqdKkjLeKFb6u2WSpOpjclQ129n5nDJuly47f5lcLqsFiw/WEy+MD9o+rKBKP7vobY0eWa6H5k/S/AVHdGz7551PqaEpXn6/kc9ndOn1Zw708KPOpGPLNe+aTXK5rRY+U6D5D47oFmE17xebNGVGuZob3brj2rHavC61Y6vLZfXnp1apvCRBv7ls3MAOPgpNmrxH8y5dLZfLauHLozT/yUO6RVjNu/RDTTmqWM3Nbt1x61HavClTknTm2Rt10ilbZIz0yoID9NyzBw/8HYgiR4/coZ/PeUcuY/XsmkP00PsTg7afeshGXTD1Q0lSQ0u8bnp1hjaWeSRJ5036SF8dt07WSp95s3X9y7PU4nP2xy7e1yPDL1aHC2XAno3GmGslfVuST5JfUqWkTEmDJeVI2toeeqmkmyUVSGqS1CLpQmvt6oEa63/D5bK67Lfb9MvvjJW3OEF//s9aLX8tQzs2DeqImTKzWoUjm/T92eM1dkKdLr9hq6786uHytRn99eYR2rw2RckpPv3l+U/04TtpQfs6DfkMM79V7pPbtfuHY9SakaARf1ir+nGZailI7ghpGJOm7eMOl4xRwq4GFf5tk7b9epwSihqU/m6Zdvz8UFm3S0Pu3qD6wzPUmpsUwTsUOS7j1w+/u1Q/+/1JKqtI0b2/e15LVw3X9qLMjpja+kTd/eg0HTNpe8hj/OSmU1RT58z8dedyWV167We69sLx8pYk6k9PrtKyNz3auTmlI2bycRUaMqJRPzhlqsaMq9Hl12/Uld+a1LH9zPN3aeeWQRqU0haJuxBVXC6/Lr3iA1378+Pl9SbrT3e/pmVLC7VzR3pHzOSjijVkSJ1+8L+naMwhFbr8h6t05Q/nasTIap10yhZdecVctba6dMMtb2nF+wUq2p3ayy3GLpfx65cnvK15T52hktoUPX7+M1q8eaS2lGd1xOyuTtP3/nWWapsTdcyo7br+xCU675/nKHdwnb498WOd/fA31dwWpz+esUgnj92k59eOjeA9iize1xFtBqQdzhgzXdLpkiZaa8dJmivpXGvtBEk/kPS2tXZC+9977buda60dL+leSbcOxDi/jIPH16loe5KKdyaprdWlJS9madoJlUEx0+ZW6vVnPZKM1q9O1eA0nzJzWlRZlqDNawNv+I31bu3clKTs/NYI3IvoQT7DK2lbnVpzEtXqSZLiXKqZlK2Uj4LzaZPckgl8W+Rq8enz8ygTipvUNGqwbIJbchs1HpSqwasr5VRjD/Rqd0ma9pSlqc3n1pvLDtDRk3YExVTVJGvDlhy1+eg43peDj6hR0c5kFe9KVlurS28tyNX0Wd6gmGmzvXr9+TxJRhvWpCsltU2ZnmZJUnZek6bMKNfCZwoiMProc/CYChUVDVZx8WC1tbn11uLhmn50UVDMtOm79fprIyUZbViXrZTBrcrMatSw4TXasD5bzc1x8vtd+mRNjo4+ZndE7kc0OLygVDsr07W7Ok1tfrdeWT9aM0dvC4r5qChftc2JkqQ1RfnKS63v2OZ2+ZUY1ya38Ss5vk1l9SlyMt7XEW0G6h26QJLXWtssSdZar7W2aB/7fG6ppCH9NrIw8eS3qGxPQsdl754EZecFP0Gz81vk3ZPYGVOcIE9+S1BM7pBmHXhYgzasdvaLJfkMr7iqVrVlduaqLTNB8dUte8UNXl2hkb9doyH3blTJ+aMkSS0FyUreVCNXXatMi08pa6sUV9k8YGOPNp7MepVVdD6eyipS5Mls6PP+1kp/vGah7rvhOZ02a31/DHG/kp3XHPw8LklUdl7w48uT26yy4uAYT3vMvGs26aHbD5TfPzDjjXbZnkZ5yzq/Hfd6k5XtaQyK8XgaVVaaHBTj8TRq+7Z0HX5EmVJTm5WY2KbJRxXLk9P3x3asyR1cr+Lazud6aW2K8gbX9xh/9rh1emfrsEBs3WA9smKCFs57VK9d+ohqmxO0dNuwfh9zNON9PTKsJGtNVP9FykC1wy2SdL0xZqOk1yQ9aa1d0sd9T5b0n/4aWL/qtiShCfH/uev//KRBPl1370b93w0j1FDn7L7hkMhnWIVaMbNuQpbqJmQp+bMaZb+wW7t/NFYtBcmqOKFQQ+/aIH+iW81DBkluB/cXh3rcfYHdf/S701VeNUgZaY36489f0Y6iDH28wbm97aEeSXu9KfbwXD/qeK+qKhK06dNUHTHFubOTXYV+XeweFDpm5440zX9yrG76wxI1NcZp65Z0+XzOfa6HfGz2EDtl2G6dfcQ6/e/jZ0uSUhObNWv0Vp36wHmqbU7QrV9ZpNMO3aiXPnX2OVZ74X0dETQgjyBrbZ0xZpKk4yTNkvSkMeYaa+3fe9ntn8aYFEluSRN7CjLGXCTpIklKMpH7VsBbnKCcgs5vKzwFLSovjQ+O2ZMgT0GzpEB/tSe/ReUlgRh3nF/X3fuZ3nzeo/cWZsnpyGd4tWXEB83exFW2qC09ocf4xoPSlODdIlddq/yD41VzTI5qjsmRJGU/t1NtGT3vG+u8FSnKyer8Njgnq17llX3vSy+vCsRW1STrnVUjNPbAMkcXQd6SxPbncYAnr1kVpQl7xeTkB8eUlybo2BPLNG2mV1OOK1d8ol+DUny6+vef6rZrDh2w8Ucbb1ly0OyNx9OoivLkvWJychultZ0x5e0xi145QIteOUCS9N3vrQmaVXKakroU5Xdpb8tNrVdp3d6fMw7KKdevT16sy54+TdVNgXP9po3Ypd3VaapsDOT19c8O0PjCYkcXQbyvI9oMWMO6tdZnrV1srf21pMslnbOPXc6VNErS45Lu6eW4D1hrJ1trJycosaewfrdxzWAVjmxS3tAmxcX7dfzpFVr2WmZQzLLXMzTnbK8kq7ETalVf61ZlWYIkqx//fqt2bk7Ws3+jr10in+HWNGKw4kubFedtltr8SltVrvpxGUEx8aVNHV8ZJ+6ol2mz8qcEvidx1wZaFuIqmpW6ulK1U7IHdPzRZP0Wj4bkVys/p1Zxbp9mTdui9z4Y3qd9kxJblZzU2vHvyYcXaduuzH3sFds2fpKqwuGNyhvSqLh4v2acWqplb3qCYpa/6dGcr5RIshozrlr1dXGq9Cbq7386QN+Zc7QuOHG6/nD1oVqzPMPRBZAkbdyQpcIhdcrLr1NcnE8zZu7QsqXBK3AtX1qoOXO3SbIac0i56uvjVVkR+LCentEkScrJqdfRx+zWkjf79tiORWv35Gp4ZpWGpNcozuXTyWM3acmmkUEx+am1uuPMV3TtS3O0vTKj4/ri2sEaV1iipLhWSVZTh+/S1nKHP9d5X48QI7+N7r9IGZCZIGPMGEl+a+1n7VdNkBR62aQurLWtxpjrJG02xhxirV3Xj8P8Uvw+o/t+M1I3PrJBbpfVovk52vHZIJ367RJJ0oLH87TizQxNmVmlh978SE1NLt35s8C3bYdNrtPcr3q1dX2y7n7xY0nSI7cN04rFGZG6OxFHPsPMbVT2PyM09O71kl+qmZ6jlsJBSn+rVJJUPSNXg1dXKG15uazbyMYbFX1/dEdvQsEDn8ld3ya5jUr+Z4T8g5zbhuD3u3TXI9P1h58tlMtl9fKSg7R9d6ZOnx04v+fFN8YqM71B993wvAYlB5ZzPefktfrez7+q9MFN+u2PX5ckud1Wr793gFasGRrJuxNxfp9L9910kG58YI1cLqtFzxZox+YUnfqNwAn5C54aohVvZWnKjHL97eXlam5y687rxkR41NHL73fpvrsn6sZb3grkc+Eo7dierlNP3yRJWvDiaK14v0BTpu7R3x5ZoObmON1525SO/a+9/j2lpbWorc3o3rsnqq7OubO+PuvSLa8dp/u+9qJcLqv/fDxWm8uz9PXxgSm0+R8dpnlHr1RGcpN+ecJbgX38Ln370a/p4z15enXjAXriO0/L5zdaX5qjp9c4u0DnfR3Rxti9moX74UYCrXB3ScqQ1CZpk6SLrLVeY8xMSVdba0/vEr+4/bqV7Zd/IulQa+33e7uddFe2nZZ0an/cBeBLWX8Hv10STgc87Yv0EGJK4odbIj2E2FKYG+kRxIzdJzp31rk/FN73QaSHEDOWNS1Qtb886k+aG3RQoT34T71+fI64j06/cZW1dvJA3+5AnRO0StLRPWxbLGlxt+tmdrt8ez8NDQAAAIDDOLenBQAAAIhxA9D0tV/il/wAAAAAOApFEAAAAABHoR0OAAAAiFF7/QA1JDETBAAAAMBhKIIAAAAAOArtcAAAAEAMspZ2uJ4wEwQAAADAUSiCAAAAADgK7XAAAABAjPLTDhcSM0EAAAAAHIUiCAAAAICj0A4HAAAAxChrIz2C6MRMEAAAAABHoQgCAAAA4Ci0wwEAAAAxih9LDY2ZIAAAAACOQhEEAAAAwFEoggAAAAA4CucEAQAAADHIynBOUA+YCQIAAADgKBRBAAAAAByFdjgAAAAgRtlIDyBKMRMEAAAAwFEoggAAAAA4Cu1wAAAAQCyyYnW4HjATBAAAAMBRKIIAAAAAOArtcAAAAECsYnm4kJgJAgAAAOAoFEEAAAAAHIV2OAAAACBGsTpcaMwEAQAAAHAUiiAAAAAAjkIRBAAAAMBROCcIAAAAiFGWJbJDiqkiyForf1NTpIcRM9yHjYn0EGJG2oaYeqpFXMqvd0R6CDGlZU5tpIcQU9z1qZEeQswofPDjSA8hpvibmyM9hJhhqSz2e7TDAQAAAHAUvp4GAAAAYpAVS2T3hJkgAAAAAI5CEQQAAADAUWiHAwAAAGKRlUQ7XEjMBAEAAABwFIogAAAAAI5COxwAAAAQo/hJo9CYCQIAAADgKBRBAAAAAByFdjgAAAAgVtEOFxIzQQAAAAAchSIIAAAAgKNQBAEAAABwFM4JAgAAAGKSkbUm0oOISswEAQAAAHAUiiAAAAAAjkI7HAAAABCrWCI7JGaCAAAAADgKRRAAAAAAR6EdDgAAAIhFVqwO1wNmggAAAAA4CkUQAAAAAEehHQ4AAACIVawOFxIzQQAAAAAchSIIAAAAgKPQDgcAAADELFaHC4WZIAAAAACOQhEEAAAAwFFohwMAAABiFavDhcRMEAAAAABHoQgCAAAA4CgUQQAAAAAchXOCAAAAgFjFOUEhMRMEAAAAwFEoggAAAAA4Cu1wAAAAQCyykqyJ9CiiEkVQGE2eWaOLbyiS22X18r+y9NTded0irC65oUhHza5RU6NLt185TJs+HtTHfZ1n0uQ9mnfparlcVgtfHqX5Tx7SLcJq3qUfaspRxWpuduuOW4/S5k2ZkqQzz96ok07ZImOkVxYcoOeePXjg70CUOXrUDv18zjtyuaye/egQPbR8YtD2Uw/dqAumfihJamiN100LZ2hjmUcjsir1x6+82hE3NKNG974zRf9cOX5Axx9N/Mub1XZXjaxfcp+WrLhzBwdv/7BZrddWyRS4JUmu45IU97+DZZutWn9YIbVaySe5jk9U3PdSI3EXosqk46t1yW92yuWWXnnCo6fuze8WYXXJb3dqyqwaNTe6dPtPRmrTJ4HXzitv3aapc6pVVR6ni084bOAHH4UmTS3VRT/+RC631aIXhmv+owd1i7Cad+VaTZ5eouYmt+68cYI2b8zQkOF1uuZ3qzqi8oc06LG/jtFzTx0wsHcgikw6rlIXX7tFLpfVK/PzNP+vw7pFWF187RZNOb5SzU0u3X7Nwdr86WDFJ/h16z/XKD7BL7dbemdhth67a0RE7kM0mTyzRhf/bnf7Z51sPXVPiM9Jv9vd5XPS8I7n+r73Bb6YAS2CjDHXSvq2JJ8kv6R5kv4gqUBSk6Q6Sd+T9HtJoyQNlpQjaWv7IS611r43kGPuK5fL6rKbd+sX3zxA3j3xumvBZ1q2MF07PkvqiJkyu1ZDRjXrgmPGauzEBl1xy2796PSD+rSv07hcfl16xQe69ufHy+tN1p/ufk3LlhZq5470jpjJRxVryJA6/eB/T9GYQyp0+Q9X6cofztWIkdU66ZQtuvKKuWptdemGW97SivcLVLTbuR82XcavX57wtuY9eYZKalP0+Hef0eJNI7WlPKsjZnd1mr73+FmqbU7UMQds1/UnL9F5j56j7RWZ+p+/f6PjOK9e+g+9sdG5H4qsz6r1TzVKuD1TynGrdV65/MckyTUy+OXUNS5B8b/PDN45QYq/M1NmkEu2zar18gr5p7bIdVjCAN6D6OJyWV124w798tyD5d0Tr7+8sF7LXk3Xjs+SO2KmzKpR4chmfW/GYRp7ZL0uv2m7fnxm4EuRV+dn64VHcnX1nVt7uglHcbmsLrn6Y133o2nylibrzr+9rWVv52vnts7Xv8nTS1U4tE4XfmO2xhxWpct++rGuuvA47d4xWFf87/Edx/nHc6/qvbe6F6TO4XJZXXb9Zv3ygsPlLUnQn59ereVvZGvH5kEdMVNmVKpwZJO+f+IkjR1fq8t/s0lXfmOCWluMrvnuEWpqcMsd59dtj6/Ryrcytf6jtAjeo8hyuawuu2mXfvGtA9s/62zUskU9fE469pD2z0m79KMzDu7TvsAXNWDnBBljpks6XdJEa+04SXMl7WzffK61drykRyTdaq0921o7QdIPJL1trZ3Q/heVBZAkjTmyQUXbElS8I1FtrS4tfi5D00+qDoqZflK1Xns6U5LR+g9SlJLuU1Zua5/2dZqDx1SoqGiwiosHq63NrbcWD9f0o4uCYqZN363XXxspyWjDumylDG5VZlajhg2v0Yb12WpujpPf79Ina3J09DG7I3I/osXhBaXaWZWu3dVpavO79cq60Zp50LagmI9256u2OVGStGZ3vvJS6/c6ztQRu7WzKl17apxbUNp1rTJD3DKFcTLxRq7ZSfK/09SnfY0xMoPaX3bbJLVZyeFdCmMm1GvPtqSO178lL2Rq+olVQTHTT6zS689kSzJa/+FgDU4LvHZK0ifvp6q2yj3wA49SBx9aqaJdKSouSlFbm0tvvVaoaccVB8VMO65Yb7wyTJLRhrWZgdfO7ODH8PjJZdqze5DKigfJqQ4eV6ui7Ukq3pUUeGy+lKNpc8qDYqbNqdDr/8mVZLT+ozQNTvMpM6dFklFTQ+BxGRdnFRdnZR3ekhT4rJPY5bNOZg+fk7IU+nNS7/uiZ9ZG91+kDOTCCAWSvNbaZkmy1nqttUXdYt6SNHoAxxQ22fmtKivq/DbXuydenoLWoBhPfqvKiuI7Y4rilZ3f2qd9nSbb0yhvWeebr9ebrGxPY1CMx9OostLkoBiPp1Hbt6Xr8CPKlJrarMTENk0+qlienIYBG3s0yk2tV3FNSsfl0toU5Q3eu8j53Nnj1+mdLd3bPqSTD9mkV9btl0/RsLFev0xu54duk+OW9fr3ivOvbVHL97xq+WmF/Fs7n8/WZ9Xyfa9aziqVa3KiXIc6dxZI+vy1s8vr4p4EZee17h2zpzNPZcUJys5vGbAx7k+yc5rkLenyuliWpOycpr1iykqSusQk7xUzY26Rlrw6pH8HG+U8eS0qK07suOwtSVR2XvDjLjuvWd7iLu/fxQny5DVLCsx83P2fD/Wv95brw/cytGGNc788kkI91+Plyd/H56Q9XT8n9b4v8EUNZBG0SNIwY8xGY8y9xpjjQ8ScIenjL3JQY8xFxpiVxpiVrWoOy0D/GybEFzx7Vbc9xPRpX4f5MvncuSNN858cq5v+sEQ33PyWtm5Jl8/n7G/gQt37nh5iU4bv1tnj1ulPi6cHXR/n8un40du0aP2BYR/ffqUPz01zcLwSnsxRwkMeuc9JUdu1VZ3b3EYJf/MoYX6O/Ota5d/i7DfyvjzXTYikO/01sichX+m653MfLwhxcX5NPbZY77xRGMaR7Yf68MIZ+vEbuNLvN7r8rCN1/vFH6eBxdRpxUM9fPDkBn5MQbQbsnCBrbZ0xZpKk4yTNkvSkMeaa9s3/NMY0Stom6YoveNwHJD0gSWkmK2JPCe+eeOUUdn5D5CloVXlxfIiYzg88nsJWVZTEKz7B7nNfp/GWJQfN3ng8jaooT94rJie3UVrbGVPeHrPolQO06JXAeSvf/d6aoFklJyqpTVF+WucbcG5qvUrrUvaKOyinXL8+ebEum3+aqpuCe62PPWCH1pd4VNHg7FyaHJdsqa/jsi3zyXiCv08yKZ2X3dMS1Xanla3yy2R0Xm9SXXIdmSD/+y1yHeDc5/ter4sFLaoo7fbaWZygnILO18ic/BZVlDh7Bq0n3rIkefI6Z809OU0q9wY/l72lScrJa+oS0xgUM3l6qTZvTFdVZaKczFucoJz8zi9XPXnNKi9N6BaTKE+XWUlPfsteMfW1cVqzPF2Tj6vU9s/2ft11ir2f660qL9nH56SCrp+Tet8XvaBgDGlAfyfIWuuz1i621v5a0uWSzmnfdG77OT9nWWt39nKIqLVh9SANGdWivGHNiov3a+aZVVq2KD0oZtmidM39WqUkq7ET69VQ41JFaXyf9nWajRuyVDikTnn5dYqL82nGzB1atjT4W8nlSws1Z+42SVZjDilXfX28KisCRVB6RuANPienXkcfs1tL3hw+wPcguqzdk6vhmVUakl6jOJdPJx+ySUs2jQyKyU+t1R1nv6JrX5qj7ZUZex3jlEM36eV13VeZch4zNl52l092T5tsq5X/jSa5jgn+sGjLfbLtX1P617UEloFJN7JVftnaQOucbbbyr2yWGe7s81k2fJSiwlFNHa9/x59RqWWvZgTFLHs1Q3POKZdkNfbIOtXXuvcqlBCwcV2GhgytV15Bg+Li/Joxt0jL3wle3GD5O/maffJOSVZjDqsMvHaWdxZBM07Y7fhWOEna+HGqCkc2Km9oU+CxeVqZlr2RFRSz7I0szTmrVJLV2PE1qq91q7IsQemZrUpJbZMkJST6dOTRVdq5xdlfIAU+6zR3+axTqWWLgheKWLYoTXO/VqHOz0nuLp+Tet8Xsc0Yc7IxZoMxZlOXSZRQcVOMMT5jzNf2dcwBmwkyxoyR5LfWftZ+1QRJ2yUdPlBj6E9+n9E91w7RzY9vkcstLXoiS9s3Jum0872SpJce9ej911M1ZU6NHn5vfWCZ1yuH9bqvk/n9Lt1390TdeMtbcrmsFi0cpR3b03Xq6ZskSQteHK0V7xdoytQ9+tsjC9TcHKc7b5vSsf+117+ntLQWtbUZ3Xv3RNXVOftbY5916ZZXj9N933hRLmP1n4/HarM3S1+fEJhGm7/6MM07ZqUykpv0yxPeCuzjd+nb/wi8hiTFtWrayJ264ZUZEbsP0cLEGcX9OE2tV1cGlsg+NVmuUfHyPReYuXSfOUj+JU3yPdcouSUlGsX/OkPGGPnL29R2c3WgKLKSa2aS3Ec7/LnuM7r3V8N106OfBZZ0ftKj7RuTdep5ZZKkBY/l6P030jRlVrUeevsTNTe6dMfVIzv2v+auLRo3vVZpmW16dPkaPXZHoRY+6YnQvYk8v8+l++44XDfcuUwut9WrLw7Tjq2pOuWsbZKkl/8zUivey9Xk6aV6cP4bgSWyb5rQsX9iYpuOnFKmu/8wLjJ3IIr4fUb3/e5A3fjgJ3K7pUXP5GnHphSd+s09kqQFTxRoxZJMTTm+Ug+9ukpNjS7d+cvAF0WZuS26+vcb5XJbGSO9/YpH7y/O6u3mYp7fZ3TPdUMDn3VcVouezNL2jcndPielacrsWj387rrA56Srhve6L5zBGOOWdI+kEyTtkrTCGPO8tfbTEHF/kLSwT8e1A9RU2d4Kd5ekDAXWRdok6SJJT0u62lq7MsQ+M9u3nd6X20gzWXaqmROmEcN92JhIDyFm7J6bHekhxJQRX90S6SHElJY53kgPIaa4hzr8XJow8pdXRnoIMcVfVxfpIcSM5f7XVGMrov6E48SRQ23+dT+K9DB6tePCn62y1k7uaXv7CtO/sdae1H75F5Jkrb2lW9yPJbVKmiLpRWvt073d7kCeE7RK0tEhNs3sZZ/Fkhb3z4gAAAAARJjHGNN1MuSB9nP+PzdEnT+rIwVmg6Z2PYAxZoiksyXNVqAI2qcB/bFUAAAAAOjC29tMkPq2yO2fJP3cWuszIZfA3BtFEAAAAIBotUtS1x8vHCqp+2+NTpb0RHsB5JF0qjGmzVr7n54OShEEAAAAxCiz/y+RvULSQcaYUZJ2S/qmpG93DbDWjvr838aYvytwTtB/ejsoRRAAAACAqGStbTPGXK7Aqm9uSQ9Za9caYy5u337/f3NciiAAAAAAUctau0DSgm7XhSx+rLX/25djUgQBAAAAschq7yUEIElyRXoAAAAAADCQKIIAAAAAOArtcAAAAEBMMpLt2+/mOA0zQQAAAAAchSIIAAAAgKPQDgcAAADEKlaHC4mZIAAAAACOQhEEAAAAwFF6bIczxtylXibQrLU/7JcRAQAAAAgP2uFC6u2coJUDNgoAAAAAGCA9FkHW2ke6XjbGpFhr6/t/SAAAAADQf/Z5TpAxZrox5lNJ69ovjzfG3NvvIwMAAADw5dgo/4uQviyM8CdJJ0kqlyRr7UeSZvTjmAAAAACg3/RpdThr7c5uV/n6YSwAAAAA0O/68mOpO40xR0uyxpgEST9Ue2scAAAAAOxv+lIEXSzpz5KGSNotaaGky/pzUAAAAAC+JCvJmkiPIirtswiy1nolnTsAYwEAAACAfteX1eEOMMa8YIwpM8aUGmOeM8YcMBCDAwAAAIBw68vCCI9LekpSgaRCSfMl/as/BwUAAADgyzM2uv8ipS9FkLHWPmqtbWv/e0wRXdUbAAAAAP57PZ4TZIzJav/nm8aYayQ9oUDx8z+SXhqAsQEAAABA2PW2MMIqBYqez5eUmNdlm5V0Q38NCgAAAEAY0L8VUo9FkLV21EAOBAAAAAAGQl9+J0jGmMMlHSop6fPrrLX/6K9BAQAAAEB/2WcRZIz5taSZChRBCySdIukdSRRBAAAAAPY7fVkd7muS5kgqttZeIGm8pMR+HRUAAAAA9JO+FEGN1lq/pDZjTJqkUkn8WCoAAACA/VJfzglaaYzJkPRXBVaMq5P0fn8OCgAAAMCXF8kfJI1m+yyCrLWXtv/zfmPMK5LSrLVr+ndYAAAAANA/evux1Im9bbPWftA/QwIAAACA/tPbTNDtvWyzkmaHeSxfmjFGrqSkfQeiT6zb7DsIfRJfx1x0ONW3JkR6CDElcdTwSA8hprR9tiXSQ4gZvKeHlzsrM9JDiBmmyh3pIeBL6u3HUmcN5EAAAAAAhJnlS+1Q+rI6HAAAAADEDIogAAAAAI7SlyWyAQAAAOxvbPsf9rLPmSATcJ4x5vr2y8ONMUf1/9AAAAAAIPz60g53r6Tpkr7VfrlW0j39NiIAAAAA6Ed9aYebaq2daIz5UJKstZXGGNanBQAAAKId7XAh9WUmqNUY41Z7Co0xOZL8/ToqAAAAAOgnfSmC/iLpWUm5xpibJL0j6eZ+HRUAAAAA9JN9tsNZa/9pjFklaY4kI+ksa+26fh8ZAAAAgC/F0A4X0j6LIGPMcEkNkl7oep21dkd/DgwAAAAA+kNfFkZ4SYHzgYykJEmjJG2QdFg/jgsAAAAA+kVf2uGO6HrZGDNR0rx+GxEAAACA8KAdLqS+LIwQxFr7gaQp/TAWAAAAAOh3fTkn6KouF12SJkoq67cRAQAAAEA/6ss5Qald/t2mwDlCz/TPcAAAAACgf/VaBLX/SOpga+1PB2g8AAAAAMKFc4JC6vGcIGNMnLXWp0D7GwAAAADEhN5mgt5XoABabYx5XtJ8SfWfb7TW/rufxwYAAAAAYdeXc4KyJJVLmq3O3wuykiiCAAAAgChlbOAPe+utCMptXxnuE3UWP58jnQAAAAD2S70VQW5JgxVc/HyOIggAAADAfqm3ImiPtfZ3AzYSAAAAAOFlQ81noMfV4RR6BggAAAAA9mu9FUFzBmwUAAAAADBAemyHs9ZWDORAAAAAAIQZZ/KH1NtMEAAAAADEHIogAAAAAI7Slx9LBQAAALAf4sdSQ2MmCAAAAICjUAQBAAAAcBTa4QAAAIBYRTtcSMwEAQAAAHAUiiAAAAAAjkIRBAAAAMBROCcIAAAAiEWWJbJ7wkwQAAAAAEdhJiiMJs2o0sXXb5fLZfXKU7maf39htwiri6/frikzq9Tc5NLtPz1Qm9emyFPQrKtv26zMnFZZv9HLT+Tqub/nR+Q+RJNJk/bo4ks+DOTzlQM0/6lDgrYPHVqjq37yvkYfWKlHHjlCzzwzts/7OtH00Tt09WnvymWs/rPqED3y9pFB208et1HfPW61JKmhJV6/f+E4fVbs6djuMn49eskzKq1J0ZWPnTqQQ4865v1Gue6tlPyS/5QU2W+lB29f3STX9WVSQeAl1n/sINnzAzGuW8tlljdKGW75HiwY8LFHo0lHlWjeFWvkclktfGmE5j8+pluE1bwfrtGUqSVqbnbrjlsmafNnGZKks76+SSedtk3WStu2puvO309Ua4t7wO9DNJk8s0YX31Akt8vq5X9l6am787pFWF1yQ5GOml2jpkaXbr9ymDZ9PKiP+zoL7+vhNemYcs37+WdyuaWF/y7Q/L+N6BZhNe+azzTluAo1N7l0x3WHaPO61I6tLpfVn59YqfLSRP3m8nEDO3jEnH6dCTLGXGuMWWuMWWOMWW2MmWqMWWyM2WCM+cgY864xZkx77GJjzOT2f28zxjzT5ThfM8b8vT/H+mW5XFaX/XabfnXBGM07aZxmnlGu4aMbgmKmzKxW4cgmfX/2eP3ll6N0+Q1bJUm+NqO/3jxC804cryvPOUynn1+y175O43L5ddllq/Sr62Zo3kUna+bM7Ro+vDooprY2Qfffd6SeeWbMF97XaVzGr5+f8Y5++I/T9PW7/kcnjdukUTkVQTFFlWm66G9n6lv3fEN/WzxJ137lraDt35r+sbaWZQ7ksKOTz8p1V6V8N+fK97cCud5skLa37hVmj0iU7/8K5Pu/go4CSJL8J6XId0vuQI44qrlcVpf++CNd/7OjdfF35+r4Obs0bERNUMzkqSUaMrRePzj3BP3ltiN1+VWrJUnZnkZ95ZzN+tFFs3TpBXPldlkdP3tXBO5F9HC5rC67ebeuO3eULpw5RrPOrNLwg5qCYqbMrtWQUc264Jix+vPPhuqKW3b3eV8n4X09vFwuq0uv3ajrLx2vi888SsefUqJhB9QHxUw+rkJDRjTqB6dN1V9+O0aXX7chaPuZ5+3Uzq2DBnLYscFG+V+E9FsRZIyZLul0SROtteMkzZW0s33zudba8ZIekXRrD4eYbIw5rL/GF24Hj69T0fYkFe9MUlurS0tezNK0EyqDYqbNrdTrz3okGa1fnarBaT5l5rSosixBm9emSJIa693auSlJ2fl7f6hykoPHVKhoT6qKiwerrc2tJUuGa9r03UEx1dVJ2rgxW20+1xfe12kOG1qqneVp2l2ZpjafW4s+PlDHH7ItKGbNznzVNiVKkj7emafc9LqObblpdTrm4B36z0pm1LShRbYwTiqMk+KN/DMHybz7BT7cjEuSUulE/tzBh1SoaHeKivekqK3NpbfeGKrpx+4Jipl27B69vnCYJKMNn2YpZXCrMrMCH87dbquERJ9cbr8SE9tU7k2KwL2IHmOObFDRtgQV70hUW6tLi5/L0PSTgr8Emn5StV57OlOS0foPUpSS7lNWbmuf9nUS3tfD6+AjalS0I1nFu5IDz/WX8zR9ljcoZtosr15/Pl+S0YY16UpJbVOmp1mSlJ3XpCnHlWvhM91n44D/Tn++ExdI8lprmyXJWuu11hZ1i3lL0uge9r9N0i/7cXxh5clvUdmehI7L3j0Jys4LfsHLzm+Rd09iZ0xxgjz5LUExuUOadeBhDdqwOqV/BxzlPNmNKitL7rjs9Q5SdnZjv+8bq3LT6lVSPbjjcmn1YOWm1vcYf+akdXpv4/COyz859T39ZdE0WU6ulPH6pNwu7VY5cTLlvr3jPm2R+6I9cv2iVNrWstd2BGR7muQt7fJ8LUtWtid49sHjaVRZtxhPTqPKvcn69xOj9chTr+if/35Z9fXx+nCls9u3svNbVVbU9b0oXp6C4PciT36ryoriO2OK4pWd39qnfZ2E9/Xwys5tlre480sKb0misvOag2I8uc0qK04MivHkBmLm/WyTHrpztPz+gRkvYl9/FkGLJA0zxmw0xtxrjDk+RMwZkj7uYf+nJE00xvRUJEmSjDEXGWNWGmNWtqi5t9CB1+0DozEhQmznlUmDfLru3o36vxtGqKHO4adrhchVn6dMv8y+DmJDJkqaNGq3zpy0XnctmiZJOvbg7aqoS9L6opyBHF706sNjyR6UIN/jhfI9UCB7Vqrcv/bueyeHCvm6uFdQiBgrDR7comnH7tEF3zxJ5331FCUl+TTrhB39Mcz9Ruj3me5BoWP6tK/T8b7+X+vbY3PvB5yV0VEzvKqqiNemT1P32o4+iHS7m9Pa4ay1dZImSbpIUpmkJ40x/9u++Z/GmNWSjpF0dQ+H8CnQKveLfdzOA9baydbayQlK7C20X3mLE5RT0Pntj6egReWl8cExexLkKegs1Dz5LSovCcS44/y67t7P9ObzHr23MGtgBh3FvN5k5eR0zt54PA0qr0juZY/w7BurSmtSlNe1vS29TmW1e/dVj84r16/OWqKf/PNkVTcGvrEbP6JYM8Zu1/NXPaabvvGapowq0u++9vqAjT3a2By3VNpl5qesTTa724n4KS4pOfDyaqcmS21Wqt57tgiStyxJntwuz9ecRlV0a2nzliUrp1tMuTdZEyaXqXhPimqqE+XzufTu24U65PDgc92cxrsnXjmFXd+LWlVe3P29KF45hZ0zGp7CVlWUxPdpXyfhfT28vCWJ8uR3zvJ68ppVUZrYLSZJOfnNQTHlpQk69MhqTZtVrodfWaqf3/qpxh1Vqatv+XTAxo7Y1K+N6dZan7V2sbX215Iul3RO+6ZzrbUTrLVnWWt39nKIRyXNkDS8l5iosHHNYBWObFLe0CbFxft1/OkVWvZa8Enky17P0JyzvZKsxk6oVX2tW5VlCZKsfvz7rdq5OVnP/o3VoiRp44YsFRbWKi+vTnFxPh1//A4tWzak3/eNVZ/uztWw7GoVZtQozu3TiUds1lvrRwbF5KXX6tZvLdT1T8/WjvKMjuvveXWqTrvtfH3ljvN07VNztWJroa5/es7A3oFoMiZBZnertKdNarVyLW6QPbpbkV3h6/yKc32z5JeUxnlAoWxcn6nCoXXKy69XXJxfM2bv0rJ3g18Hl79boDkn7ZRkNebQCtXXx6uyIkllJckae2iFEhPbJFlNmFiqndud/U3xhtWDNGRUi/KGNSsu3q+ZZ1Zp2aLg1QuXLUrX3K9VSrIaO7FeDTUuVZTG92lfJ+F9Pbw2fpKqwhGNyhvSGHiun1KiZYs9QTHL38zWnK8US7IaM65a9XVxqvQm6u9/PlDfmXu0Ljh5uv7w00O15v1M3faLQyNzRxAz+m1utn3VN7+19rP2qyZI2i7p8L4ew1rbaoy5U9I1kt4I+yDDyO8zuu83I3XjIxvkdlktmp+jHZ8N0qnfLpEkLXg8TyvezNCUmVV66M2P1NTk0p0/O0CSdNjkOs39qldb1yfr7hcD3YGP3DZMKxZnROruRJzf79J9907UjTctCeRz0QHasT1dp566SZK0YMFoZWY26i9/eVWDBrXKb43OOmuj5s07RQ0N8SH3dTKf36VbXzxWd333JbldVs9/MEZbSrN0zpS1kqRnVhymC2euUvqgJv38jLc79vnO/ef0dlhnchv5r8iS+5rSwBLZJ6dIIxNkXqiVJNkzUmXeapDrhTrJLSnByHedp6MXxHWTV+ajJqnaL/c3d8v/3XTZUwb3coOxze9z6b4/jdeNt70rl0tatGCEdmxL06lfCayyteD5UVqxLE9TphXrb4+/quZmt+78/URJ0oZ1WXpnyRD95a9vyucz2rIpQy+/MDKC9yby/D6je64dopsf3yKXW1r0RJa2b0zSaecHWjJfetSj919P1ZQ5NXr4vfVqbl8iu7d9nYr39fDy+1y67+aDdeP9H8nltlr0bIF2bE7RqV8PLFy0YP4QrXg7W1NmVOhvC5apucmtO68bu4+joi/4sdTQjO2nhl9jzCRJd0nKkNQmaZMCrXFPS7raWruyW/ziz683xmyTNNla6zXGJEraKmmRtfZ/e7vNdFe2nZbk7N8vCauDR0Z6BDGjbApLS4dT+recvdpfuCVe4uxzFcLN99mWSA8hZriSnFuE9QeTwvLS4bK06t+qbi0LfXJtFEkaMsyOuPiqSA+jVxuvv2qVtXbyQN9uv73zWWtXSTo6xKaZPcTP7PLvkV3+3SyJ9RABAAAAhAVN6gAAAAAchSIIAAAAgKNQBAEAAABwFIogAAAAAI7CkkAAAABArGKJ7JCYCQIAAADgKBRBAAAAAByFdjgAAAAgFlnJ0A4XEjNBAAAAAByFIggAAACAo9AOBwAAAMQq2uFCYiYIAAAAgKNQBAEAAABwFNrhAAAAgFhFO1xIzAQBAAAAcBSKIAAAAACOQjscAAAAEIOM+LHUnjATBAAAAMBRKIIAAAAAOArtcAAAAECsoh0uJGaCAAAAADgKRRAAAAAAR6EIAgAAAOAoFEEAAABALLKBJbKj+a8vjDEnG2M2GGM2GWOuCbH9TGPMGmPMamPMSmPMsfs6JgsjAAAAAIhKxhi3pHsknSBpl6QVxpjnrbWfdgl7XdLz1lprjBkn6SlJY3s7LjNBAAAAAKLVUZI2WWu3WGtbJD0h6cyuAdbaOmvt5/NKKerDmnjMBAEAAACxKvqXyPYYY1Z2ufyAtfaBLpeHSNrZ5fIuSVO7H8QYc7akWyTlSjptXzdKEQQAAAAgUrzW2sm9bDchrturtLPWPivpWWPMDEk3SJrb243SDgcAAAAgWu2SNKzL5aGSinoKtta+JelAY4ynt4NSBAEAAACxykb5376tkHSQMWaUMSZB0jclPd81wBgz2hhj2v89UVKCpPLeDko7HAAAAICoZK1tM8ZcLmmhJLekh6y1a40xF7dvv1/SOZK+Y4xpldQo6X+6LJQQEkUQAAAAgKhlrV0gaUG36+7v8u8/SPrDFzkmRRAAAAAQo/r6g6ROwzlBAAAAAByFIggAAACAo9AOBwAAAMQq2uFCiqkiyForf1NTpIcRO9asj/QIYkb2mkiPIMb8LdIDiC2+SA8A6AHv6WFGPsPGWl4593e0wwEAAABwFIogAAAAAI4SU+1wAAAAANpZcU5QD5gJAgAAAOAoFEEAAAAAHIV2OAAAACBGGdrhQmImCAAAAICjUAQBAAAAcBTa4QAAAIBYRTtcSMwEAQAAAHAUiiAAAAAAjkI7HAAAABCjWB0uNGaCAAAAADgKRRAAAAAAR6EdDgAAAIhVtMOFxEwQAAAAAEehCAIAAADgKBRBAAAAAByFc4IAAACAWGTFOUE9YCYIAAAAgKNQBAEAAABwFNrhAAAAgBhk2v+wN2aCAAAAADgKRRAAAAAAR6EdDgAAAIhVrA4XEjNBAAAAAByFIggAAACAo9AOBwAAAMQoQztcSMwEAQAAAHAUiiAAAAAAjkI7HAAAABCraIcLiZkgAAAAAI5CEQQAAADAUWiHAwAAAGIV7XAhMRMEAAAAwFEoggAAAAA4CkVQGE2eWaMH316vh99dp29cXhIiwuqSG3br4XfX6b7XNmj0EQ1fYF/nIZ/hRT7Dh1yGF/kML/IZPuQyvMgnoklEiiBjjM8Ys9oY84kxZr4xZlD79XVdYpa3x+wwxpS1/3u1MWZkJMa8Ly6X1WU379Z1547ShTPHaNaZVRp+UFNQzJTZtRoyqlkXHDNWf/7ZUF1xy+4+7+s05DO8yGf4kMvwIp/hRT7Dh1yGF/mMECuZKP+LlEjNBDVaaydYaw+X1CLp4u4B1tqp1toJkq6X9GR7/ARr7baBHWrfjDmyQUXbElS8I1FtrS4tfi5D00+qDoqZflK1Xns6U5LR+g9SlJLuU1Zua5/2dRryGV7kM3zIZXiRz/Ain+FDLsOLfCLaREM73NuSRkd6EF9Wdn6ryooSOi5798TLU9AaFOPJb1VZUXxnTFG8svNb+7Sv05DP8CKf4UMuw4t8hhf5DB9yGV7kE9EmoktkG2PiJJ0i6ZVIjiMcjNn7Ott9iq+HmD7t6zDkM7zIZ/iQy/Ain+FFPsOHXIYX+YwgchVSpIqgZGPM6vZ/vy3pb//tgYwxF0m6SJKSNOjLj+y/5N0Tr5zClo7LnoJWlRfHh4jp/ObCU9iqipJ4xSfYfe7rNOQzvMhn+JDL8CKf4UU+w4dchhf5RLSJ9DlBE6y1V1hrW/a9S2jW2gestZOttZPjlRjOMX4hG1YP0pBRLcob1qy4eL9mnlmlZYvSg2KWLUrX3K9VSrIaO7FeDTUuVZTG92lfpyGf4UU+w4dchhf5DC/yGT7kMrzIJ6JNRNvhYonfZ3TPtUN08+Nb5HJLi57I0vaNSTrtfK8k6aVHPXr/9VRNmVOjh99br+ZGl26/cliv+zoZ+Qwv8hk+5DK8yGd4kc/wIZfhRT4jJ5IrsEUzYyPQVGmMqbPWDg5xvV9SUZer7pBUIWmytfbyfR03zWTZqWZO+AYKAAAAdLPcvq4aWxHibKXoMih3mB3z9asiPYxerb73qlXW2skDfbsRmQkKVQC1X99Te97f+280AAAAAJyEdjgAAAAgVtEOF1I0/E4QAAAAAAwYiiAAAAAAjkI7HAAAABCjWB0uNGaCAAAAADgKRRAAAAAAR6EIAgAAAOAonBMEAAAAxCIrlsjuATNBAAAAAByFIggAAACAo9AOBwAAAMQq2uFCYiYIAAAAgKNQBAEAAABwFNrhAAAAgBhkJBna4UJiJggAAACAo1AEAQAAAHAU2uEAAACAWEU7XEjMBAEAAABwFIogAAAAAI5COxwAAAAQo4ylHy4UZoIAAAAAOApFEAAAAABHoR0OAAAAiEVWrA7XA2aCAAAAADgKRRAAAAAAR6EIAgAAAOAonBMEAAAAxCjDOUEhMRMEAAAAwFEoggAAAAA4Cu1wAAAAQKyiHS4kZoIAAAAAOApFEAAAAABHoR0OAAAAiFGsDhcaM0EAAAAAHIUiCAAAAICj0A4HAAAAxCra4UJiJggAAACAo1AEAQAAAHAU2uEAAACAWGRZHa4nzAQBAAAAcBSKIAAAAACOQhEEAAAAwFE4JwgAAACIVZwTFBIzQQAAAAAchSIIAAAAgKPQDgcAAADEICOWyO4JM0EAAAAAHIUiCAAAAICj0A4HAAAAxCpLP1wozAQBAAAAcBSKIAAAAACOQhEEAAAAxChjo/uvT/fBmJONMRuMMZuMMdeE2H6uMWZN+997xpjx+zomRRAAAACAqGSMcUu6R9Ipkg6V9C1jzKHdwrZKOt5aO07SDZIe2NdxKYIAAAAARKujJG2y1m6x1rZIekLSmV0DrLXvWWsr2y8ukzR0XwdldTgAAAAgFtn2v+jmMcas7HL5AWtt15mcIZJ2drm8S9LUXo73fUkv7+tGKYIAAAAARIrXWju5l+0mxHUhSztjzCwFiqBj93WjFEEAAAAAotUuScO6XB4qqah7kDFmnKQHJZ1irS3f10E5JwgAAABAtFoh6SBjzChjTIKkb0p6vmuAMWa4pH9LOt9au7EvB2UmCAAAAIhRxh/pEXw51to2Y8zlkhZKckt6yFq71hhzcfv2+yVdLylb0r3GGElq20eLHUUQAAAAgOhlrV0gaUG36+7v8u8fSPrBFzkm7XAAAAAAHIWZIAAAACBWRf8S2RHBTBAAAAAAR6EIAgAAAOAotMMBAAAAMcrQDhcSM0EAAAAAHIUiCAAAAICj0A4HAAAAxCIrydIPFwozQQAAAAAchSIIAAAAgKPQDgcAAADEKFaHC42ZIAAAAACOQhEEAAAAwFFohwMAAABiFe1wITETFEaTZ9bowbfX6+F31+kbl5eEiLC65IbdevjddbrvtQ0afUTDF9jXechneJHP8CGX4UU+w4t8hg+5DC/yiWgSFUWQMcZnjFltjPnEGPOCMSbDGLO8/bodxpiy9n+vNsaMjPR4Q3G5rC67ebeuO3eULpw5RrPOrNLwg5qCYqbMrtWQUc264Jix+vPPhuqKW3b3eV+nIZ/hRT7Dh1yGF/kML/IZPuQyvMgnok1UFEGSGq21E6y1h0uqkHSZtXaqtXaCpOslPdm+fYK1dlskB9qTMUc2qGhbgop3JKqt1aXFz2Vo+knVQTHTT6rWa09nSjJa/0GKUtJ9yspt7dO+TkM+w4t8hg+5DC/yGV7kM3zIZXiRT0SbaCmCuloqaUikB/FFZee3qqwooeOyd0+8PAWtQTGe/FaVFcV3xhTFKzu/tU/7Og35DC/yGT7kMrzIZ3iRz/Ahl+FFPiPDKLBEdjT/RUpUFUHGGLekOZKe/wL7XGSMWWmMWdmq5v4b3D7Hsfd1tvv/2B5i+rSvw5DP8CKf4UMuw4t8hhf5DB9yGV7kE9EmWlaHSzbGrJY0UtIqSa/2dUdr7QOSHpCkNJMVsaeEd0+8cgpbOi57ClpVXhwfIqbzmwtPYasqSuIVn2D3ua/TkM/wIp/hQy7Di3yGF/kMH3IZXuQT0SZaZoIa28//GSEpQdJlkR3OF7dh9SANGdWivGHNiov3a+aZVVq2KD0oZtmidM39WqUkq7ET69VQ41JFaXyf9nUa8hle5DN8yGV4kc/wIp/hQy7Di3xGiLXR/xch0TITJEmy1lYbY34o6TljzH3W2v2m4dPvM7rn2iG6+fEtcrmlRU9kafvGJJ12vleS9NKjHr3/eqqmzKnRw++tV3OjS7dfOazXfZ2MfIYX+Qwfchle5DO8yGf4kMvwIp+INsZGQVOlMabOWju4y+UXJD1lrX3UGPO/kiZbay/f13HSTJadaub040gBAADgdMvt66qxFSHOVoouqRlD7YSZP4r0MHr1znM/W2WtnTzQtxsVM0FdC6D2y2d0+fffJf19gIcEAAAA7PciuQJbNIuWc4IAAAAAYEBQBAEAAABwlKhohwMAAADQD2iHC4mZIAAAAACOQhEEAAAAwFFohwMAAABiFKvDhcZMEAAAAABHoQgCAAAA4CgUQQAAAAAchXOCAAAAgFhkJfk5KSgUZoIAAAAAOApFEAAAAABHoR0OAAAAiFV0w4XETBAAAAAAR6EIAgAAAOAotMMBAAAAMcrQDhcSM0EAAAAAHIUiCAAAAICj0A4HAAAAxCpLP1wozAQBAAAAcBSKIAAAAACOQjscAAAAEKNYHS40ZoIAAAAAOApFEAAAAABHoR0OAAAAiEW2/Q97YSYIAAAAgKNQBAEAAABwFIogAAAAAI7COUEAAABADDKSjOWkoFCYCQIAAADgKBRBAAAAAByFdjgAAAAgVvkjPYDoxEwQAAAAAEehCAIAAADgKLTDAQAAADGK1eFCYyYIAAAAgKMwEwRg/+NyR3oEscVy1mw4xeXnRXoIMaPy+JGRHkJMee+O+yM9hJhx1EkNkR4CviSKIAAAACAW2fY/7IV2OAAAAACOQhEEAAAAwFFohwMAAABikpVYHS4kZoIAAAAAOApFEAAAAABHoQgCAAAA4CicEwQAAADEKMMpQSExEwQAAADAUSiCAAAAADgK7XAAAABArGKJ7JCYCQIAAADgKBRBAAAAAByFdjgAAAAgFlnJ+CM9iOjETBAAAAAAR6EIAgAAAOAotMMBAAAAsYrV4UJiJggAAACAo1AEAQAAAHAU2uEAAACAWEU3XEjMBAEAAABwFIogAAAAAI5CEQQAAADAUTgnCAAAAIhRhiWyQ2ImCAAAAICjUAQBAAAAcBTa4QAAAIBYRTtcSMwEAQAAAHAUiiAAAAAAjkI7HAAAABCLrCR/pAcRnZgJAgAAAOAoFEEAAAAAHIV2OAAAACAGGVl+LLUHzAQBAAAAcBSKIAAAAACOQjscAAAAEKtohwuJmSAAAAAAjsJMUBhNnlmji28okttl9fK/svTU3XndIqwuuaFIR82uUVOjS7dfOUybPh7Ux32dh3yGF/kMn8kzq3Xxb3fJ7ZZe/le2nronv1uE1SW/29WeS6PbrxypTZ8EcnnVbds1dW61qrxxmjf30IEffBSaPLNGF/9ud/vjK1tP3RPisfm73V0em8M78rnvfZ1n0vQyXXT1erncVov+M1Tz/35AtwireT9dr8nHlKm5ya07f3OENq9PkyQ99MISNTbEye8z8vmMfnz+9IG/A1Fk6tgd+vFZ78ntsnph2Vg9+saRQdtPnPiZzpu9WpLU2ByvW585TpuKsvu0rxOteDNV9/9qiHx+o1O+Va7/uaI0aPv8e3P0xr+zJEk+n7TzsyQ9+fEnSkr26ydfHa3WFpd8bdJxp1XrOz8tjsRdQAzp15kgY4zPGLO6y99IY8xMY8yLXWJuNMYsNMY8a4w5q8v1G4wx13W5/Iwx5qv9Od4vw+Wyuuzm3bru3FG6cOYYzTqzSsMPagqKmTK7VkNGNeuCY8bqzz8bqitu2d3nfZ2GfIYX+Qwfl8vqsht36rrzR+vCWYdo1pmVGn5QY1DMlNk1gVwee6j+/PMRuuKWHR3bFs3P0rXnjR7oYUctl8vqspt26brzDtCFs8Zq1lmVPT82jz1Ef/75MF1xy64+7+s0LpfVJdes069/OEmXfO1YzThpj4aNqguKmXyMV4XDGnThWcfprhsP02W/+DRo+y/mTdEV3z7a8QWQy/h19Vff1U8eOFXf/sM3NHfiJo3MqwyKKapI1WX3fEXfue3revjVifr519/q875O4/NJ9/xyqG785xb9dfF6vflcprZvTAyK+fqlZbrvtQ2677UN+t4v9uiI6XVKy/QpPtHqj/M36/7XNui+Vzdo5eJUrVs1KEL3ZD9kbXT/RUh/t8M1WmsndPnb1nWjMeZaScdIOkvSe5KObr8+W1KdpK6vwNPbY6LSmCMbVLQtQcU7EtXW6tLi5zI0/aTqoJjpJ1XrtaczJRmt/yBFKek+ZeW29mlfpyGf4UU+w2fMhHoVbUvsko9MTT+xWy5PrNZrT2epI5dpgVxK0ifLU1Vb5Y7AyKNT4PHVLZ8hH5td8hn02Ox9X6c5+LBqFe0cpOLdg9TW5tJbiwo0bWbwt+3Tji/VGy8VSjLa8EmGUga3KtPTHJkBR7FDh5dqlzdNRRVpavO59dqHo3Xc4duCYj7Zlq/axsAH+bXb85SbUdfnfZ1mw4eDVDiyWQUjWhSfYDXzzEotXZjeY/yb/8nUzLMChaMxUnKKX5LU1mrkazUyZkCGjRgWsXOCjDE/kXSqpDOstY2S3lV7EdT+3xcl5ZiAUQoUVFE795md36qyooSOy9498fIUtAbFePJbVVYU3xlTFK/s/NY+7es05DO8yGf4ZBe0qmxPl3wUh8plS7ecJSg7v2XAxrg/ye7+uNsTL0/+Ph6be7o+Nnvf12myc5vkLUnquOwtSVJ2TlO3mGaVdY0p7Yyx1uiGe1bqz48t1cln7xyYQUepnPQGlVQN7rhcVpWinPT6HuNPn7peS9cN/6/2dYLy4njlFHY+Pz0FrfLuiQ8Z29RgtHJxqo49tfNLDZ9PumTuGP3PuMN15IxajZ3Y0O9jRmzr7yIouUsr3LNdrj9G0sWSTrHWfj5Pv0rS4caYBAWKoKWSNkg6pP3yu6FuwBhzkTFmpTFmZasi901WqG8k9prh6yGmT/s6DPkML/IZPqG+fOxbLvnaMhQem+EV8tvxbo89Y0Ikqf2qn37vKP3o3KN1/RUTddo3duiwIyvCP8j9RYg89fT4mjh6t86Yul73vjj1C+/rFKHuf0+zOcteTddhk+uVlunruM7tlu57bYP+uepTbVg9SNvWJ4XeGTHJGHNy+6kym4wx14TYPtYYs9QY02yMubovx+zvhREarbUTQly/SVKmpBMlPS1J1tpmY8xaSRMlTZP0R0kHKFAAHakeWuGstQ9IekCS0kxWxF5ivHvilVPY+U2vp6BV5cXxIWK6fAtS2KqKknjFJ9h97us05DO8yGf4ePfEK6egSz7yQ+UyoVvOWlRR4tyc9Wavx11Bq8pL9vHYLOj62Ox9X6fxliTJk9c58+PJa1K5N3GvmJyuMblNKvcGPlBWtP+3ujJRS9/M05jDq7X2w6wBGHn0KatKUV5G5/lUORn18tak7BV3YEG5fvGNt3TVX09RTUPSF9rXSTwFoWd0Q1nyXEZHK1x3g9N9Gj+9TiveTNXIsc4+B7BPrCR/pAfx5Rhj3JLukXSCpF2SVhhjnrfWdj2hsULSDxU4xaZPItUOV6JAK9ydxphZXa5/T9IMSanW2kpJyxQognqcCYoWG1YP0pBRLcob1qy4eL9mnlmlZYuCe12XLUrX3K9VSrIaO7FeDTUuVZTG92lfpyGf4UU+w2fDRykaMqq5Sz4qtezVULmsUEcua92qKHX2h/OeBB5f3fK5KC0oZtmitOB81ri7PDZ739dpNn6apiHDGpRX2KC4OL9mnLhHy5fkBsUsfytXs08rkmQ15vAq1dfFqdKbqMSkNiUPapMkJSa1aeK0cm3fNDjErTjDup25GppTrYKsGsW5fZp75Ca988mIoJi8jFrdcsEi/fbxWdpZlvGF9nWaMRMatHtroop3JKi1xWjxc5madmLNXnH1NS6tWTZYR5/cua2q3K266sC5lM2NRh+8naphozmPzUGOkrTJWrvFWtsi6QlJZ3YNsNaWWmtXSOpzT3TElsi21m5sX+3tP8aY06y1qxUodG6XtLg9bI0Cs0J5ktZGYpx95fcZ3XPtEN38+Ba53NKiJ7K0fWOSTjvfK0l66VGP3n89VVPm1Ojh99aruX0J4t72dTLyGV7kM3z8PqN7fjVMN/9zk1wuq0VPZmv7xmSddl6ZJOmlx3L0/htpmjK7Wg+/s1bNTS7dflXnh59r7t6qcdNrlZ7VpsdWfKxHby/Qwic8kbo7Eef3Gd1z3dDA48tltejJrEA+gx6baZoyu1YPv7su8Ni8aniv+zqZ3+fSfX88RDfcvUout9Wrzw3Rji2Ddco5gfN7Xn5mmFa849HkY8r04HNvty+RfbgkKTO7Rdfe9qEkye22WvJKgVYtzYnYfYk0n9+lO/59rO68aIHcLqsX3x+jrSVZOmt64Mvn/yw9VBec+IHSBjXp6nPead/H6Pt3ntPjvk7mjpMuu2mXfvntA+T3GZ34zQqNHNOkF/8RWFL89O+US5LefTlDk2bUKmlQ5/RFRUm8bvvRcPn9Rn6/NOOMKk07Ye8CCjFriKSuJynukjT1yx7U2H5sUjXG1FlrB3e7bqakq621p7dfPlHSg5JmSapVYJboQmvtg+3bF0tqttaetK/bSzNZdqqZE867ACAauVhdLazsft4rEWXi8vmtonCpPH5kpIcQU9674/5IDyFmHHXSTq38qCnqT/ZMH1Ropx/8g0gPo1cLP7phuyRvl6seaD/dRZJkjPm6pJOstT9ov3y+pKOstVd0P5Yx5jeS6qy1t+3rdvt1Jqh7AdR+3WJ1zvTIWrtI0vAuIaZb/Mz+GR0AAACACPNaayf3sn2XpGFdLg+VVPRlbzRiS2QDAAAAwD6skHSQMWZU+yrS35T0/Jc9aMTOCQIAAADQz/bz9dmttW3GmMslLZTklvSQtXatMebi9u33G2PyJa2UlCbJb4z5saRDrbU9njxGEQQAAAAgallrF0ha0O26+7v8u1iBNrk+ox0OAAAAgKMwEwQAAADEJLvft8P1F2aCAAAAADgKRRAAAAAAR6EdDgAAAIhFVrTD9YCZIAAAAACOQhEEAAAAwFEoggAAAAA4CucEAQAAALHKH+kBRCdmggAAAAA4CkUQAAAAAEehHQ4AAACIUYYlskNiJggAAACAo1AEAQAAAHAU2uEAAACAWEU7XEjMBAEAAABwFIogAAAAAI5COxwAAAAQi6wkP+1woTATBAAAAMBRKIIAAAAAOArtcAAAAEBMsqwO1wNmggAAAAA4CkUQAAAAAEehHQ4AAACIVbTDhcRMEAAAAABHoQgCAAAA4CgUQQAAAAAchXOCAAAAgFjFOUEhMRMEAAAAwFEoggAAAAA4Cu1wAAAAQCyykvy0w4XCTBAAAAAAR6EIAgAAAOAoMdUOV6tK72v26e2RHkcfeCR5Iz2IGEEuw2v/yKcv0gPos/0jn/uH/SeXRZEeQJ/sH/n8V6QH0Gf7RT7d5DOcRkR6AH1jJeuP9CCiUkwVQdbanEiPoS+MMSuttZMjPY5YQC7Di3yGF/kMH3IZXuQzvMhneJFPDATa4QAAAAA4SkzNBAEAAADogh9LDYmZoMh4INIDiCHkMrzIZ3iRz/Ahl+FFPsOLfIYX+US/M5bqEAAAAIg56Yl59uiCb0d6GL16ZfufVkXiHDDa4QAAAIBYxI+l9oh2OADA/7d378F2leUdx78/IncRvETLUGxAUUDaBhqFhBFCWy2hKmrpSMtMqb0gHS5jK3/YyvQ+007xNiKKFCxaUSzXwUsJLZKCCDUmBDBYaBQqDG3lVgqaqiRP/1jr4Oa4z8kmydn77L2+n5kz2ftd71rr2c/syT7PeZ+1tiRJnWIRNEeSbEqyLsntSdYmWdaOL0qyMcltSb6R5KtJTh51vOMgyU8kuTTJN5PcleSLSV5hPgeX5D1J1ie5o31/3tD+uyHJ4+3jdUmWJVmV5O72Pbw6yeJRxz/f9Mnn4dPydnOSVya5aqY8j/o1zAeD5rGduyrJkvbxfUmu6DnOCUkuHtHLmHd6Poe+nuSyJLu140/2zPnXds63kzzU895cNLLA57lpef1ckr3M42B6cvd0fpIsT/L5njl/mWRl+//mm3vG705yds/zK5K8dcgvQRPEdri5s7GqFgMk+SXgr4Cj223frKpD2237A1cm2aGq/m4kkY6BJAGuAj5RVSe2Y4uBl2A+B5JkKfAG4LCq+n6SFwE7VdWDSZYDZ1XVG3rmA5xUVV9L8nbgHOB1w498fpopn+3mqbydApxTVW9q91nOtDx33bPJI/CmPodYkuRVVbV+SCGPk97PoUuAU4H3906oqsPb7b8JLKmq04cc4zjqzesngNPM48Cezt2U3kIxyXuAI4HjgNOBZcDVSV4IPAks7dl1KXDaHMerCeZK0HA8D3is34aq+hbwB8CZQ41o/BwD/LCqzp8aqKp1wP29k8znrPYGHq6q7wNU1cNVNeh3298C7DNnkY2nQfJ5I/DyoUc2XrY1j+8F/mgO45sUN+F7cS74f+N2kuRdNMXPG6tqI3AzTRFE++/ngYVp7EdTUP3XaKIdM1Xz+2dELILmzq7tUu+/ARcCfzHL3LXAgcMJa2wdAqwZcK757O86YN8k9yT5SJKjt7jHjxwLXD03YY2tQfL5RuDOIcc1brY1j/8AHJbEX/BnkOQ5wAp8L25XSRYAvwBcM+pYxsjU70brklzVM34kzUrliqqaatdcAxySZCeaIugW4G7goPb5zUOMWxPIdri507tcvhT4ZJJDZpiboUXVDeazj6p6MsnPAa+lWVn7bJJ3V9XFs+x2SZLdgQXAYUMIc2zMlM928yVJNgL3AWeMKMSxsB3yuImmVe4PgX+c43DHza5J1rWPbwIuGmEsk2Qqr4toflH/p5FGM15+rB2utQF4PvB64HKAtj12Pc1nzxHA3wD70xRAhwJfGUbAmlwWQUNQVbe0fe4LZ5hyKPCNIYY0jtYDJww413zOoKo2AauAVUnuBE4GLp5ll5OA24G/Bs4DvAi1xwz5hPZalpEFNma2Qx7/nqYI8rqgZ5rpF05tm41VtTjJnjQtWqcBHxpxTOPuv2k+b65P8khV3dCOfwU4Ctijqh5LcivNtUKHAuf3P5R+jN8J2pftcEOQ5ECav6Q/0mfbIpqe9nOHHNa4+RKwc5LfnRpI8mrgp3onmc+ZpblL2QE9Q4uB/9jSflX1Q+Bs4IgkB81ReGNna/OpZ9oeeWzfox8A3rn9IpNmV1WP01x/elaSHUcdz7irqnto/tD2qfzobqQ3A++g+WMcwB00q0IvxT96aBu5EjR3etsQApxcVZvaO269LMltwC7AE8C53slsdlVVSd4CfLBtlfk/mhaZd2I+B/Vc4NwkewFP0bQfnDLIjlW1Mcn7gLOA356zCMfLTPm8fJRBjaHtlceLaIp1bdluSR7oef5+4NFRBTPOquq2JLcDJ9KsSGobVNXq9m6k1yQ5hmYlaH+aO+xSVU8l+Q5wf1VtHmGomgApl8gkSZKkibPnTi+uZQvfNuowZnXtgx9eU1VLhn1e2+EkSZIkdYpFkCRJkqRO8ZogSZIkaRIVsNnLp/pxJUiSJElSp1gESZIkSeoUiyBJGqIkm5KsS/L1JJcl2W0bjnVxkhPaxxcmOXiWucuTLNuKc9zXftnzQOPT5jz5LM/1p0nOerYxSpJmUTW/f0bEIkiShmtjVS2uqkOAHwCn9m5MsmBrDlpVv1NVd80yZTnwrIsgSZImkUWQJI3OTcDL21WaG5J8GrgzyYIk5yRZneSOJO8ASOPDSe5K8gXgxVMHSrIqyZL28bFJ1ia5Pcn1SRbRFFu/365CvTbJwiRXtOdYneTIdt8XJrkuyW1JPkbzZc+zSnJ1kjVJ1ic5Zdq297WxXJ9kYTv2siTXtvvclOTA7ZJNSZIG5N3hJGkEkjwHWAFc2w69Bjikqu5tC4nHq+rVSXYGbk5yHXAo8Ergp4GXAHcBH5923IXA3wJHtcd6QVU9muR84Mmqem8779PAB6rqy0leCqwEDgL+BPhyVf15kl8GnlHUzOC32nPsCqxOckVVPQLsDqytqncl+eP22KcDFwCnVtW/Jzkc+Ajw81uRRkmStopFkCQN165J1rWPbwIuomlT+2pV3duOvx74manrfYA9gQOAo4DPVNUm4MEkX+pz/COAG6eOVVWPzhDHLwIHJ08v9DwvyR7tOd7a7vuFJI8N8JrOTPKW9vG+bayPAJuBz7bjnwKuTPLc9vVe1nPunQc4hyRpa4zwupv5zCJIkoZrY1Ut7h1oi4Hv9g4BZ1TVymnzjqP51ofZZIA50LRDL62qjX1iGfgTM8lymoJqaVV9L8kqYJcZpld73v+ZngNJkobJa4Ikaf5ZCfxekh0Bkrwiye7AjcCJ7TVDewPH9Nn3FuDoJPu1+76gHX8C2KNn3nU0rWm08xa3D28ETmrHVgDP30KsewKPtQXQgTQrUVN2AKZWs36dps3uf4F7k/xqe44k+dktnEOSpO3KlSBJmn8uBBYBa9MszTwEvBm4iubamTuBe4B/mb5jVT3UXlN0ZZIdgO8ArwM+B1ye5HjgDOBM4Lwkd9B8FtxIc/OEPwM+k2Rte/xvbyHWa4FT2+PcDdzas+27wKuSrAEeB97Wjp8EfDTJ2cCOwKXA7QNlRpL0LBRsth2un5R9gpIkSdLE2XPHhbVsr18ZdRizuvbhj62pqiXDPq/tcJIkSZI6xXY4SZIkaRIVVG0edRTzkitBkiRJkjrFIkiSJElSp9gOJ0mSJE0q7w7XlytBkiRJkjrFIkiSJElSp9gOJ0mSJE0qvxO0L1eCJEmSJHWKRZAkSZKkTrEdTpIkSZpEVbDZL0vtx5UgSZIkSZ1iESRJkiSpUyyCJEmSJHWK1wRJkiRJk8pbZPflSpAkSZKkTrEIkiRJktQptsNJkiRJE6q8RXZfrgRJkiRJ6hSLIEmSJEmdYjucJEmSNJHKu8PNwJUgSZIkSZ1iESRJkiSpU2yHkyRJkiZRAZtth+vHlSBJkiRJnWIRJEmSJKlTbIeTJEmSJlX5Zan9uBIkSZIkqVMsgiRJkiR1ikWQJEmSpE7xmiBJkiRpAhVQ3iK7L1eCJEmSJHWKRZAkSZKkTrEdTpIkSZpEVd4iewauBEmSJEnqFIsgSZIkSZ1iO5wkSZI0obw7XH+uBEmSJEnqFIsgSZIkSZ1iESRJkiRNqto8v38GkOTYJHcn2ZDk3X22J8mH2u13JDlsS8e0CJIkSZI0LyVZAJwHrAAOBn4tycHTpq0ADmh/TgE+uqXjWgRJkiRJmq9eA2yoqm9V1Q+AS4Hjp805HvhkNW4F9kqy92wH9e5wkiRJ0gR6gsdW/nNd/qJRx7EFuyT5Ws/zC6rqgp7n+wD39zx/ADh82jH6zdkH+M+ZTmoRJEmSJE2gqjp21DFsB+kzNv2+34PMeQbb4SRJkiTNVw8A+/Y8/0ngwa2Y8wwWQZIkSZLmq9XAAUn2S7ITcCJwzbQ51wC/0d4l7gjg8aqasRUObIeTJEmSNE9V1VNJTgdWAguAj1fV+iSnttvPB74IHAdsAL4HvH1Lx03VrO1ykiRJkjRRbIeTJEmS1CkWQZIkSZI6xSJIkiRJUqdYBEmSJEnqFIsgSZIkSZ1iESRJkiSpUyyCJEmSJHXK/wPbdMBjW2FiKwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=[15, 15])\n",
    "disp2.plot(include_values=True,\n",
    "                     cmap='viridis', ax=ax, xticks_rotation='horizontal',\n",
    "                     values_format='.2f', colorbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STAR2006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STAR2006\n"
     ]
    }
   ],
   "source": [
    "ee = deployment[2]\n",
    "print(ee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "fea_temp = np.load(os.path.join(feature_path, 'train_oswald_no_'+ee+'.npz'))\n",
    "fea_train = fea_temp['fea_train']\n",
    "label_train_list = fea_temp['label_train']\n",
    "del fea_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train = np.zeros(len(label_train_list))\n",
    "for ii in range(len(label_train_list)):\n",
    "    label_train[ii] = species_dict[label_train_list[ii]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing data\n",
    "fea_temp = np.load(os.path.join(feature_path, 'oswald_'+ee+'_orig.npz'))\n",
    "fea_test = fea_temp['feas_orig']\n",
    "label_test_list = fea_temp['labels_orig']\n",
    "\n",
    "fea_test = fea_test[:,:100,:]\n",
    "label_test = np.zeros(len(label_test_list))\n",
    "for ii in range(len(label_test_list)):\n",
    "    label_test[ii] = species_dict[label_test_list[ii]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_train = fea_train[:,:100,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train = np.zeros(len(label_train_list))\n",
    "for ii in range(len(label_train_list)):\n",
    "    label_train[ii] = species_dict[label_train_list[ii]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'BD': 11466,\n",
       "         'CD': 28296,\n",
       "         'PLT': 8250,\n",
       "         'RT': 7590,\n",
       "         'SPIN': 6198,\n",
       "         'SPT': 12744,\n",
       "         'STR': 10692,\n",
       "         'FKW': 13662})"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(label_train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1.0: 24, 7.0: 903, 5.0: 632, 6.0: 46, 4.0: 2, 3.0: 147, 2.0: 750})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(label_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_result_path2 = os.path.join(fit_result_path1, ee)\n",
    "if not os.path.exists(fit_result_path2):\n",
    "    makedirs(fit_result_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature train shape: (98898, 100, 128)\n",
      "feature test shape: (2504, 100, 128)\n",
      "label train shape: (98898,)\n",
      "label test shape: (2504,)\n",
      "dim_time: 100\n",
      "dim_freq: 128\n"
     ]
    }
   ],
   "source": [
    "print('feature train shape: '+str(fea_train.shape))\n",
    "print('feature test shape: '+str(fea_test.shape))\n",
    "print('label train shape: '+str(label_train.shape))\n",
    "print('label test shape: '+str(label_test.shape))\n",
    "\n",
    "dim_time = fea_train.shape[1]\n",
    "dim_freq = fea_train.shape[2]\n",
    "print('dim_time: '+str(dim_time))\n",
    "print('dim_freq: '+str(dim_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle features & labels\n",
    "fea_train, label_train = shuffle(fea_train, label_train, random_state=0)\n",
    "fea_test, label_test = shuffle(fea_test, label_test, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class weight\n",
    "weights = compute_class_weight(class_weight='balanced', classes=np.unique(label_train), y=label_train)\n",
    "\n",
    "class_weights = dict()\n",
    "for ii in range(num_species):\n",
    "    class_weights[ii] = weights[ii]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_train = np.expand_dims(fea_train, axis=3)\n",
    "fea_test = np.expand_dims(fea_test, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_train, fea_validate, label_train, label_validate = train_test_split(fea_train, label_train, test_size=0.10, random_state=42)\n",
    "\n",
    "train_generator = DataGenerator(fea_train, label_train, batch_size=batch_size, num_classes=num_species)\n",
    "del fea_train\n",
    "validate_generator = DataGenerator(fea_validate, label_validate, batch_size=batch_size, num_classes=num_species)\n",
    "del fea_validate\n",
    "\n",
    "# test_generator = DataGenerator(fea_test, label_test, batch_size=batch_size, num_classes=num_species)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "   2/5563 [..............................] - ETA: 11:41 - loss: 9.1858 - accuracy: 0.0625WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.119035). Check your callbacks.\n",
      "5563/5563 [==============================] - ETA: 0s - loss: 0.7844 - accuracy: 0.1270\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.08566, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2006/epoch_01_valloss_0.5004_valacc_0.0857.hdf5\n",
      "5563/5563 [==============================] - 95s 17ms/step - loss: 0.7844 - accuracy: 0.1270 - val_loss: 0.5004 - val_accuracy: 0.0857\n",
      "Epoch 2/200\n",
      "5563/5563 [==============================] - ETA: 0s - loss: 0.4934 - accuracy: 0.1418\n",
      "Epoch 00002: val_accuracy improved from 0.08566 to 0.18710, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2006/epoch_02_valloss_0.4460_valacc_0.1871.hdf5\n",
      "5563/5563 [==============================] - 95s 17ms/step - loss: 0.4934 - accuracy: 0.1418 - val_loss: 0.4460 - val_accuracy: 0.1871\n",
      "Epoch 3/200\n",
      "5563/5563 [==============================] - ETA: 0s - loss: 0.4496 - accuracy: 0.1750\n",
      "Epoch 00003: val_accuracy improved from 0.18710 to 0.24191, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2006/epoch_03_valloss_0.4112_valacc_0.2419.hdf5\n",
      "5563/5563 [==============================] - 95s 17ms/step - loss: 0.4496 - accuracy: 0.1750 - val_loss: 0.4112 - val_accuracy: 0.2419\n",
      "Epoch 4/200\n",
      "5562/5563 [============================>.] - ETA: 0s - loss: 0.4168 - accuracy: 0.2243\n",
      "Epoch 00004: val_accuracy improved from 0.24191 to 0.27326, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2006/epoch_04_valloss_0.3862_valacc_0.2733.hdf5\n",
      "5563/5563 [==============================] - 95s 17ms/step - loss: 0.4168 - accuracy: 0.2243 - val_loss: 0.3862 - val_accuracy: 0.2733\n",
      "Epoch 5/200\n",
      "5560/5563 [============================>.] - ETA: 0s - loss: 0.3949 - accuracy: 0.2633\n",
      "Epoch 00005: val_accuracy improved from 0.27326 to 0.30522, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2006/epoch_05_valloss_0.3699_valacc_0.3052.hdf5\n",
      "5563/5563 [==============================] - 94s 17ms/step - loss: 0.3949 - accuracy: 0.2634 - val_loss: 0.3699 - val_accuracy: 0.3052\n",
      "Epoch 6/200\n",
      "5563/5563 [==============================] - ETA: 0s - loss: 0.3769 - accuracy: 0.3008\n",
      "Epoch 00006: val_accuracy improved from 0.30522 to 0.32787, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2006/epoch_06_valloss_0.3549_valacc_0.3279.hdf5\n",
      "5563/5563 [==============================] - 94s 17ms/step - loss: 0.3769 - accuracy: 0.3008 - val_loss: 0.3549 - val_accuracy: 0.3279\n",
      "Epoch 7/200\n",
      "5561/5563 [============================>.] - ETA: 0s - loss: 0.3618 - accuracy: 0.3355\n",
      "Epoch 00007: val_accuracy improved from 0.32787 to 0.36630, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2006/epoch_07_valloss_0.3355_valacc_0.3663.hdf5\n",
      "5563/5563 [==============================] - 95s 17ms/step - loss: 0.3618 - accuracy: 0.3355 - val_loss: 0.3355 - val_accuracy: 0.3663\n",
      "Epoch 8/200\n",
      "5562/5563 [============================>.] - ETA: 0s - loss: 0.3494 - accuracy: 0.3699\n",
      "Epoch 00008: val_accuracy did not improve from 0.36630\n",
      "5563/5563 [==============================] - 94s 17ms/step - loss: 0.3494 - accuracy: 0.3699 - val_loss: 0.3427 - val_accuracy: 0.3607\n",
      "Epoch 9/200\n",
      "5561/5563 [============================>.] - ETA: 0s - loss: 0.3386 - accuracy: 0.3939\n",
      "Epoch 00009: val_accuracy improved from 0.36630 to 0.39543, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2006/epoch_09_valloss_0.3295_valacc_0.3954.hdf5\n",
      "5563/5563 [==============================] - 95s 17ms/step - loss: 0.3386 - accuracy: 0.3939 - val_loss: 0.3295 - val_accuracy: 0.3954\n",
      "Epoch 10/200\n",
      "5561/5563 [============================>.] - ETA: 0s - loss: 0.3301 - accuracy: 0.4135\n",
      "Epoch 00010: val_accuracy improved from 0.39543 to 0.41545, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2006/epoch_10_valloss_0.3220_valacc_0.4155.hdf5\n",
      "5563/5563 [==============================] - 95s 17ms/step - loss: 0.3301 - accuracy: 0.4135 - val_loss: 0.3220 - val_accuracy: 0.4155\n",
      "Epoch 11/200\n",
      "5563/5563 [==============================] - ETA: 0s - loss: 0.3233 - accuracy: 0.4293\n",
      "Epoch 00011: val_accuracy improved from 0.41545 to 0.44357, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2006/epoch_11_valloss_0.3114_valacc_0.4436.hdf5\n",
      "5563/5563 [==============================] - 95s 17ms/step - loss: 0.3233 - accuracy: 0.4293 - val_loss: 0.3114 - val_accuracy: 0.4436\n",
      "Epoch 12/200\n",
      "5561/5563 [============================>.] - ETA: 0s - loss: 0.3170 - accuracy: 0.4463\n",
      "Epoch 00012: val_accuracy did not improve from 0.44357\n",
      "5563/5563 [==============================] - 94s 17ms/step - loss: 0.3170 - accuracy: 0.4464 - val_loss: 0.3182 - val_accuracy: 0.4231\n",
      "Epoch 13/200\n",
      "5561/5563 [============================>.] - ETA: 0s - loss: 0.3120 - accuracy: 0.4545\n",
      "Epoch 00013: val_accuracy improved from 0.44357 to 0.45338, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2006/epoch_13_valloss_0.3033_valacc_0.4534.hdf5\n",
      "5563/5563 [==============================] - 98s 18ms/step - loss: 0.3120 - accuracy: 0.4545 - val_loss: 0.3033 - val_accuracy: 0.4534\n",
      "Epoch 14/200\n",
      "5563/5563 [==============================] - ETA: 0s - loss: 0.3065 - accuracy: 0.4705\n",
      "Epoch 00014: val_accuracy did not improve from 0.45338\n",
      "5563/5563 [==============================] - 95s 17ms/step - loss: 0.3065 - accuracy: 0.4705 - val_loss: 0.3207 - val_accuracy: 0.4329\n",
      "Epoch 15/200\n",
      "5560/5563 [============================>.] - ETA: 0s - loss: 0.3017 - accuracy: 0.4809\n",
      "Epoch 00015: val_accuracy improved from 0.45338 to 0.49110, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2006/epoch_15_valloss_0.2941_valacc_0.4911.hdf5\n",
      "5563/5563 [==============================] - 95s 17ms/step - loss: 0.3018 - accuracy: 0.4809 - val_loss: 0.2941 - val_accuracy: 0.4911\n",
      "Epoch 16/200\n",
      "5562/5563 [============================>.] - ETA: 0s - loss: 0.2969 - accuracy: 0.4918\n",
      "Epoch 00016: val_accuracy did not improve from 0.49110\n",
      "5563/5563 [==============================] - 94s 17ms/step - loss: 0.2969 - accuracy: 0.4918 - val_loss: 0.2992 - val_accuracy: 0.4805\n",
      "Epoch 17/200\n",
      "5562/5563 [============================>.] - ETA: 0s - loss: 0.2931 - accuracy: 0.4986\n",
      "Epoch 00017: val_accuracy improved from 0.49110 to 0.50253, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2006/epoch_17_valloss_0.2874_valacc_0.5025.hdf5\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2931 - accuracy: 0.4986 - val_loss: 0.2874 - val_accuracy: 0.5025\n",
      "Epoch 18/200\n",
      "5561/5563 [============================>.] - ETA: 0s - loss: 0.2896 - accuracy: 0.5071\n",
      "Epoch 00018: val_accuracy improved from 0.50253 to 0.54035, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2006/epoch_18_valloss_0.2694_valacc_0.5404.hdf5\n",
      "5563/5563 [==============================] - 95s 17ms/step - loss: 0.2895 - accuracy: 0.5071 - val_loss: 0.2694 - val_accuracy: 0.5404\n",
      "Epoch 19/200\n",
      "5561/5563 [============================>.] - ETA: 0s - loss: 0.2862 - accuracy: 0.5135\n",
      "Epoch 00019: val_accuracy improved from 0.54035 to 0.55805, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2006/epoch_19_valloss_0.2587_valacc_0.5581.hdf5\n",
      "5563/5563 [==============================] - 95s 17ms/step - loss: 0.2862 - accuracy: 0.5135 - val_loss: 0.2587 - val_accuracy: 0.5581\n",
      "Epoch 20/200\n",
      "5563/5563 [==============================] - ETA: 0s - loss: 0.2835 - accuracy: 0.5195\n",
      "Epoch 00020: val_accuracy did not improve from 0.55805\n",
      "5563/5563 [==============================] - 95s 17ms/step - loss: 0.2835 - accuracy: 0.5195 - val_loss: 0.2657 - val_accuracy: 0.5466\n",
      "Epoch 21/200\n",
      "5560/5563 [============================>.] - ETA: 0s - loss: 0.2803 - accuracy: 0.5268\n",
      "Epoch 00021: val_accuracy did not improve from 0.55805\n",
      "5563/5563 [==============================] - 95s 17ms/step - loss: 0.2803 - accuracy: 0.5269 - val_loss: 0.2614 - val_accuracy: 0.5569\n",
      "Epoch 22/200\n",
      "5560/5563 [============================>.] - ETA: 0s - loss: 0.2781 - accuracy: 0.5313\n",
      "Epoch 00022: val_accuracy did not improve from 0.55805\n",
      "5563/5563 [==============================] - 95s 17ms/step - loss: 0.2781 - accuracy: 0.5312 - val_loss: 0.2646 - val_accuracy: 0.5447\n",
      "Epoch 23/200\n",
      "5562/5563 [============================>.] - ETA: 0s - loss: 0.2759 - accuracy: 0.5343\n",
      "Epoch 00023: val_accuracy did not improve from 0.55805\n",
      "5563/5563 [==============================] - 95s 17ms/step - loss: 0.2759 - accuracy: 0.5343 - val_loss: 0.2688 - val_accuracy: 0.5385\n",
      "Epoch 24/200\n",
      "5561/5563 [============================>.] - ETA: 0s - loss: 0.2730 - accuracy: 0.5400\n",
      "Epoch 00024: val_accuracy did not improve from 0.55805\n",
      "5563/5563 [==============================] - 95s 17ms/step - loss: 0.2730 - accuracy: 0.5400 - val_loss: 0.2919 - val_accuracy: 0.4924\n",
      "Epoch 25/200\n",
      "5563/5563 [==============================] - ETA: 0s - loss: 0.2717 - accuracy: 0.5456\n",
      "Epoch 00025: val_accuracy did not improve from 0.55805\n",
      "5563/5563 [==============================] - 95s 17ms/step - loss: 0.2717 - accuracy: 0.5456 - val_loss: 0.2796 - val_accuracy: 0.5301\n",
      "Epoch 26/200\n",
      "5561/5563 [============================>.] - ETA: 0s - loss: 0.2688 - accuracy: 0.5499\n",
      "Epoch 00026: val_accuracy improved from 0.55805 to 0.58667, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2006/epoch_26_valloss_0.2484_valacc_0.5867.hdf5\n",
      "5563/5563 [==============================] - 95s 17ms/step - loss: 0.2688 - accuracy: 0.5500 - val_loss: 0.2484 - val_accuracy: 0.5867\n",
      "Epoch 27/200\n",
      "5561/5563 [============================>.] - ETA: 0s - loss: 0.2675 - accuracy: 0.5544\n",
      "Epoch 00027: val_accuracy did not improve from 0.58667\n",
      "5563/5563 [==============================] - 95s 17ms/step - loss: 0.2675 - accuracy: 0.5544 - val_loss: 0.2556 - val_accuracy: 0.5698\n",
      "Epoch 28/200\n",
      "5562/5563 [============================>.] - ETA: 0s - loss: 0.2655 - accuracy: 0.5589\n",
      "Epoch 00028: val_accuracy did not improve from 0.58667\n",
      "5563/5563 [==============================] - 95s 17ms/step - loss: 0.2655 - accuracy: 0.5589 - val_loss: 0.2481 - val_accuracy: 0.5851\n",
      "Epoch 29/200\n",
      "5563/5563 [==============================] - ETA: 0s - loss: 0.2645 - accuracy: 0.5590\n",
      "Epoch 00029: val_accuracy did not improve from 0.58667\n",
      "5563/5563 [==============================] - 95s 17ms/step - loss: 0.2645 - accuracy: 0.5590 - val_loss: 0.2561 - val_accuracy: 0.5694\n",
      "Epoch 30/200\n",
      "5560/5563 [============================>.] - ETA: 0s - loss: 0.2631 - accuracy: 0.5641\n",
      "Epoch 00030: val_accuracy improved from 0.58667 to 0.58900, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2006/epoch_30_valloss_0.2443_valacc_0.5890.hdf5\n",
      "5563/5563 [==============================] - 95s 17ms/step - loss: 0.2631 - accuracy: 0.5642 - val_loss: 0.2443 - val_accuracy: 0.5890\n",
      "Epoch 31/200\n",
      "5561/5563 [============================>.] - ETA: 0s - loss: 0.2608 - accuracy: 0.5680\n",
      "Epoch 00031: val_accuracy did not improve from 0.58900\n",
      "5563/5563 [==============================] - 95s 17ms/step - loss: 0.2608 - accuracy: 0.5680 - val_loss: 0.2546 - val_accuracy: 0.5804\n",
      "Epoch 32/200\n",
      "5561/5563 [============================>.] - ETA: 0s - loss: 0.2602 - accuracy: 0.5701\n",
      "Epoch 00032: val_accuracy did not improve from 0.58900\n",
      "5563/5563 [==============================] - 95s 17ms/step - loss: 0.2602 - accuracy: 0.5701 - val_loss: 0.2523 - val_accuracy: 0.5725\n",
      "Epoch 33/200\n",
      "5561/5563 [============================>.] - ETA: 0s - loss: 0.2583 - accuracy: 0.5735\n",
      "Epoch 00033: val_accuracy improved from 0.58900 to 0.60093, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2006/epoch_33_valloss_0.2434_valacc_0.6009.hdf5\n",
      "5563/5563 [==============================] - 95s 17ms/step - loss: 0.2583 - accuracy: 0.5736 - val_loss: 0.2434 - val_accuracy: 0.6009\n",
      "Epoch 34/200\n",
      "5563/5563 [==============================] - ETA: 0s - loss: 0.2567 - accuracy: 0.5757\n",
      "Epoch 00034: val_accuracy improved from 0.60093 to 0.60801, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2006/epoch_34_valloss_0.2352_valacc_0.6080.hdf5\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2567 - accuracy: 0.5757 - val_loss: 0.2352 - val_accuracy: 0.6080\n",
      "Epoch 35/200\n",
      "5562/5563 [============================>.] - ETA: 0s - loss: 0.2555 - accuracy: 0.5771\n",
      "Epoch 00035: val_accuracy did not improve from 0.60801\n",
      "5563/5563 [==============================] - 95s 17ms/step - loss: 0.2555 - accuracy: 0.5772 - val_loss: 0.2455 - val_accuracy: 0.5936\n",
      "Epoch 36/200\n",
      "5561/5563 [============================>.] - ETA: 0s - loss: 0.2545 - accuracy: 0.5811\n",
      "Epoch 00036: val_accuracy did not improve from 0.60801\n",
      "5563/5563 [==============================] - 95s 17ms/step - loss: 0.2545 - accuracy: 0.5811 - val_loss: 0.2743 - val_accuracy: 0.5430\n",
      "Epoch 37/200\n",
      "5561/5563 [============================>.] - ETA: 0s - loss: 0.2530 - accuracy: 0.5829\n",
      "Epoch 00037: val_accuracy did not improve from 0.60801\n",
      "5563/5563 [==============================] - 95s 17ms/step - loss: 0.2530 - accuracy: 0.5829 - val_loss: 0.2469 - val_accuracy: 0.5917\n",
      "Epoch 38/200\n",
      "5562/5563 [============================>.] - ETA: 0s - loss: 0.2518 - accuracy: 0.5851\n",
      "Epoch 00038: val_accuracy improved from 0.60801 to 0.61731, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2006/epoch_38_valloss_0.2354_valacc_0.6173.hdf5\n",
      "5563/5563 [==============================] - 95s 17ms/step - loss: 0.2518 - accuracy: 0.5851 - val_loss: 0.2354 - val_accuracy: 0.6173\n",
      "Epoch 39/200\n",
      "5562/5563 [============================>.] - ETA: 0s - loss: 0.2509 - accuracy: 0.5881\n",
      "Epoch 00039: val_accuracy did not improve from 0.61731\n",
      "5563/5563 [==============================] - 95s 17ms/step - loss: 0.2509 - accuracy: 0.5881 - val_loss: 0.2382 - val_accuracy: 0.6173\n",
      "Epoch 40/200\n",
      "5561/5563 [============================>.] - ETA: 0s - loss: 0.2503 - accuracy: 0.5892\n",
      "Epoch 00040: val_accuracy did not improve from 0.61731\n",
      "5563/5563 [==============================] - 95s 17ms/step - loss: 0.2503 - accuracy: 0.5891 - val_loss: 0.2373 - val_accuracy: 0.6142\n",
      "Epoch 41/200\n",
      "5562/5563 [============================>.] - ETA: 0s - loss: 0.2491 - accuracy: 0.5927\n",
      "Epoch 00041: val_accuracy did not improve from 0.61731\n",
      "5563/5563 [==============================] - 95s 17ms/step - loss: 0.2491 - accuracy: 0.5927 - val_loss: 0.2469 - val_accuracy: 0.5894\n",
      "Epoch 42/200\n",
      "5561/5563 [============================>.] - ETA: 0s - loss: 0.2479 - accuracy: 0.5949\n",
      "Epoch 00042: val_accuracy improved from 0.61731 to 0.62318, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2006/epoch_42_valloss_0.2325_valacc_0.6232.hdf5\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2479 - accuracy: 0.5949 - val_loss: 0.2325 - val_accuracy: 0.6232\n",
      "Epoch 43/200\n",
      "5563/5563 [==============================] - ETA: 0s - loss: 0.2471 - accuracy: 0.5954\n",
      "Epoch 00043: val_accuracy did not improve from 0.62318\n",
      "5563/5563 [==============================] - 95s 17ms/step - loss: 0.2471 - accuracy: 0.5954 - val_loss: 0.2487 - val_accuracy: 0.5912\n",
      "Epoch 44/200\n",
      "5560/5563 [============================>.] - ETA: 0s - loss: 0.2462 - accuracy: 0.5987\n",
      "Epoch 00044: val_accuracy did not improve from 0.62318\n",
      "5563/5563 [==============================] - 95s 17ms/step - loss: 0.2462 - accuracy: 0.5987 - val_loss: 0.2333 - val_accuracy: 0.6180\n",
      "Epoch 45/200\n",
      "5562/5563 [============================>.] - ETA: 0s - loss: 0.2447 - accuracy: 0.6019\n",
      "Epoch 00045: val_accuracy improved from 0.62318 to 0.64644, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2006/epoch_45_valloss_0.2232_valacc_0.6464.hdf5\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2447 - accuracy: 0.6019 - val_loss: 0.2232 - val_accuracy: 0.6464\n",
      "Epoch 46/200\n",
      "5562/5563 [============================>.] - ETA: 0s - loss: 0.2443 - accuracy: 0.6015\n",
      "Epoch 00046: val_accuracy did not improve from 0.64644\n",
      "5563/5563 [==============================] - 95s 17ms/step - loss: 0.2443 - accuracy: 0.6016 - val_loss: 0.2244 - val_accuracy: 0.6349\n",
      "Epoch 47/200\n",
      "5560/5563 [============================>.] - ETA: 0s - loss: 0.2436 - accuracy: 0.6040\n",
      "Epoch 00047: val_accuracy did not improve from 0.64644\n",
      "5563/5563 [==============================] - 95s 17ms/step - loss: 0.2436 - accuracy: 0.6039 - val_loss: 0.2429 - val_accuracy: 0.5991\n",
      "Epoch 48/200\n",
      "5560/5563 [============================>.] - ETA: 0s - loss: 0.2426 - accuracy: 0.6065\n",
      "Epoch 00048: val_accuracy did not improve from 0.64644\n",
      "5563/5563 [==============================] - 95s 17ms/step - loss: 0.2426 - accuracy: 0.6065 - val_loss: 0.2510 - val_accuracy: 0.5884\n",
      "Epoch 49/200\n",
      "5560/5563 [============================>.] - ETA: 0s - loss: 0.2418 - accuracy: 0.6092\n",
      "Epoch 00049: val_accuracy did not improve from 0.64644\n",
      "5563/5563 [==============================] - 95s 17ms/step - loss: 0.2418 - accuracy: 0.6093 - val_loss: 0.2263 - val_accuracy: 0.6330\n",
      "Epoch 50/200\n",
      "5562/5563 [============================>.] - ETA: 0s - loss: 0.2416 - accuracy: 0.6088\n",
      "Epoch 00050: val_accuracy did not improve from 0.64644\n",
      "5563/5563 [==============================] - 95s 17ms/step - loss: 0.2416 - accuracy: 0.6088 - val_loss: 0.2294 - val_accuracy: 0.6283\n",
      "Epoch 51/200\n",
      "5561/5563 [============================>.] - ETA: 0s - loss: 0.2406 - accuracy: 0.6127\n",
      "Epoch 00051: val_accuracy improved from 0.64644 to 0.64806, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2006/epoch_51_valloss_0.2172_valacc_0.6481.hdf5\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2406 - accuracy: 0.6127 - val_loss: 0.2172 - val_accuracy: 0.6481\n",
      "Epoch 52/200\n",
      "5561/5563 [============================>.] - ETA: 0s - loss: 0.2397 - accuracy: 0.6134\n",
      "Epoch 00052: val_accuracy did not improve from 0.64806\n",
      "5563/5563 [==============================] - 95s 17ms/step - loss: 0.2397 - accuracy: 0.6134 - val_loss: 0.2699 - val_accuracy: 0.5653\n",
      "Epoch 53/200\n",
      "5560/5563 [============================>.] - ETA: 0s - loss: 0.2384 - accuracy: 0.6150\n",
      "Epoch 00053: val_accuracy did not improve from 0.64806\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2383 - accuracy: 0.6151 - val_loss: 0.2347 - val_accuracy: 0.6221\n",
      "Epoch 54/200\n",
      "5563/5563 [==============================] - ETA: 0s - loss: 0.2386 - accuracy: 0.6165\n",
      "Epoch 00054: val_accuracy did not improve from 0.64806\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2386 - accuracy: 0.6165 - val_loss: 0.2423 - val_accuracy: 0.6071\n",
      "Epoch 55/200\n",
      "5562/5563 [============================>.] - ETA: 0s - loss: 0.2365 - accuracy: 0.6209\n",
      "Epoch 00055: val_accuracy improved from 0.64806 to 0.66404, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2006/epoch_55_valloss_0.2128_valacc_0.6640.hdf5\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2366 - accuracy: 0.6208 - val_loss: 0.2128 - val_accuracy: 0.6640\n",
      "Epoch 56/200\n",
      "5561/5563 [============================>.] - ETA: 0s - loss: 0.2366 - accuracy: 0.6227\n",
      "Epoch 00056: val_accuracy did not improve from 0.66404\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2366 - accuracy: 0.6227 - val_loss: 0.2232 - val_accuracy: 0.6366\n",
      "Epoch 57/200\n",
      "5562/5563 [============================>.] - ETA: 0s - loss: 0.2364 - accuracy: 0.6206\n",
      "Epoch 00057: val_accuracy did not improve from 0.66404\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2364 - accuracy: 0.6206 - val_loss: 0.2255 - val_accuracy: 0.6385\n",
      "Epoch 58/200\n",
      "5563/5563 [==============================] - ETA: 0s - loss: 0.2352 - accuracy: 0.6235\n",
      "Epoch 00058: val_accuracy did not improve from 0.66404\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2352 - accuracy: 0.6235 - val_loss: 0.2377 - val_accuracy: 0.6196\n",
      "Epoch 59/200\n",
      "5561/5563 [============================>.] - ETA: 0s - loss: 0.2345 - accuracy: 0.6251\n",
      "Epoch 00059: val_accuracy did not improve from 0.66404\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2346 - accuracy: 0.6251 - val_loss: 0.2218 - val_accuracy: 0.6410\n",
      "Epoch 60/200\n",
      "5562/5563 [============================>.] - ETA: 0s - loss: 0.2342 - accuracy: 0.6245\n",
      "Epoch 00060: val_accuracy did not improve from 0.66404\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2342 - accuracy: 0.6246 - val_loss: 0.2174 - val_accuracy: 0.6583\n",
      "Epoch 61/200\n",
      "5562/5563 [============================>.] - ETA: 0s - loss: 0.2342 - accuracy: 0.6279\n",
      "Epoch 00061: val_accuracy did not improve from 0.66404\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2342 - accuracy: 0.6279 - val_loss: 0.2371 - val_accuracy: 0.6183\n",
      "Epoch 62/200\n",
      "5563/5563 [==============================] - ETA: 0s - loss: 0.2327 - accuracy: 0.6297\n",
      "Epoch 00062: val_accuracy improved from 0.66404 to 0.67223, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2006/epoch_62_valloss_0.2098_valacc_0.6722.hdf5\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2327 - accuracy: 0.6297 - val_loss: 0.2098 - val_accuracy: 0.6722\n",
      "Epoch 63/200\n",
      "5560/5563 [============================>.] - ETA: 0s - loss: 0.2319 - accuracy: 0.6314\n",
      "Epoch 00063: val_accuracy did not improve from 0.67223\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2319 - accuracy: 0.6314 - val_loss: 0.2438 - val_accuracy: 0.6080\n",
      "Epoch 64/200\n",
      "5561/5563 [============================>.] - ETA: 0s - loss: 0.2307 - accuracy: 0.6331\n",
      "Epoch 00064: val_accuracy did not improve from 0.67223\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2308 - accuracy: 0.6331 - val_loss: 0.2369 - val_accuracy: 0.6251\n",
      "Epoch 65/200\n",
      "5563/5563 [==============================] - ETA: 0s - loss: 0.2305 - accuracy: 0.6332\n",
      "Epoch 00065: val_accuracy did not improve from 0.67223\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2305 - accuracy: 0.6332 - val_loss: 0.2218 - val_accuracy: 0.6502\n",
      "Epoch 66/200\n",
      "5561/5563 [============================>.] - ETA: 0s - loss: 0.2301 - accuracy: 0.6341\n",
      "Epoch 00066: val_accuracy did not improve from 0.67223\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2301 - accuracy: 0.6340 - val_loss: 0.2342 - val_accuracy: 0.6201\n",
      "Epoch 67/200\n",
      "5561/5563 [============================>.] - ETA: 0s - loss: 0.2305 - accuracy: 0.6347\n",
      "Epoch 00067: val_accuracy did not improve from 0.67223\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2306 - accuracy: 0.6347 - val_loss: 0.2363 - val_accuracy: 0.6190\n",
      "Epoch 68/200\n",
      "5563/5563 [==============================] - ETA: 0s - loss: 0.2300 - accuracy: 0.6341\n",
      "Epoch 00068: val_accuracy improved from 0.67223 to 0.67536, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2006/epoch_68_valloss_0.2093_valacc_0.6754.hdf5\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2300 - accuracy: 0.6341 - val_loss: 0.2093 - val_accuracy: 0.6754\n",
      "Epoch 69/200\n",
      "5562/5563 [============================>.] - ETA: 0s - loss: 0.2293 - accuracy: 0.6375\n",
      "Epoch 00069: val_accuracy did not improve from 0.67536\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2293 - accuracy: 0.6375 - val_loss: 0.2301 - val_accuracy: 0.6378\n",
      "Epoch 70/200\n",
      "5562/5563 [============================>.] - ETA: 0s - loss: 0.2286 - accuracy: 0.6387\n",
      "Epoch 00070: val_accuracy did not improve from 0.67536\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2286 - accuracy: 0.6387 - val_loss: 0.2365 - val_accuracy: 0.6199\n",
      "Epoch 71/200\n",
      "5563/5563 [==============================] - ETA: 0s - loss: 0.2277 - accuracy: 0.6412\n",
      "Epoch 00071: val_accuracy did not improve from 0.67536\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2277 - accuracy: 0.6412 - val_loss: 0.2261 - val_accuracy: 0.6422\n",
      "Epoch 72/200\n",
      "5561/5563 [============================>.] - ETA: 0s - loss: 0.2277 - accuracy: 0.6414\n",
      "Epoch 00072: val_accuracy did not improve from 0.67536\n",
      "5563/5563 [==============================] - 97s 17ms/step - loss: 0.2277 - accuracy: 0.6414 - val_loss: 0.2286 - val_accuracy: 0.6358\n",
      "Epoch 73/200\n",
      "5563/5563 [==============================] - ETA: 0s - loss: 0.2272 - accuracy: 0.6419\n",
      "Epoch 00073: val_accuracy did not improve from 0.67536\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2272 - accuracy: 0.6419 - val_loss: 0.2182 - val_accuracy: 0.6568\n",
      "Epoch 74/200\n",
      "5561/5563 [============================>.] - ETA: 0s - loss: 0.2264 - accuracy: 0.6455\n",
      "Epoch 00074: val_accuracy did not improve from 0.67536\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2264 - accuracy: 0.6455 - val_loss: 0.2260 - val_accuracy: 0.6490\n",
      "Epoch 75/200\n",
      "5562/5563 [============================>.] - ETA: 0s - loss: 0.2256 - accuracy: 0.6454\n",
      "Epoch 00075: val_accuracy did not improve from 0.67536\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2257 - accuracy: 0.6454 - val_loss: 0.2537 - val_accuracy: 0.6004\n",
      "Epoch 76/200\n",
      "5562/5563 [============================>.] - ETA: 0s - loss: 0.2259 - accuracy: 0.6458\n",
      "Epoch 00076: val_accuracy did not improve from 0.67536\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2259 - accuracy: 0.6458 - val_loss: 0.2269 - val_accuracy: 0.6441\n",
      "Epoch 77/200\n",
      "5563/5563 [==============================] - ETA: 0s - loss: 0.2250 - accuracy: 0.6453\n",
      "Epoch 00077: val_accuracy did not improve from 0.67536\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2250 - accuracy: 0.6453 - val_loss: 0.2335 - val_accuracy: 0.6278\n",
      "Epoch 78/200\n",
      "5560/5563 [============================>.] - ETA: 0s - loss: 0.2241 - accuracy: 0.6479\n",
      "Epoch 00078: val_accuracy did not improve from 0.67536\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2241 - accuracy: 0.6479 - val_loss: 0.2375 - val_accuracy: 0.6221\n",
      "Epoch 79/200\n",
      "5562/5563 [============================>.] - ETA: 0s - loss: 0.2241 - accuracy: 0.6491\n",
      "Epoch 00079: val_accuracy did not improve from 0.67536\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2241 - accuracy: 0.6491 - val_loss: 0.2274 - val_accuracy: 0.6387\n",
      "Epoch 80/200\n",
      "5562/5563 [============================>.] - ETA: 0s - loss: 0.2234 - accuracy: 0.6504\n",
      "Epoch 00080: val_accuracy improved from 0.67536 to 0.68558, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2006/epoch_80_valloss_0.2048_valacc_0.6856.hdf5\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2234 - accuracy: 0.6503 - val_loss: 0.2048 - val_accuracy: 0.6856\n",
      "Epoch 81/200\n",
      "5562/5563 [============================>.] - ETA: 0s - loss: 0.2228 - accuracy: 0.6511\n",
      "Epoch 00081: val_accuracy did not improve from 0.68558\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2228 - accuracy: 0.6511 - val_loss: 0.2239 - val_accuracy: 0.6548\n",
      "Epoch 82/200\n",
      "5562/5563 [============================>.] - ETA: 0s - loss: 0.2228 - accuracy: 0.6527\n",
      "Epoch 00082: val_accuracy did not improve from 0.68558\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2228 - accuracy: 0.6527 - val_loss: 0.2250 - val_accuracy: 0.6474\n",
      "Epoch 83/200\n",
      "5563/5563 [==============================] - ETA: 0s - loss: 0.2223 - accuracy: 0.6526\n",
      "Epoch 00083: val_accuracy did not improve from 0.68558\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2223 - accuracy: 0.6526 - val_loss: 0.2396 - val_accuracy: 0.6156\n",
      "Epoch 84/200\n",
      "5563/5563 [==============================] - ETA: 0s - loss: 0.2224 - accuracy: 0.6541\n",
      "Epoch 00084: val_accuracy did not improve from 0.68558\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2224 - accuracy: 0.6541 - val_loss: 0.2242 - val_accuracy: 0.6500\n",
      "Epoch 85/200\n",
      "5563/5563 [==============================] - ETA: 0s - loss: 0.2216 - accuracy: 0.6535\n",
      "Epoch 00085: val_accuracy did not improve from 0.68558\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2216 - accuracy: 0.6535 - val_loss: 0.2371 - val_accuracy: 0.6258\n",
      "Epoch 86/200\n",
      "5561/5563 [============================>.] - ETA: 0s - loss: 0.2213 - accuracy: 0.6569\n",
      "Epoch 00086: val_accuracy did not improve from 0.68558\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2213 - accuracy: 0.6569 - val_loss: 0.2720 - val_accuracy: 0.5664\n",
      "Epoch 87/200\n",
      "5562/5563 [============================>.] - ETA: 0s - loss: 0.2207 - accuracy: 0.6565\n",
      "Epoch 00087: val_accuracy did not improve from 0.68558\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2207 - accuracy: 0.6566 - val_loss: 0.2260 - val_accuracy: 0.6456\n",
      "Epoch 88/200\n",
      "5562/5563 [============================>.] - ETA: 0s - loss: 0.2216 - accuracy: 0.6547\n",
      "Epoch 00088: val_accuracy did not improve from 0.68558\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2216 - accuracy: 0.6547 - val_loss: 0.2165 - val_accuracy: 0.6558\n",
      "Epoch 89/200\n",
      "5561/5563 [============================>.] - ETA: 0s - loss: 0.2203 - accuracy: 0.6578\n",
      "Epoch 00089: val_accuracy did not improve from 0.68558\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2203 - accuracy: 0.6578 - val_loss: 0.2142 - val_accuracy: 0.6671\n",
      "Epoch 90/200\n",
      "5562/5563 [============================>.] - ETA: 0s - loss: 0.2198 - accuracy: 0.6578\n",
      "Epoch 00090: val_accuracy did not improve from 0.68558\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2198 - accuracy: 0.6578 - val_loss: 0.2344 - val_accuracy: 0.6360\n",
      "Epoch 91/200\n",
      "5561/5563 [============================>.] - ETA: 0s - loss: 0.2189 - accuracy: 0.6620\n",
      "Epoch 00091: val_accuracy did not improve from 0.68558\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2189 - accuracy: 0.6620 - val_loss: 0.2275 - val_accuracy: 0.6442\n",
      "Epoch 92/200\n",
      "5562/5563 [============================>.] - ETA: 0s - loss: 0.2185 - accuracy: 0.6623\n",
      "Epoch 00092: val_accuracy did not improve from 0.68558\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2185 - accuracy: 0.6623 - val_loss: 0.2321 - val_accuracy: 0.6310\n",
      "Epoch 93/200\n",
      "5562/5563 [============================>.] - ETA: 0s - loss: 0.2184 - accuracy: 0.6608\n",
      "Epoch 00093: val_accuracy did not improve from 0.68558\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2184 - accuracy: 0.6608 - val_loss: 0.2315 - val_accuracy: 0.6320\n",
      "Epoch 94/200\n",
      "5560/5563 [============================>.] - ETA: 0s - loss: 0.2177 - accuracy: 0.6624\n",
      "Epoch 00094: val_accuracy did not improve from 0.68558\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2177 - accuracy: 0.6624 - val_loss: 0.2127 - val_accuracy: 0.6750\n",
      "Epoch 95/200\n",
      "5561/5563 [============================>.] - ETA: 0s - loss: 0.2176 - accuracy: 0.6649\n",
      "Epoch 00095: val_accuracy did not improve from 0.68558\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2176 - accuracy: 0.6648 - val_loss: 0.2081 - val_accuracy: 0.6849\n",
      "Epoch 96/200\n",
      "5563/5563 [==============================] - ETA: 0s - loss: 0.2180 - accuracy: 0.6641\n",
      "Epoch 00096: val_accuracy did not improve from 0.68558\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2180 - accuracy: 0.6641 - val_loss: 0.2573 - val_accuracy: 0.5899\n",
      "Epoch 97/200\n",
      "5562/5563 [============================>.] - ETA: 0s - loss: 0.2172 - accuracy: 0.6643\n",
      "Epoch 00097: val_accuracy did not improve from 0.68558\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2172 - accuracy: 0.6643 - val_loss: 0.2169 - val_accuracy: 0.6644\n",
      "Epoch 98/200\n",
      "5561/5563 [============================>.] - ETA: 0s - loss: 0.2163 - accuracy: 0.6671\n",
      "Epoch 00098: val_accuracy did not improve from 0.68558\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2163 - accuracy: 0.6671 - val_loss: 0.2497 - val_accuracy: 0.6046\n",
      "Epoch 99/200\n",
      "5562/5563 [============================>.] - ETA: 0s - loss: 0.2167 - accuracy: 0.6661\n",
      "Epoch 00099: val_accuracy did not improve from 0.68558\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2167 - accuracy: 0.6662 - val_loss: 0.2201 - val_accuracy: 0.6634\n",
      "Epoch 100/200\n",
      "5562/5563 [============================>.] - ETA: 0s - loss: 0.2157 - accuracy: 0.6680\n",
      "Epoch 00100: val_accuracy did not improve from 0.68558\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2157 - accuracy: 0.6680 - val_loss: 0.2635 - val_accuracy: 0.5882\n",
      "Epoch 101/200\n",
      "5563/5563 [==============================] - ETA: 0s - loss: 0.2154 - accuracy: 0.6688\n",
      "Epoch 00101: val_accuracy improved from 0.68558 to 0.69013, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2006/epoch_101_valloss_0.2058_valacc_0.6901.hdf5\n",
      "5563/5563 [==============================] - 97s 17ms/step - loss: 0.2154 - accuracy: 0.6688 - val_loss: 0.2058 - val_accuracy: 0.6901\n",
      "Epoch 102/200\n",
      "5561/5563 [============================>.] - ETA: 0s - loss: 0.2148 - accuracy: 0.6701\n",
      "Epoch 00102: val_accuracy did not improve from 0.69013\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2148 - accuracy: 0.6701 - val_loss: 0.2341 - val_accuracy: 0.6324\n",
      "Epoch 103/200\n",
      "5560/5563 [============================>.] - ETA: 0s - loss: 0.2139 - accuracy: 0.6729\n",
      "Epoch 00103: val_accuracy did not improve from 0.69013\n",
      "5563/5563 [==============================] - 97s 17ms/step - loss: 0.2140 - accuracy: 0.6729 - val_loss: 0.2271 - val_accuracy: 0.6479\n",
      "Epoch 104/200\n",
      "5561/5563 [============================>.] - ETA: 0s - loss: 0.2133 - accuracy: 0.6725\n",
      "Epoch 00104: val_accuracy did not improve from 0.69013\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2133 - accuracy: 0.6725 - val_loss: 0.2356 - val_accuracy: 0.6395\n",
      "Epoch 105/200\n",
      "5563/5563 [==============================] - ETA: 0s - loss: 0.2142 - accuracy: 0.6728\n",
      "Epoch 00105: val_accuracy did not improve from 0.69013\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2142 - accuracy: 0.6728 - val_loss: 0.2170 - val_accuracy: 0.6596\n",
      "Epoch 106/200\n",
      "5562/5563 [============================>.] - ETA: 0s - loss: 0.2141 - accuracy: 0.6715\n",
      "Epoch 00106: val_accuracy did not improve from 0.69013\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2141 - accuracy: 0.6715 - val_loss: 0.2304 - val_accuracy: 0.6403\n",
      "Epoch 107/200\n",
      "5563/5563 [==============================] - ETA: 0s - loss: 0.2131 - accuracy: 0.6732\n",
      "Epoch 00107: val_accuracy did not improve from 0.69013\n",
      "5563/5563 [==============================] - 97s 17ms/step - loss: 0.2131 - accuracy: 0.6732 - val_loss: 0.2419 - val_accuracy: 0.6233\n",
      "Epoch 108/200\n",
      "5562/5563 [============================>.] - ETA: 0s - loss: 0.2124 - accuracy: 0.6761\n",
      "Epoch 00108: val_accuracy did not improve from 0.69013\n",
      "5563/5563 [==============================] - 97s 17ms/step - loss: 0.2124 - accuracy: 0.6762 - val_loss: 0.2181 - val_accuracy: 0.6612\n",
      "Epoch 109/200\n",
      "5560/5563 [============================>.] - ETA: 0s - loss: 0.2122 - accuracy: 0.6754\n",
      "Epoch 00109: val_accuracy did not improve from 0.69013\n",
      "5563/5563 [==============================] - 97s 17ms/step - loss: 0.2122 - accuracy: 0.6754 - val_loss: 0.2309 - val_accuracy: 0.6427\n",
      "Epoch 110/200\n",
      "5561/5563 [============================>.] - ETA: 0s - loss: 0.2115 - accuracy: 0.6794\n",
      "Epoch 00110: val_accuracy did not improve from 0.69013\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2115 - accuracy: 0.6794 - val_loss: 0.2431 - val_accuracy: 0.6272\n",
      "Epoch 111/200\n",
      "5562/5563 [============================>.] - ETA: 0s - loss: 0.2118 - accuracy: 0.6759\n",
      "Epoch 00111: val_accuracy did not improve from 0.69013\n",
      "5563/5563 [==============================] - 97s 17ms/step - loss: 0.2118 - accuracy: 0.6759 - val_loss: 0.2457 - val_accuracy: 0.6279\n",
      "Epoch 112/200\n",
      "5563/5563 [==============================] - ETA: 0s - loss: 0.2110 - accuracy: 0.6795\n",
      "Epoch 00112: val_accuracy did not improve from 0.69013\n",
      "5563/5563 [==============================] - 98s 18ms/step - loss: 0.2110 - accuracy: 0.6795 - val_loss: 0.2510 - val_accuracy: 0.6100\n",
      "Epoch 113/200\n",
      "5562/5563 [============================>.] - ETA: 0s - loss: 0.2102 - accuracy: 0.6802\n",
      "Epoch 00113: val_accuracy did not improve from 0.69013\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2102 - accuracy: 0.6801 - val_loss: 0.2065 - val_accuracy: 0.6858\n",
      "Epoch 114/200\n",
      "5562/5563 [============================>.] - ETA: 0s - loss: 0.2111 - accuracy: 0.6770\n",
      "Epoch 00114: val_accuracy did not improve from 0.69013\n",
      "5563/5563 [==============================] - 97s 17ms/step - loss: 0.2111 - accuracy: 0.6770 - val_loss: 0.2393 - val_accuracy: 0.6315\n",
      "Epoch 115/200\n",
      "5562/5563 [============================>.] - ETA: 0s - loss: 0.2102 - accuracy: 0.6818\n",
      "Epoch 00115: val_accuracy did not improve from 0.69013\n",
      "5563/5563 [==============================] - 97s 17ms/step - loss: 0.2102 - accuracy: 0.6817 - val_loss: 0.2346 - val_accuracy: 0.6404\n",
      "Epoch 116/200\n",
      "5560/5563 [============================>.] - ETA: 0s - loss: 0.2105 - accuracy: 0.6802\n",
      "Epoch 00116: val_accuracy did not improve from 0.69013\n",
      "5563/5563 [==============================] - 97s 17ms/step - loss: 0.2105 - accuracy: 0.6802 - val_loss: 0.2483 - val_accuracy: 0.6175\n",
      "Epoch 117/200\n",
      "5563/5563 [==============================] - ETA: 0s - loss: 0.2107 - accuracy: 0.6776\n",
      "Epoch 00117: val_accuracy did not improve from 0.69013\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2107 - accuracy: 0.6776 - val_loss: 0.2334 - val_accuracy: 0.6547\n",
      "Epoch 118/200\n",
      "5563/5563 [==============================] - ETA: 0s - loss: 0.2095 - accuracy: 0.6815\n",
      "Epoch 00118: val_accuracy did not improve from 0.69013\n",
      "5563/5563 [==============================] - 97s 17ms/step - loss: 0.2095 - accuracy: 0.6815 - val_loss: 0.2146 - val_accuracy: 0.6740\n",
      "Epoch 119/200\n",
      "5563/5563 [==============================] - ETA: 0s - loss: 0.2092 - accuracy: 0.6837\n",
      "Epoch 00119: val_accuracy did not improve from 0.69013\n",
      "5563/5563 [==============================] - 97s 17ms/step - loss: 0.2092 - accuracy: 0.6837 - val_loss: 0.2123 - val_accuracy: 0.6809\n",
      "Epoch 120/200\n",
      "5563/5563 [==============================] - ETA: 0s - loss: 0.2085 - accuracy: 0.6854\n",
      "Epoch 00120: val_accuracy did not improve from 0.69013\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2085 - accuracy: 0.6854 - val_loss: 0.2253 - val_accuracy: 0.6493\n",
      "Epoch 121/200\n",
      "5561/5563 [============================>.] - ETA: 0s - loss: 0.2089 - accuracy: 0.6831\n",
      "Epoch 00121: val_accuracy did not improve from 0.69013\n",
      "5563/5563 [==============================] - 96s 17ms/step - loss: 0.2089 - accuracy: 0.6831 - val_loss: 0.2467 - val_accuracy: 0.6188\n",
      "Epoch 122/200\n",
      "5563/5563 [==============================] - ETA: 0s - loss: 0.2078 - accuracy: 0.6873\n",
      "Epoch 00122: val_accuracy did not improve from 0.69013\n",
      "5563/5563 [==============================] - 97s 17ms/step - loss: 0.2078 - accuracy: 0.6873 - val_loss: 0.2151 - val_accuracy: 0.6763\n",
      "Epoch 123/200\n",
      "5562/5563 [============================>.] - ETA: 0s - loss: 0.2074 - accuracy: 0.6854\n",
      "Epoch 00123: val_accuracy did not improve from 0.69013\n",
      "5563/5563 [==============================] - 97s 17ms/step - loss: 0.2074 - accuracy: 0.6854 - val_loss: 0.2292 - val_accuracy: 0.6456\n",
      "Epoch 124/200\n",
      "5563/5563 [==============================] - ETA: 0s - loss: 0.2077 - accuracy: 0.6864\n",
      "Epoch 00124: val_accuracy did not improve from 0.69013\n",
      "5563/5563 [==============================] - 97s 17ms/step - loss: 0.2077 - accuracy: 0.6864 - val_loss: 0.2180 - val_accuracy: 0.6670\n",
      "Epoch 125/200\n",
      "5562/5563 [============================>.] - ETA: 0s - loss: 0.2072 - accuracy: 0.6856\n",
      "Epoch 00125: val_accuracy did not improve from 0.69013\n",
      "5563/5563 [==============================] - 97s 17ms/step - loss: 0.2072 - accuracy: 0.6856 - val_loss: 0.2298 - val_accuracy: 0.6537\n",
      "Epoch 126/200\n",
      "5560/5563 [============================>.] - ETA: 0s - loss: 0.2066 - accuracy: 0.6873\n",
      "Epoch 00126: val_accuracy did not improve from 0.69013\n",
      "5563/5563 [==============================] - 97s 17ms/step - loss: 0.2066 - accuracy: 0.6873 - val_loss: 0.2271 - val_accuracy: 0.6570\n",
      "Epoch 127/200\n",
      "5563/5563 [==============================] - ETA: 0s - loss: 0.2065 - accuracy: 0.6893\n",
      "Epoch 00127: val_accuracy did not improve from 0.69013\n",
      "5563/5563 [==============================] - 97s 17ms/step - loss: 0.2065 - accuracy: 0.6893 - val_loss: 0.2216 - val_accuracy: 0.6650\n",
      "Epoch 128/200\n",
      "5562/5563 [============================>.] - ETA: 0s - loss: 0.2061 - accuracy: 0.6904\n",
      "Epoch 00128: val_accuracy did not improve from 0.69013\n",
      "5563/5563 [==============================] - 97s 17ms/step - loss: 0.2061 - accuracy: 0.6904 - val_loss: 0.2417 - val_accuracy: 0.6290\n",
      "Epoch 129/200\n",
      "5561/5563 [============================>.] - ETA: 0s - loss: 0.2054 - accuracy: 0.6906\n",
      "Epoch 00129: val_accuracy did not improve from 0.69013\n",
      "5563/5563 [==============================] - 97s 17ms/step - loss: 0.2054 - accuracy: 0.6906 - val_loss: 0.2447 - val_accuracy: 0.6183\n",
      "Epoch 130/200\n",
      "5562/5563 [============================>.] - ETA: 0s - loss: 0.2060 - accuracy: 0.6893\n",
      "Epoch 00130: val_accuracy did not improve from 0.69013\n",
      "5563/5563 [==============================] - 97s 17ms/step - loss: 0.2060 - accuracy: 0.6892 - val_loss: 0.2558 - val_accuracy: 0.6066\n",
      "Epoch 131/200\n",
      "5563/5563 [==============================] - ETA: 0s - loss: 0.2057 - accuracy: 0.6909\n",
      "Epoch 00131: val_accuracy did not improve from 0.69013\n",
      "5563/5563 [==============================] - 97s 17ms/step - loss: 0.2057 - accuracy: 0.6909 - val_loss: 0.2277 - val_accuracy: 0.6593\n",
      "Epoch 132/200\n",
      "5562/5563 [============================>.] - ETA: 0s - loss: 0.2061 - accuracy: 0.6895\n",
      "Epoch 00132: val_accuracy did not improve from 0.69013\n",
      "5563/5563 [==============================] - 97s 17ms/step - loss: 0.2061 - accuracy: 0.6896 - val_loss: 0.2293 - val_accuracy: 0.6489\n",
      "Epoch 133/200\n",
      "5563/5563 [==============================] - ETA: 0s - loss: 0.2046 - accuracy: 0.6923\n",
      "Epoch 00133: val_accuracy did not improve from 0.69013\n",
      "5563/5563 [==============================] - 97s 17ms/step - loss: 0.2046 - accuracy: 0.6923 - val_loss: 0.2402 - val_accuracy: 0.6315\n",
      "Epoch 134/200\n",
      "5563/5563 [==============================] - ETA: 0s - loss: 0.2049 - accuracy: 0.6915\n",
      "Epoch 00134: val_accuracy did not improve from 0.69013\n",
      "5563/5563 [==============================] - 97s 17ms/step - loss: 0.2049 - accuracy: 0.6915 - val_loss: 0.2397 - val_accuracy: 0.6357\n",
      "Epoch 135/200\n",
      "5561/5563 [============================>.] - ETA: 0s - loss: 0.2052 - accuracy: 0.6928\n",
      "Epoch 00135: val_accuracy did not improve from 0.69013\n",
      "5563/5563 [==============================] - 97s 17ms/step - loss: 0.2052 - accuracy: 0.6928 - val_loss: 0.2224 - val_accuracy: 0.6603\n",
      "Epoch 136/200\n",
      "5561/5563 [============================>.] - ETA: 0s - loss: 0.2049 - accuracy: 0.6919\n",
      "Epoch 00136: val_accuracy did not improve from 0.69013\n",
      "5563/5563 [==============================] - 97s 17ms/step - loss: 0.2049 - accuracy: 0.6919 - val_loss: 0.2225 - val_accuracy: 0.6553\n",
      "Epoch 137/200\n",
      "5563/5563 [==============================] - ETA: 0s - loss: 0.2043 - accuracy: 0.6932\n",
      "Epoch 00137: val_accuracy did not improve from 0.69013\n",
      "5563/5563 [==============================] - 97s 17ms/step - loss: 0.2043 - accuracy: 0.6932 - val_loss: 0.2613 - val_accuracy: 0.5936\n",
      "Epoch 138/200\n",
      "5561/5563 [============================>.] - ETA: 0s - loss: 0.2032 - accuracy: 0.6972\n",
      "Epoch 00138: val_accuracy did not improve from 0.69013\n",
      "5563/5563 [==============================] - 97s 17ms/step - loss: 0.2032 - accuracy: 0.6971 - val_loss: 0.2416 - val_accuracy: 0.6411\n",
      "Epoch 139/200\n",
      "5561/5563 [============================>.] - ETA: 0s - loss: 0.2050 - accuracy: 0.6933\n",
      "Epoch 00139: val_accuracy did not improve from 0.69013\n",
      "5563/5563 [==============================] - 97s 17ms/step - loss: 0.2050 - accuracy: 0.6933 - val_loss: 0.2245 - val_accuracy: 0.6574\n",
      "Epoch 140/200\n",
      "5560/5563 [============================>.] - ETA: 0s - loss: 0.2035 - accuracy: 0.6961\n",
      "Epoch 00140: val_accuracy did not improve from 0.69013\n",
      "5563/5563 [==============================] - 97s 17ms/step - loss: 0.2035 - accuracy: 0.6961 - val_loss: 0.2516 - val_accuracy: 0.6058\n",
      "Epoch 141/200\n",
      "5563/5563 [==============================] - ETA: 0s - loss: 0.2037 - accuracy: 0.6954\n",
      "Epoch 00141: val_accuracy did not improve from 0.69013\n",
      "5563/5563 [==============================] - 97s 17ms/step - loss: 0.2037 - accuracy: 0.6954 - val_loss: 0.2265 - val_accuracy: 0.6617\n",
      "Epoch 00141: early stopping\n"
     ]
    }
   ],
   "source": [
    "# model = model_cnn14_attention_multi(dim_time, dim_freq, num_species, model_type='feature_level_attention', conv_dim=conv_dim, pool_size=pool_size, pool_stride=pool_stride, hidden_units=hidden_units, l2_regu=l2_regu, drop_rate=drop_rate)\n",
    "model = model_cnn14_spp(dim_time, dim_freq, num_species, conv_dim=conv_dim, pool_size=pool_size, pool_stride=pool_stride, hidden_units=hidden_units, l2_regu=l2_regu, drop_rate=drop_rate)\n",
    "# loss = CategoricalCrossentropy()\n",
    "loss = binary_crossentropy\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate_fn), loss=loss, metrics=['accuracy'])\n",
    "\n",
    "# With classes\n",
    "# history = model.fit(fea_train, to_categorical(label_train), class_weight=class_weights, validation_split=0.3, batch_size=batch_size, epochs=num_epoch, callbacks=[EarlyStopping(patience=num_patience), ModelCheckpoint(filepath=os.path.join(fit_result_path, '{epoch:02d}-{val_loss:.4f}.hdf5'), verbose=1, monitor=\"val_loss\", save_best_only=True)])\n",
    "# history = model.fit(train_generator, validation_data=validate_generator, class_weight=class_weights, epochs=num_epoch, callbacks=[EarlyStopping(patience=num_patience, monitor='val_loss', mode='min', verbose=1), TensorBoard(log_dir=fit_result_path1), ModelCheckpoint(filepath=os.path.join(fit_result_path1, '{epoch:02d}-{val_loss:.4f}.hdf5'), verbose=1, monitor=\"val_loss\", save_best_only=True)])\n",
    "# history = model.fit(train_generator, validation_data=validate_generator, class_weight=class_weights, epochs=num_epoch, callbacks=[EarlyStopping(patience=num_patience, monitor='val_loss', mode='min', verbose=1), TensorBoard(log_dir=fit_result_path2), ModelCheckpoint(filepath=os.path.join(fit_result_path2, 'epoch_{epoch:02d}_valloss_{val_loss:.4f}_valacc_{val_accuracy:.4f}.hdf5' ), verbose=1, monitor=\"val_accuracy\", save_best_only=True)])\n",
    "history = model.fit(train_generator, validation_data=validate_generator, class_weight=class_weights, epochs=num_epoch, callbacks=[EarlyStopping(patience=num_patience, monitor='val_accuracy', mode='max', verbose=1), TensorBoard(log_dir=fit_result_path2), ModelCheckpoint(filepath=os.path.join(fit_result_path2, 'epoch_{epoch:02d}_valloss_{val_loss:.4f}_valacc_{val_accuracy:.4f}.hdf5' ), verbose=1, monitor=\"val_accuracy\", save_best_only=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model:0.6901\n",
      "/home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/STAR2006/epoch_101_valloss_0.2058_valacc_0.6901.hdf5\n"
     ]
    }
   ],
   "source": [
    "# fit_result_path1 = '/home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210210_224527'\n",
    "the_best_model, _ = find_best_model(fit_result_path2, purge=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 100, 128, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 100, 128, 16)      160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 100, 128, 16)      64        \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 100, 128, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 100, 128, 16)      2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 100, 128, 16)      64        \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 100, 128, 16)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 50, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 50, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 50, 64, 32)        4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 50, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 50, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 50, 64, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 50, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 50, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 25, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 25, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 25, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 25, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 25, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 25, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 25, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 25, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 13, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 13, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 13, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 13, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 13, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 13, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 13, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 13, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 7, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 7, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 7, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 7, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 7, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 7, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 7, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 7, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "spatial_pyramid_pooling2d_2  (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               1376512   \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 8)                 2056      \n",
      "=================================================================\n",
      "Total params: 2,695,672\n",
      "Trainable params: 2,692,152\n",
      "Non-trainable params: 3,520\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_model(the_best_model)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pred = model.predict(fea_test)\n",
    "# label_pred = model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=200, precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "['BD', 'CD', 'STR', 'SPT', 'SPIN', 'PLT', 'RT', 'FKW']\n",
      "\n",
      "[[  0   0   0   0   0   0   0   0]\n",
      " [ 12   0   3   0   6   2   1   0]\n",
      " [138  49 488  33  39   0   2   1]\n",
      " [132   0  14   1   0   0   0   0]\n",
      " [  1   0   0   0   0   0   1   0]\n",
      " [256  11  25   5   8 253  60  14]\n",
      " [ 16   0   7   0   1   2  16   4]\n",
      " [ 28  14  55   0   0 121  38 647]]\n",
      "\n",
      "[[0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.5  0.   0.12 0.   0.25 0.08 0.04 0.  ]\n",
      " [0.18 0.07 0.65 0.04 0.05 0.   0.   0.  ]\n",
      " [0.9  0.   0.1  0.01 0.   0.   0.   0.  ]\n",
      " [0.5  0.   0.   0.   0.   0.   0.5  0.  ]\n",
      " [0.41 0.02 0.04 0.01 0.01 0.4  0.09 0.02]\n",
      " [0.35 0.   0.15 0.   0.02 0.04 0.35 0.09]\n",
      " [0.03 0.02 0.06 0.   0.   0.13 0.04 0.72]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix:\")\n",
    "cm = confusion_matrix(label_test, np.argmax(label_pred, axis=1), labels=species_id)\n",
    "\n",
    "print(species_list)\n",
    "print('')\n",
    "print(cm)\n",
    "print('')\n",
    "\n",
    "cm2 = cm*1.0\n",
    "for ii in range(cm.shape[0]):\n",
    "    cm_row = cm[ii, :]*1.0\n",
    "\n",
    "    cm_row_sum = cm_row.sum()\n",
    "    if cm_row_sum != 0:\n",
    "        cm2[ii, :] = cm_row / cm_row_sum\n",
    "    else:\n",
    "        cm2[ii, :] = np.zeros(cm.shape[1])\n",
    "\n",
    "print(cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics._plot.confusion_matrix import ConfusionMatrixDisplay\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=species_list)\n",
    "disp2 = ConfusionMatrixDisplay(confusion_matrix=cm2, display_labels=species_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fb9bb02fd30>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=[15, 15])\n",
    "disp.plot(include_values=True,\n",
    "                     cmap='viridis', ax=ax, xticks_rotation='horizontal',\n",
    "                     values_format=None, colorbar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fb9bae0ebb0>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=[15, 15])\n",
    "disp2.plot(include_values=True,\n",
    "                     cmap='viridis', ax=ax, xticks_rotation='horizontal',\n",
    "                     values_format='.2f', colorbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HICEAS2002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HICEAS2002\n"
     ]
    }
   ],
   "source": [
    "ee = deployment[3]\n",
    "print(ee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "fea_temp = np.load(os.path.join(feature_path, 'train_oswald_no_'+ee+'.npz'))\n",
    "fea_train = fea_temp['fea_train']\n",
    "label_train_list = fea_temp['label_train']\n",
    "del fea_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train = np.zeros(len(label_train_list))\n",
    "for ii in range(len(label_train_list)):\n",
    "    label_train[ii] = species_dict[label_train_list[ii]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing data\n",
    "fea_temp = np.load(os.path.join(feature_path, 'oswald_'+ee+'_orig.npz'))\n",
    "fea_test = fea_temp['feas_orig']\n",
    "label_test_list = fea_temp['labels_orig']\n",
    "\n",
    "fea_test = fea_test[:,:100,:]\n",
    "label_test = np.zeros(len(label_test_list))\n",
    "for ii in range(len(label_test_list)):\n",
    "    label_test[ii] = species_dict[label_test_list[ii]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_train = fea_train[:,:100,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train = np.zeros(len(label_train_list))\n",
    "for ii in range(len(label_train_list)):\n",
    "    label_train[ii] = species_dict[label_train_list[ii]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'BD': 11220,\n",
       "         'CD': 28440,\n",
       "         'PLT': 5730,\n",
       "         'RT': 3372,\n",
       "         'SPIN': 5694,\n",
       "         'SPT': 11316,\n",
       "         'STR': 13896,\n",
       "         'FKW': 19080})"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(label_train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0.0: 41, 5.0: 1052, 6.0: 749, 4.0: 86, 3.0: 385, 2.0: 216})"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(label_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_result_path2 = os.path.join(fit_result_path1, ee)\n",
    "if not os.path.exists(fit_result_path2):\n",
    "    makedirs(fit_result_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature train shape: (98748, 100, 128)\n",
      "feature test shape: (2529, 100, 128)\n",
      "label train shape: (98748,)\n",
      "label test shape: (2529,)\n",
      "dim_time: 100\n",
      "dim_freq: 128\n"
     ]
    }
   ],
   "source": [
    "print('feature train shape: '+str(fea_train.shape))\n",
    "print('feature test shape: '+str(fea_test.shape))\n",
    "print('label train shape: '+str(label_train.shape))\n",
    "print('label test shape: '+str(label_test.shape))\n",
    "\n",
    "dim_time = fea_train.shape[1]\n",
    "dim_freq = fea_train.shape[2]\n",
    "print('dim_time: '+str(dim_time))\n",
    "print('dim_freq: '+str(dim_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle features & labels\n",
    "fea_train, label_train = shuffle(fea_train, label_train, random_state=0)\n",
    "fea_test, label_test = shuffle(fea_test, label_test, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class weight\n",
    "weights = compute_class_weight(class_weight='balanced', classes=np.unique(label_train), y=label_train)\n",
    "\n",
    "class_weights = dict()\n",
    "for ii in range(num_species):\n",
    "    class_weights[ii] = weights[ii]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_train = np.expand_dims(fea_train, axis=3)\n",
    "fea_test = np.expand_dims(fea_test, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_train, fea_validate, label_train, label_validate = train_test_split(fea_train, label_train, test_size=0.10, random_state=42)\n",
    "\n",
    "train_generator = DataGenerator(fea_train, label_train, batch_size=batch_size, num_classes=num_species)\n",
    "del fea_train\n",
    "validate_generator = DataGenerator(fea_validate, label_validate, batch_size=batch_size, num_classes=num_species)\n",
    "del fea_validate\n",
    "\n",
    "# test_generator = DataGenerator(fea_test, label_test, batch_size=batch_size, num_classes=num_species)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "   2/5554 [..............................] - ETA: 11:18 - loss: 8.8065 - accuracy: 0.0938WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.115286). Check your callbacks.\n",
      "5553/5554 [============================>.] - ETA: 0s - loss: 0.6908 - accuracy: 0.1220\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.06453, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/HICEAS2002/epoch_01_valloss_0.4796_valacc_0.0645.hdf5\n",
      "5554/5554 [==============================] - 97s 17ms/step - loss: 0.6908 - accuracy: 0.1220 - val_loss: 0.4796 - val_accuracy: 0.0645\n",
      "Epoch 2/200\n",
      "5551/5554 [============================>.] - ETA: 0s - loss: 0.4813 - accuracy: 0.1228\n",
      "Epoch 00002: val_accuracy did not improve from 0.06453\n",
      "5554/5554 [==============================] - 98s 18ms/step - loss: 0.4812 - accuracy: 0.1229 - val_loss: 0.4382 - val_accuracy: 0.0451\n",
      "Epoch 3/200\n",
      "5551/5554 [============================>.] - ETA: 0s - loss: 0.4566 - accuracy: 0.1225\n",
      "Epoch 00003: val_accuracy improved from 0.06453 to 0.06635, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/HICEAS2002/epoch_03_valloss_0.4287_valacc_0.0663.hdf5\n",
      "5554/5554 [==============================] - 95s 17ms/step - loss: 0.4566 - accuracy: 0.1225 - val_loss: 0.4287 - val_accuracy: 0.0663\n",
      "Epoch 4/200\n",
      "5551/5554 [============================>.] - ETA: 0s - loss: 0.4455 - accuracy: 0.1228\n",
      "Epoch 00004: val_accuracy did not improve from 0.06635\n",
      "5554/5554 [==============================] - 95s 17ms/step - loss: 0.4454 - accuracy: 0.1228 - val_loss: 0.4210 - val_accuracy: 0.0435\n",
      "Epoch 5/200\n",
      "5552/5554 [============================>.] - ETA: 0s - loss: 0.4367 - accuracy: 0.1257\n",
      "Epoch 00005: val_accuracy improved from 0.06635 to 0.08752, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/HICEAS2002/epoch_05_valloss_0.4178_valacc_0.0875.hdf5\n",
      "5554/5554 [==============================] - 95s 17ms/step - loss: 0.4366 - accuracy: 0.1257 - val_loss: 0.4178 - val_accuracy: 0.0875\n",
      "Epoch 6/200\n",
      "5553/5554 [============================>.] - ETA: 0s - loss: 0.4246 - accuracy: 0.1454\n",
      "Epoch 00006: val_accuracy improved from 0.08752 to 0.10494, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/HICEAS2002/epoch_06_valloss_0.4160_valacc_0.1049.hdf5\n",
      "5554/5554 [==============================] - 95s 17ms/step - loss: 0.4246 - accuracy: 0.1454 - val_loss: 0.4160 - val_accuracy: 0.1049\n",
      "Epoch 7/200\n",
      "5554/5554 [==============================] - ETA: 0s - loss: 0.4082 - accuracy: 0.1749\n",
      "Epoch 00007: val_accuracy improved from 0.10494 to 0.17220, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/HICEAS2002/epoch_07_valloss_0.3950_valacc_0.1722.hdf5\n",
      "5554/5554 [==============================] - 95s 17ms/step - loss: 0.4082 - accuracy: 0.1749 - val_loss: 0.3950 - val_accuracy: 0.1722\n",
      "Epoch 8/200\n",
      "5551/5554 [============================>.] - ETA: 0s - loss: 0.3891 - accuracy: 0.2313\n",
      "Epoch 00008: val_accuracy improved from 0.17220 to 0.26033, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/HICEAS2002/epoch_08_valloss_0.3662_valacc_0.2603.hdf5\n",
      "5554/5554 [==============================] - 95s 17ms/step - loss: 0.3891 - accuracy: 0.2313 - val_loss: 0.3662 - val_accuracy: 0.2603\n",
      "Epoch 9/200\n",
      "5554/5554 [==============================] - ETA: 0s - loss: 0.3688 - accuracy: 0.2976\n",
      "Epoch 00009: val_accuracy did not improve from 0.26033\n",
      "5554/5554 [==============================] - 95s 17ms/step - loss: 0.3688 - accuracy: 0.2976 - val_loss: 0.3667 - val_accuracy: 0.2524\n",
      "Epoch 10/200\n",
      "5553/5554 [============================>.] - ETA: 0s - loss: 0.3529 - accuracy: 0.3335\n",
      "Epoch 00010: val_accuracy improved from 0.26033 to 0.26165, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/HICEAS2002/epoch_10_valloss_0.3715_valacc_0.2616.hdf5\n",
      "5554/5554 [==============================] - 95s 17ms/step - loss: 0.3529 - accuracy: 0.3336 - val_loss: 0.3715 - val_accuracy: 0.2616\n",
      "Epoch 11/200\n",
      "5554/5554 [==============================] - ETA: 0s - loss: 0.3427 - accuracy: 0.3577\n",
      "Epoch 00011: val_accuracy improved from 0.26165 to 0.31291, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/HICEAS2002/epoch_11_valloss_0.3549_valacc_0.3129.hdf5\n",
      "5554/5554 [==============================] - 95s 17ms/step - loss: 0.3427 - accuracy: 0.3577 - val_loss: 0.3549 - val_accuracy: 0.3129\n",
      "Epoch 12/200\n",
      "5553/5554 [============================>.] - ETA: 0s - loss: 0.3340 - accuracy: 0.3752\n",
      "Epoch 00012: val_accuracy improved from 0.31291 to 0.40103, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/HICEAS2002/epoch_12_valloss_0.3200_valacc_0.4010.hdf5\n",
      "5554/5554 [==============================] - 95s 17ms/step - loss: 0.3340 - accuracy: 0.3752 - val_loss: 0.3200 - val_accuracy: 0.4010\n",
      "Epoch 13/200\n",
      "5552/5554 [============================>.] - ETA: 0s - loss: 0.3254 - accuracy: 0.3998\n",
      "Epoch 00013: val_accuracy improved from 0.40103 to 0.42180, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/HICEAS2002/epoch_13_valloss_0.3162_valacc_0.4218.hdf5\n",
      "5554/5554 [==============================] - 95s 17ms/step - loss: 0.3254 - accuracy: 0.3998 - val_loss: 0.3162 - val_accuracy: 0.4218\n",
      "Epoch 14/200\n",
      "5553/5554 [============================>.] - ETA: 0s - loss: 0.3179 - accuracy: 0.4239\n",
      "Epoch 00014: val_accuracy did not improve from 0.42180\n",
      "5554/5554 [==============================] - 95s 17ms/step - loss: 0.3179 - accuracy: 0.4239 - val_loss: 0.3350 - val_accuracy: 0.3722\n",
      "Epoch 15/200\n",
      "5553/5554 [============================>.] - ETA: 0s - loss: 0.3114 - accuracy: 0.4373\n",
      "Epoch 00015: val_accuracy improved from 0.42180 to 0.42980, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/HICEAS2002/epoch_15_valloss_0.3124_valacc_0.4298.hdf5\n",
      "5554/5554 [==============================] - 95s 17ms/step - loss: 0.3114 - accuracy: 0.4373 - val_loss: 0.3124 - val_accuracy: 0.4298\n",
      "Epoch 16/200\n",
      "5552/5554 [============================>.] - ETA: 0s - loss: 0.3061 - accuracy: 0.4502\n",
      "Epoch 00016: val_accuracy did not improve from 0.42980\n",
      "5554/5554 [==============================] - 95s 17ms/step - loss: 0.3061 - accuracy: 0.4502 - val_loss: 0.3163 - val_accuracy: 0.4062\n",
      "Epoch 17/200\n",
      "5552/5554 [============================>.] - ETA: 0s - loss: 0.3016 - accuracy: 0.4617\n",
      "Epoch 00017: val_accuracy improved from 0.42980 to 0.48572, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/HICEAS2002/epoch_17_valloss_0.2866_valacc_0.4857.hdf5\n",
      "5554/5554 [==============================] - 95s 17ms/step - loss: 0.3016 - accuracy: 0.4618 - val_loss: 0.2866 - val_accuracy: 0.4857\n",
      "Epoch 18/200\n",
      "5551/5554 [============================>.] - ETA: 0s - loss: 0.2972 - accuracy: 0.4718\n",
      "Epoch 00018: val_accuracy did not improve from 0.48572\n",
      "5554/5554 [==============================] - 95s 17ms/step - loss: 0.2972 - accuracy: 0.4718 - val_loss: 0.3039 - val_accuracy: 0.4423\n",
      "Epoch 19/200\n",
      "5554/5554 [==============================] - ETA: 0s - loss: 0.2929 - accuracy: 0.4826\n",
      "Epoch 00019: val_accuracy did not improve from 0.48572\n",
      "5554/5554 [==============================] - 95s 17ms/step - loss: 0.2929 - accuracy: 0.4826 - val_loss: 0.3062 - val_accuracy: 0.4734\n",
      "Epoch 20/200\n",
      "5553/5554 [============================>.] - ETA: 0s - loss: 0.2888 - accuracy: 0.4932\n",
      "Epoch 00020: val_accuracy improved from 0.48572 to 0.51185, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/HICEAS2002/epoch_20_valloss_0.2761_valacc_0.5119.hdf5\n",
      "5554/5554 [==============================] - 95s 17ms/step - loss: 0.2888 - accuracy: 0.4932 - val_loss: 0.2761 - val_accuracy: 0.5119\n",
      "Epoch 21/200\n",
      "5554/5554 [==============================] - ETA: 0s - loss: 0.2858 - accuracy: 0.4999\n",
      "Epoch 00021: val_accuracy did not improve from 0.51185\n",
      "5554/5554 [==============================] - 95s 17ms/step - loss: 0.2858 - accuracy: 0.4999 - val_loss: 0.2970 - val_accuracy: 0.4720\n",
      "Epoch 22/200\n",
      "5554/5554 [==============================] - ETA: 0s - loss: 0.2824 - accuracy: 0.5076\n",
      "Epoch 00022: val_accuracy did not improve from 0.51185\n",
      "5554/5554 [==============================] - 95s 17ms/step - loss: 0.2824 - accuracy: 0.5076 - val_loss: 0.3353 - val_accuracy: 0.3863\n",
      "Epoch 23/200\n",
      "5553/5554 [============================>.] - ETA: 0s - loss: 0.2802 - accuracy: 0.5132\n",
      "Epoch 00023: val_accuracy did not improve from 0.51185\n",
      "5554/5554 [==============================] - 95s 17ms/step - loss: 0.2801 - accuracy: 0.5132 - val_loss: 0.3050 - val_accuracy: 0.4524\n",
      "Epoch 24/200\n",
      "5553/5554 [============================>.] - ETA: 0s - loss: 0.2771 - accuracy: 0.5182\n",
      "Epoch 00024: val_accuracy improved from 0.51185 to 0.54974, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/HICEAS2002/epoch_24_valloss_0.2586_valacc_0.5497.hdf5\n",
      "5554/5554 [==============================] - 95s 17ms/step - loss: 0.2771 - accuracy: 0.5182 - val_loss: 0.2586 - val_accuracy: 0.5497\n",
      "Epoch 25/200\n",
      "5553/5554 [============================>.] - ETA: 0s - loss: 0.2735 - accuracy: 0.5253\n",
      "Epoch 00025: val_accuracy did not improve from 0.54974\n",
      "5554/5554 [==============================] - 95s 17ms/step - loss: 0.2735 - accuracy: 0.5253 - val_loss: 0.2714 - val_accuracy: 0.5399\n",
      "Epoch 26/200\n",
      "5554/5554 [==============================] - ETA: 0s - loss: 0.2711 - accuracy: 0.5340\n",
      "Epoch 00026: val_accuracy did not improve from 0.54974\n",
      "5554/5554 [==============================] - 96s 17ms/step - loss: 0.2711 - accuracy: 0.5340 - val_loss: 0.2956 - val_accuracy: 0.4954\n",
      "Epoch 27/200\n",
      "5553/5554 [============================>.] - ETA: 0s - loss: 0.2687 - accuracy: 0.5367\n",
      "Epoch 00027: val_accuracy improved from 0.54974 to 0.55409, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/HICEAS2002/epoch_27_valloss_0.2623_valacc_0.5541.hdf5\n",
      "5554/5554 [==============================] - 96s 17ms/step - loss: 0.2687 - accuracy: 0.5366 - val_loss: 0.2623 - val_accuracy: 0.5541\n",
      "Epoch 28/200\n",
      "5553/5554 [============================>.] - ETA: 0s - loss: 0.2661 - accuracy: 0.5446\n",
      "Epoch 00028: val_accuracy did not improve from 0.55409\n",
      "5554/5554 [==============================] - 95s 17ms/step - loss: 0.2661 - accuracy: 0.5446 - val_loss: 0.2926 - val_accuracy: 0.4925\n",
      "Epoch 29/200\n",
      "5554/5554 [==============================] - ETA: 0s - loss: 0.2650 - accuracy: 0.5461\n",
      "Epoch 00029: val_accuracy did not improve from 0.55409\n",
      "5554/5554 [==============================] - 95s 17ms/step - loss: 0.2650 - accuracy: 0.5461 - val_loss: 0.2736 - val_accuracy: 0.5276\n",
      "Epoch 30/200\n",
      "5551/5554 [============================>.] - ETA: 0s - loss: 0.2616 - accuracy: 0.5535\n",
      "Epoch 00030: val_accuracy improved from 0.55409 to 0.57040, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/HICEAS2002/epoch_30_valloss_0.2509_valacc_0.5704.hdf5\n",
      "5554/5554 [==============================] - 95s 17ms/step - loss: 0.2616 - accuracy: 0.5535 - val_loss: 0.2509 - val_accuracy: 0.5704\n",
      "Epoch 31/200\n",
      "5553/5554 [============================>.] - ETA: 0s - loss: 0.2603 - accuracy: 0.5582\n",
      "Epoch 00031: val_accuracy did not improve from 0.57040\n",
      "5554/5554 [==============================] - 95s 17ms/step - loss: 0.2603 - accuracy: 0.5582 - val_loss: 0.2885 - val_accuracy: 0.4903\n",
      "Epoch 32/200\n",
      "5554/5554 [==============================] - ETA: 0s - loss: 0.2580 - accuracy: 0.5630\n",
      "Epoch 00032: val_accuracy improved from 0.57040 to 0.59340, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/HICEAS2002/epoch_32_valloss_0.2411_valacc_0.5934.hdf5\n",
      "5554/5554 [==============================] - 96s 17ms/step - loss: 0.2580 - accuracy: 0.5630 - val_loss: 0.2411 - val_accuracy: 0.5934\n",
      "Epoch 33/200\n",
      "5552/5554 [============================>.] - ETA: 0s - loss: 0.2559 - accuracy: 0.5667\n",
      "Epoch 00033: val_accuracy did not improve from 0.59340\n",
      "5554/5554 [==============================] - 96s 17ms/step - loss: 0.2559 - accuracy: 0.5668 - val_loss: 0.2588 - val_accuracy: 0.5618\n",
      "Epoch 34/200\n",
      "5551/5554 [============================>.] - ETA: 0s - loss: 0.2541 - accuracy: 0.5697\n",
      "Epoch 00034: val_accuracy did not improve from 0.59340\n",
      "5554/5554 [==============================] - 95s 17ms/step - loss: 0.2542 - accuracy: 0.5696 - val_loss: 0.2745 - val_accuracy: 0.5216\n",
      "Epoch 35/200\n",
      "5552/5554 [============================>.] - ETA: 0s - loss: 0.2529 - accuracy: 0.5735\n",
      "Epoch 00035: val_accuracy did not improve from 0.59340\n",
      "5554/5554 [==============================] - 95s 17ms/step - loss: 0.2529 - accuracy: 0.5735 - val_loss: 0.2714 - val_accuracy: 0.5365\n",
      "Epoch 36/200\n",
      "5553/5554 [============================>.] - ETA: 0s - loss: 0.2517 - accuracy: 0.5761\n",
      "Epoch 00036: val_accuracy did not improve from 0.59340\n",
      "5554/5554 [==============================] - 96s 17ms/step - loss: 0.2517 - accuracy: 0.5762 - val_loss: 0.2901 - val_accuracy: 0.5080\n",
      "Epoch 37/200\n",
      "5552/5554 [============================>.] - ETA: 0s - loss: 0.2501 - accuracy: 0.5812\n",
      "Epoch 00037: val_accuracy did not improve from 0.59340\n",
      "5554/5554 [==============================] - 95s 17ms/step - loss: 0.2501 - accuracy: 0.5812 - val_loss: 0.2642 - val_accuracy: 0.5595\n",
      "Epoch 38/200\n",
      "5553/5554 [============================>.] - ETA: 0s - loss: 0.2489 - accuracy: 0.5826\n",
      "Epoch 00038: val_accuracy did not improve from 0.59340\n",
      "5554/5554 [==============================] - 96s 17ms/step - loss: 0.2489 - accuracy: 0.5826 - val_loss: 0.2575 - val_accuracy: 0.5590\n",
      "Epoch 39/200\n",
      "5551/5554 [============================>.] - ETA: 0s - loss: 0.2471 - accuracy: 0.5869\n",
      "Epoch 00039: val_accuracy did not improve from 0.59340\n",
      "5554/5554 [==============================] - 95s 17ms/step - loss: 0.2471 - accuracy: 0.5870 - val_loss: 0.2565 - val_accuracy: 0.5653\n",
      "Epoch 40/200\n",
      "5552/5554 [============================>.] - ETA: 0s - loss: 0.2457 - accuracy: 0.5908\n",
      "Epoch 00040: val_accuracy did not improve from 0.59340\n",
      "5554/5554 [==============================] - 96s 17ms/step - loss: 0.2457 - accuracy: 0.5907 - val_loss: 0.2923 - val_accuracy: 0.5088\n",
      "Epoch 41/200\n",
      "5554/5554 [==============================] - ETA: 0s - loss: 0.2448 - accuracy: 0.5929\n",
      "Epoch 00041: val_accuracy did not improve from 0.59340\n",
      "5554/5554 [==============================] - 96s 17ms/step - loss: 0.2448 - accuracy: 0.5929 - val_loss: 0.2507 - val_accuracy: 0.5915\n",
      "Epoch 42/200\n",
      "5554/5554 [==============================] - ETA: 0s - loss: 0.2427 - accuracy: 0.5971\n",
      "Epoch 00042: val_accuracy did not improve from 0.59340\n",
      "5554/5554 [==============================] - 96s 17ms/step - loss: 0.2427 - accuracy: 0.5971 - val_loss: 0.2661 - val_accuracy: 0.5526\n",
      "Epoch 43/200\n",
      "5552/5554 [============================>.] - ETA: 0s - loss: 0.2430 - accuracy: 0.5973\n",
      "Epoch 00043: val_accuracy did not improve from 0.59340\n",
      "5554/5554 [==============================] - 96s 17ms/step - loss: 0.2430 - accuracy: 0.5974 - val_loss: 0.2560 - val_accuracy: 0.5833\n",
      "Epoch 44/200\n",
      "5551/5554 [============================>.] - ETA: 0s - loss: 0.2404 - accuracy: 0.6020\n",
      "Epoch 00044: val_accuracy did not improve from 0.59340\n",
      "5554/5554 [==============================] - 96s 17ms/step - loss: 0.2404 - accuracy: 0.6020 - val_loss: 0.2467 - val_accuracy: 0.5870\n",
      "Epoch 45/200\n",
      "5554/5554 [==============================] - ETA: 0s - loss: 0.2405 - accuracy: 0.6025\n",
      "Epoch 00045: val_accuracy improved from 0.59340 to 0.60930, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/HICEAS2002/epoch_45_valloss_0.2350_valacc_0.6093.hdf5\n",
      "5554/5554 [==============================] - 96s 17ms/step - loss: 0.2405 - accuracy: 0.6025 - val_loss: 0.2350 - val_accuracy: 0.6093\n",
      "Epoch 46/200\n",
      "5553/5554 [============================>.] - ETA: 0s - loss: 0.2387 - accuracy: 0.6053\n",
      "Epoch 00046: val_accuracy did not improve from 0.60930\n",
      "5554/5554 [==============================] - 96s 17ms/step - loss: 0.2387 - accuracy: 0.6053 - val_loss: 0.2368 - val_accuracy: 0.6053\n",
      "Epoch 47/200\n",
      "5554/5554 [==============================] - ETA: 0s - loss: 0.2382 - accuracy: 0.6056\n",
      "Epoch 00047: val_accuracy did not improve from 0.60930\n",
      "5554/5554 [==============================] - 96s 17ms/step - loss: 0.2382 - accuracy: 0.6056 - val_loss: 0.2563 - val_accuracy: 0.5786\n",
      "Epoch 48/200\n",
      "5552/5554 [============================>.] - ETA: 0s - loss: 0.2372 - accuracy: 0.6094\n",
      "Epoch 00048: val_accuracy improved from 0.60930 to 0.62561, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/HICEAS2002/epoch_48_valloss_0.2297_valacc_0.6256.hdf5\n",
      "5554/5554 [==============================] - 96s 17ms/step - loss: 0.2372 - accuracy: 0.6094 - val_loss: 0.2297 - val_accuracy: 0.6256\n",
      "Epoch 49/200\n",
      "5554/5554 [==============================] - ETA: 0s - loss: 0.2363 - accuracy: 0.6114\n",
      "Epoch 00049: val_accuracy did not improve from 0.62561\n",
      "5554/5554 [==============================] - 96s 17ms/step - loss: 0.2363 - accuracy: 0.6114 - val_loss: 0.2356 - val_accuracy: 0.6197\n",
      "Epoch 50/200\n",
      "5554/5554 [==============================] - ETA: 0s - loss: 0.2357 - accuracy: 0.6133\n",
      "Epoch 00050: val_accuracy did not improve from 0.62561\n",
      "5554/5554 [==============================] - 96s 17ms/step - loss: 0.2357 - accuracy: 0.6133 - val_loss: 0.2365 - val_accuracy: 0.6166\n",
      "Epoch 51/200\n",
      "5553/5554 [============================>.] - ETA: 0s - loss: 0.2350 - accuracy: 0.6159\n",
      "Epoch 00051: val_accuracy did not improve from 0.62561\n",
      "5554/5554 [==============================] - 96s 17ms/step - loss: 0.2351 - accuracy: 0.6159 - val_loss: 0.2407 - val_accuracy: 0.6104\n",
      "Epoch 52/200\n",
      "5553/5554 [============================>.] - ETA: 0s - loss: 0.2338 - accuracy: 0.6171\n",
      "Epoch 00052: val_accuracy did not improve from 0.62561\n",
      "5554/5554 [==============================] - 96s 17ms/step - loss: 0.2338 - accuracy: 0.6171 - val_loss: 0.2354 - val_accuracy: 0.6173\n",
      "Epoch 53/200\n",
      "5553/5554 [============================>.] - ETA: 0s - loss: 0.2327 - accuracy: 0.6209\n",
      "Epoch 00053: val_accuracy did not improve from 0.62561\n",
      "5554/5554 [==============================] - 96s 17ms/step - loss: 0.2327 - accuracy: 0.6210 - val_loss: 0.2433 - val_accuracy: 0.5912\n",
      "Epoch 54/200\n",
      "5554/5554 [==============================] - ETA: 0s - loss: 0.2325 - accuracy: 0.6206\n",
      "Epoch 00054: val_accuracy improved from 0.62561 to 0.63513, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/HICEAS2002/epoch_54_valloss_0.2288_valacc_0.6351.hdf5\n",
      "5554/5554 [==============================] - 96s 17ms/step - loss: 0.2325 - accuracy: 0.6206 - val_loss: 0.2288 - val_accuracy: 0.6351\n",
      "Epoch 55/200\n",
      "5552/5554 [============================>.] - ETA: 0s - loss: 0.2313 - accuracy: 0.6237\n",
      "Epoch 00055: val_accuracy improved from 0.63513 to 0.63645, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/HICEAS2002/epoch_55_valloss_0.2253_valacc_0.6364.hdf5\n",
      "5554/5554 [==============================] - 96s 17ms/step - loss: 0.2313 - accuracy: 0.6237 - val_loss: 0.2253 - val_accuracy: 0.6364\n",
      "Epoch 56/200\n",
      "5552/5554 [============================>.] - ETA: 0s - loss: 0.2299 - accuracy: 0.6254\n",
      "Epoch 00056: val_accuracy did not improve from 0.63645\n",
      "5554/5554 [==============================] - 96s 17ms/step - loss: 0.2299 - accuracy: 0.6254 - val_loss: 0.2665 - val_accuracy: 0.5577\n",
      "Epoch 57/200\n",
      "5554/5554 [==============================] - ETA: 0s - loss: 0.2295 - accuracy: 0.6253\n",
      "Epoch 00057: val_accuracy did not improve from 0.63645\n",
      "5554/5554 [==============================] - 96s 17ms/step - loss: 0.2295 - accuracy: 0.6253 - val_loss: 0.2320 - val_accuracy: 0.6330\n",
      "Epoch 58/200\n",
      "5553/5554 [============================>.] - ETA: 0s - loss: 0.2286 - accuracy: 0.6297\n",
      "Epoch 00058: val_accuracy did not improve from 0.63645\n",
      "5554/5554 [==============================] - 96s 17ms/step - loss: 0.2286 - accuracy: 0.6297 - val_loss: 0.2422 - val_accuracy: 0.6066\n",
      "Epoch 59/200\n",
      "5551/5554 [============================>.] - ETA: 0s - loss: 0.2284 - accuracy: 0.6333\n",
      "Epoch 00059: val_accuracy did not improve from 0.63645\n",
      "5554/5554 [==============================] - 96s 17ms/step - loss: 0.2284 - accuracy: 0.6333 - val_loss: 0.2288 - val_accuracy: 0.6312\n",
      "Epoch 60/200\n",
      "5553/5554 [============================>.] - ETA: 0s - loss: 0.2273 - accuracy: 0.6303\n",
      "Epoch 00060: val_accuracy did not improve from 0.63645\n",
      "5554/5554 [==============================] - 96s 17ms/step - loss: 0.2273 - accuracy: 0.6303 - val_loss: 0.2428 - val_accuracy: 0.6073\n",
      "Epoch 61/200\n",
      "5553/5554 [============================>.] - ETA: 0s - loss: 0.2268 - accuracy: 0.6328\n",
      "Epoch 00061: val_accuracy did not improve from 0.63645\n",
      "5554/5554 [==============================] - 96s 17ms/step - loss: 0.2268 - accuracy: 0.6328 - val_loss: 0.2379 - val_accuracy: 0.6063\n",
      "Epoch 62/200\n",
      "5554/5554 [==============================] - ETA: 0s - loss: 0.2256 - accuracy: 0.6350\n",
      "Epoch 00062: val_accuracy did not improve from 0.63645\n",
      "5554/5554 [==============================] - 96s 17ms/step - loss: 0.2256 - accuracy: 0.6350 - val_loss: 0.2597 - val_accuracy: 0.5724\n",
      "Epoch 63/200\n",
      "5553/5554 [============================>.] - ETA: 0s - loss: 0.2256 - accuracy: 0.6341\n",
      "Epoch 00063: val_accuracy did not improve from 0.63645\n",
      "5554/5554 [==============================] - 96s 17ms/step - loss: 0.2256 - accuracy: 0.6341 - val_loss: 0.2459 - val_accuracy: 0.5987\n",
      "Epoch 64/200\n",
      "5552/5554 [============================>.] - ETA: 0s - loss: 0.2246 - accuracy: 0.6373\n",
      "Epoch 00064: val_accuracy improved from 0.63645 to 0.64050, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210316_220846/HICEAS2002/epoch_64_valloss_0.2231_valacc_0.6405.hdf5\n",
      "5554/5554 [==============================] - 97s 17ms/step - loss: 0.2246 - accuracy: 0.6373 - val_loss: 0.2231 - val_accuracy: 0.6405\n",
      "Epoch 65/200\n",
      "5554/5554 [==============================] - ETA: 0s - loss: 0.2239 - accuracy: 0.6390\n",
      "Epoch 00065: val_accuracy did not improve from 0.64050\n",
      "5554/5554 [==============================] - 96s 17ms/step - loss: 0.2239 - accuracy: 0.6390 - val_loss: 0.2461 - val_accuracy: 0.5926\n",
      "Epoch 66/200\n",
      "5552/5554 [============================>.] - ETA: 0s - loss: 0.2236 - accuracy: 0.6381\n",
      "Epoch 00066: val_accuracy did not improve from 0.64050\n",
      "5554/5554 [==============================] - 97s 17ms/step - loss: 0.2236 - accuracy: 0.6381 - val_loss: 0.2312 - val_accuracy: 0.6339\n",
      "Epoch 67/200\n",
      "5552/5554 [============================>.] - ETA: 0s - loss: 0.2233 - accuracy: 0.6402\n",
      "Epoch 00067: val_accuracy did not improve from 0.64050\n",
      "5554/5554 [==============================] - 96s 17ms/step - loss: 0.2233 - accuracy: 0.6402 - val_loss: 0.2537 - val_accuracy: 0.5900\n",
      "Epoch 68/200\n",
      "4994/5554 [=========================>....] - ETA: 9s - loss: 0.2228 - accuracy: 0.6424"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-0cd4286d109d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# history = model.fit(train_generator, validation_data=validate_generator, class_weight=class_weights, epochs=num_epoch, callbacks=[EarlyStopping(patience=num_patience, monitor='val_loss', mode='min', verbose=1), TensorBoard(log_dir=fit_result_path1), ModelCheckpoint(filepath=os.path.join(fit_result_path1, '{epoch:02d}-{val_loss:.4f}.hdf5'), verbose=1, monitor=\"val_loss\", save_best_only=True)])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# history = model.fit(train_generator, validation_data=validate_generator, class_weight=class_weights, epochs=num_epoch, callbacks=[EarlyStopping(patience=num_patience, monitor='val_loss', mode='min', verbose=1), TensorBoard(log_dir=fit_result_path2), ModelCheckpoint(filepath=os.path.join(fit_result_path2, 'epoch_{epoch:02d}_valloss_{val_loss:.4f}_valacc_{val_accuracy:.4f}.hdf5' ), verbose=1, monitor=\"val_accuracy\", save_best_only=True)])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_patience\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_result_path2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_result_path2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'epoch_{epoch:02d}_valloss_{val_loss:.4f}_valacc_{val_accuracy:.4f}.hdf5'\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"val_accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/whistle_classifier/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/whistle_classifier/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/whistle_classifier/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/whistle_classifier/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/whistle_classifier/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/whistle_classifier/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1659\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \"\"\"\n\u001b[0;32m-> 1661\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1662\u001b[0m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/miniconda3/envs/whistle_classifier/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/miniconda3/envs/whistle_classifier/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    591\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    594\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/whistle_classifier/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model = model_cnn14_attention_multi(dim_time, dim_freq, num_species, model_type='feature_level_attention', conv_dim=conv_dim, pool_size=pool_size, pool_stride=pool_stride, hidden_units=hidden_units, l2_regu=l2_regu, drop_rate=drop_rate)\n",
    "model = model_cnn14_spp(dim_time, dim_freq, num_species, conv_dim=conv_dim, pool_size=pool_size, pool_stride=pool_stride, hidden_units=hidden_units, l2_regu=l2_regu, drop_rate=drop_rate)\n",
    "# loss = CategoricalCrossentropy()\n",
    "loss = binary_crossentropy\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate_fn), loss=loss, metrics=['accuracy'])\n",
    "\n",
    "# With classes\n",
    "# history = model.fit(fea_train, to_categorical(label_train), class_weight=class_weights, validation_split=0.3, batch_size=batch_size, epochs=num_epoch, callbacks=[EarlyStopping(patience=num_patience), ModelCheckpoint(filepath=os.path.join(fit_result_path, '{epoch:02d}-{val_loss:.4f}.hdf5'), verbose=1, monitor=\"val_loss\", save_best_only=True)])\n",
    "# history = model.fit(train_generator, validation_data=validate_generator, class_weight=class_weights, epochs=num_epoch, callbacks=[EarlyStopping(patience=num_patience, monitor='val_loss', mode='min', verbose=1), TensorBoard(log_dir=fit_result_path1), ModelCheckpoint(filepath=os.path.join(fit_result_path1, '{epoch:02d}-{val_loss:.4f}.hdf5'), verbose=1, monitor=\"val_loss\", save_best_only=True)])\n",
    "# history = model.fit(train_generator, validation_data=validate_generator, class_weight=class_weights, epochs=num_epoch, callbacks=[EarlyStopping(patience=num_patience, monitor='val_loss', mode='min', verbose=1), TensorBoard(log_dir=fit_result_path2), ModelCheckpoint(filepath=os.path.join(fit_result_path2, 'epoch_{epoch:02d}_valloss_{val_loss:.4f}_valacc_{val_accuracy:.4f}.hdf5' ), verbose=1, monitor=\"val_accuracy\", save_best_only=True)])\n",
    "history = model.fit(train_generator, validation_data=validate_generator, class_weight=class_weights, epochs=num_epoch, callbacks=[EarlyStopping(patience=num_patience, monitor='val_accuracy', mode='max', verbose=1), TensorBoard(log_dir=fit_result_path2), ModelCheckpoint(filepath=os.path.join(fit_result_path2, 'epoch_{epoch:02d}_valloss_{val_loss:.4f}_valacc_{val_accuracy:.4f}.hdf5' ), verbose=1, monitor=\"val_accuracy\", save_best_only=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit_result_path1 = '/home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210210_224527'\n",
    "the_best_model, _ = find_best_model(fit_result_path2, purge=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = load_model(the_best_model)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pred = model.predict(fea_test)\n",
    "# label_pred = model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=200, precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion matrix:\")\n",
    "cm = confusion_matrix(label_test, np.argmax(label_pred, axis=1), labels=species_id)\n",
    "\n",
    "print(species_list)\n",
    "print('')\n",
    "print(cm)\n",
    "print('')\n",
    "\n",
    "cm2 = cm*1.0\n",
    "for ii in range(cm.shape[0]):\n",
    "    cm_row = cm[ii, :]*1.0\n",
    "\n",
    "    cm_row_sum = cm_row.sum()\n",
    "    if cm_row_sum != 0:\n",
    "        cm2[ii, :] = cm_row / cm_row_sum\n",
    "    else:\n",
    "        cm2[ii, :] = np.zeros(cm.shape[1])\n",
    "\n",
    "print(cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics._plot.confusion_matrix import ConfusionMatrixDisplay\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=species_list)\n",
    "disp2 = ConfusionMatrixDisplay(confusion_matrix=cm2, display_labels=species_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[15, 15])\n",
    "disp.plot(include_values=True,\n",
    "                     cmap='viridis', ax=ax, xticks_rotation='horizontal',\n",
    "                     values_format=None, colorbar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[15, 15])\n",
    "disp2.plot(include_values=True,\n",
    "                     cmap='viridis', ax=ax, xticks_rotation='horizontal',\n",
    "                     values_format='.2f', colorbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PICES2005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee = deployment[4]\n",
    "print(ee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "fea_temp = np.load(os.path.join(feature_path, 'train_oswald_no_'+ee+'.npz'))\n",
    "fea_train = fea_temp['fea_train']\n",
    "label_train_list = fea_temp['label_train']\n",
    "del fea_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train = np.zeros(len(label_train_list))\n",
    "for ii in range(len(label_train_list)):\n",
    "    label_train[ii] = species_dict[label_train_list[ii]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing data\n",
    "fea_temp = np.load(os.path.join(feature_path, 'oswald_'+ee+'_orig.npz'))\n",
    "fea_test = fea_temp['feas_orig']\n",
    "label_test_list = fea_temp['labels_orig']\n",
    "\n",
    "fea_test = fea_test[:,:100,:]\n",
    "label_test = np.zeros(len(label_test_list))\n",
    "for ii in range(len(label_test_list)):\n",
    "    label_test[ii] = species_dict[label_test_list[ii]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_train = fea_train[:,:100,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train = np.zeros(len(label_train_list))\n",
    "for ii in range(len(label_train_list)):\n",
    "    label_train[ii] = species_dict[label_train_list[ii]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Counter(label_train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(label_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_result_path2 = os.path.join(fit_result_path1, ee)\n",
    "if not os.path.exists(fit_result_path2):\n",
    "    makedirs(fit_result_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('feature train shape: '+str(fea_train.shape))\n",
    "print('feature test shape: '+str(fea_test.shape))\n",
    "print('label train shape: '+str(label_train.shape))\n",
    "print('label test shape: '+str(label_test.shape))\n",
    "\n",
    "dim_time = fea_train.shape[1]\n",
    "dim_freq = fea_train.shape[2]\n",
    "print('dim_time: '+str(dim_time))\n",
    "print('dim_freq: '+str(dim_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle features & labels\n",
    "fea_train, label_train = shuffle(fea_train, label_train, random_state=0)\n",
    "fea_test, label_test = shuffle(fea_test, label_test, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class weight\n",
    "weights = compute_class_weight(class_weight='balanced', classes=np.unique(label_train), y=label_train)\n",
    "\n",
    "class_weights = dict()\n",
    "for ii in range(num_species):\n",
    "    class_weights[ii] = weights[ii]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_train = np.expand_dims(fea_train, axis=3)\n",
    "fea_test = np.expand_dims(fea_test, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_train, fea_validate, label_train, label_validate = train_test_split(fea_train, label_train, test_size=0.10, random_state=42)\n",
    "\n",
    "train_generator = DataGenerator(fea_train, label_train, batch_size=batch_size, num_classes=num_species)\n",
    "del fea_train\n",
    "validate_generator = DataGenerator(fea_validate, label_validate, batch_size=batch_size, num_classes=num_species)\n",
    "del fea_validate\n",
    "\n",
    "# test_generator = DataGenerator(fea_test, label_test, batch_size=batch_size, num_classes=num_species)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model = model_cnn14_attention_multi(dim_time, dim_freq, num_species, model_type='feature_level_attention', conv_dim=conv_dim, pool_size=pool_size, pool_stride=pool_stride, hidden_units=hidden_units, l2_regu=l2_regu, drop_rate=drop_rate)\n",
    "model = model_cnn14_spp(dim_time, dim_freq, num_species, conv_dim=conv_dim, pool_size=pool_size, pool_stride=pool_stride, hidden_units=hidden_units, l2_regu=l2_regu, drop_rate=drop_rate)\n",
    "# loss = CategoricalCrossentropy()\n",
    "loss = binary_crossentropy\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate_fn), loss=loss, metrics=['accuracy'])\n",
    "\n",
    "# With classes\n",
    "# history = model.fit(fea_train, to_categorical(label_train), class_weight=class_weights, validation_split=0.3, batch_size=batch_size, epochs=num_epoch, callbacks=[EarlyStopping(patience=num_patience), ModelCheckpoint(filepath=os.path.join(fit_result_path, '{epoch:02d}-{val_loss:.4f}.hdf5'), verbose=1, monitor=\"val_loss\", save_best_only=True)])\n",
    "# history = model.fit(train_generator, validation_data=validate_generator, class_weight=class_weights, epochs=num_epoch, callbacks=[EarlyStopping(patience=num_patience, monitor='val_loss', mode='min', verbose=1), TensorBoard(log_dir=fit_result_path1), ModelCheckpoint(filepath=os.path.join(fit_result_path1, '{epoch:02d}-{val_loss:.4f}.hdf5'), verbose=1, monitor=\"val_loss\", save_best_only=True)])\n",
    "# history = model.fit(train_generator, validation_data=validate_generator, class_weight=class_weights, epochs=num_epoch, callbacks=[EarlyStopping(patience=num_patience, monitor='val_loss', mode='min', verbose=1), TensorBoard(log_dir=fit_result_path2), ModelCheckpoint(filepath=os.path.join(fit_result_path2, 'epoch_{epoch:02d}_valloss_{val_loss:.4f}_valacc_{val_accuracy:.4f}.hdf5' ), verbose=1, monitor=\"val_accuracy\", save_best_only=True)])\n",
    "history = model.fit(train_generator, validation_data=validate_generator, class_weight=class_weights, epochs=num_epoch, callbacks=[EarlyStopping(patience=num_patience, monitor='val_accuracy', mode='max', verbose=1), TensorBoard(log_dir=fit_result_path2), ModelCheckpoint(filepath=os.path.join(fit_result_path2, 'epoch_{epoch:02d}_valloss_{val_loss:.4f}_valacc_{val_accuracy:.4f}.hdf5' ), verbose=1, monitor=\"val_accuracy\", save_best_only=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit_result_path1 = '/home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210210_224527'\n",
    "the_best_model, _ = find_best_model(fit_result_path2, purge=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = load_model(the_best_model)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pred = model.predict(fea_test)\n",
    "# label_pred = model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=200, precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion matrix:\")\n",
    "cm = confusion_matrix(label_test, np.argmax(label_pred, axis=1), labels=species_id)\n",
    "\n",
    "print(species_list)\n",
    "print('')\n",
    "print(cm)\n",
    "print('')\n",
    "\n",
    "cm2 = cm*1.0\n",
    "for ii in range(cm.shape[0]):\n",
    "    cm_row = cm[ii, :]*1.0\n",
    "\n",
    "    cm_row_sum = cm_row.sum()\n",
    "    if cm_row_sum != 0:\n",
    "        cm2[ii, :] = cm_row / cm_row_sum\n",
    "    else:\n",
    "        cm2[ii, :] = np.zeros(cm.shape[1])\n",
    "\n",
    "print(cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics._plot.confusion_matrix import ConfusionMatrixDisplay\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=species_list)\n",
    "disp2 = ConfusionMatrixDisplay(confusion_matrix=cm2, display_labels=species_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[15, 15])\n",
    "disp.plot(include_values=True,\n",
    "                     cmap='viridis', ax=ax, xticks_rotation='horizontal',\n",
    "                     values_format=None, colorbar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[15, 15])\n",
    "disp2.plot(include_values=True,\n",
    "                     cmap='viridis', ax=ax, xticks_rotation='horizontal',\n",
    "                     values_format='.2f', colorbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
