{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training species classifier Expt 3: cross-validation of Oswald data\n",
    "# Feb 23, 2021\n",
    "## The augemented noise is from the all five deployments.\n",
    "## Trained on PICEAS2005 & STAR2000 whereas tested on HICEAS2002, STAR2003 & STAR2006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import permutations\n",
    "import random\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n",
    "import pandas as pd\n",
    "from os import makedirs\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "\n",
    "from math import floor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# from MulticoreTSNE import MulticoreTSNE as TSNE\n",
    "# from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout, Activation\n",
    "from tensorflow.keras.layers import Conv2D, Lambda, Flatten, MaxPooling2D, Concatenate, LSTM, Reshape, Lambda, ConvLSTM2D, GlobalAveragePooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, GRU\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay, PiecewiseConstantDecay\n",
    "from tensorflow.keras.optimizers import SGD,Adam\n",
    "from tensorflow.keras.losses import binary_crossentropy, CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model\n",
    "# import tensorflow_addons as tfa\n",
    "# import tensorflow_datasets as tfds\n",
    "from tensorflow.math import l2_normalize\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "learning_rate = 1.0e-3\n",
    "conv_dim = 16\n",
    "rnn_dim = 16\n",
    "pool_size = 2\n",
    "pool_stride = 2\n",
    "l2_regu = 0.000\n",
    "drop_rate = 0.2\n",
    "hidden_units = 512\n",
    "fcn_dim = 512\n",
    "\n",
    "# learning_rate = 1.e-4\n",
    "# conv_dim = 64\n",
    "# rnn_dim = 16\n",
    "# pool_size = 2\n",
    "# pool_stride = 2\n",
    "# l2_regu = 0.00\n",
    "# drop_rate = 0.2\n",
    "# # drop_rate = 0.5\n",
    "# hidden_units = 512\n",
    "# fcn_dim = 512\n",
    "\n",
    "num_epoch = 200\n",
    "# batch_size = 128\n",
    "batch_size = 32  # for cnn14+attention\n",
    "\n",
    "num_patience = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_type_dict = {1: 'universal', 2: 'file', 3: 'encounter', 4: 'domain'}\n",
    "# data_type = 2\n",
    "\n",
    "work_path = '/home/ys587/__Data/__whistle/__whislte_30_species'\n",
    "fit_result_path =  os.path.join(work_path, '__fit_result_species')\n",
    "# feature_path = os.path.join(work_path, '__feature_species')\n",
    "feature_path = os.path.join(work_path, '__dataset/20210210')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_dict = {'BD': 0, 'CD': 1, 'STR': 2, 'SPT': 3, 'SPIN': 4, 'PLT': 5, 'RT': 6,  'FKW': 7}\n",
    "num_species = len(species_dict)\n",
    "# species_dict = {'BD': 0, 'MH': 1, 'CD': 2, 'STR': 3, 'SPT': 4, 'SPIN': 5, 'PLT': 6, 'RD': 7, 'RT': 8,\n",
    "#                 'WSD': 9, 'FKW': 10, 'BEL': 11, 'KW': 12, 'WBD': 13, 'DUSK': 14, 'FRA': 15, 'PKW': 16, 'LPLT': 17,\n",
    "#                 'CLY': 18, 'SPE': 19, 'ASP': 20}\n",
    "species_list = list(species_dict.keys())\n",
    "species_id = list(species_dict.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment = ['STAR2000', 'STAR2003', 'STAR2006', 'HICEAS2002', 'PICEAS2005']  # oswald_STAR2000_orig.npz, oswald_STAR2000_aug.npz\n",
    "# feature_path = '/home/ys587/__Data/__whistle/__whislte_30_species/__dataset/20210223_augment_all_three_noise_mixed'\n",
    "feature_path = '/home/ys587/__Data/__whistle/__whislte_30_species/__dataset/20210223_augment_all_three_noise_mixed_class_balanced_min_5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STAR2000\n",
      "oswald_STAR2003_orig.npz\n",
      "['feas_orig', 'labels_orig']\n",
      "(1770, 101, 128)\n",
      "(1770,)\n",
      "oswald_STAR2003_aug.npz\n",
      "['feas_aug', 'labels_aug']\n",
      "(14078, 101, 128)\n",
      "(14078,)\n",
      "oswald_STAR2006_orig.npz\n",
      "['feas_orig', 'labels_orig']\n",
      "(16582, 101, 128)\n",
      "(16582,)\n",
      "oswald_STAR2006_aug.npz\n",
      "['feas_aug', 'labels_aug']\n",
      "(32950, 101, 128)\n",
      "(32950,)\n",
      "oswald_HICEAS2002_orig.npz\n",
      "['feas_orig', 'labels_orig']\n",
      "(35479, 101, 128)\n",
      "(35479,)\n",
      "oswald_HICEAS2002_aug.npz\n",
      "['feas_aug', 'labels_aug']\n",
      "(52870, 101, 128)\n",
      "(52870,)\n",
      "oswald_PICEAS2005_orig.npz\n",
      "['feas_orig', 'labels_orig']\n",
      "(58386, 101, 128)\n",
      "(58386,)\n",
      "oswald_PICEAS2005_aug.npz\n",
      "['feas_aug', 'labels_aug']\n",
      "(96966, 101, 128)\n",
      "(96966,)\n",
      "(96966, 101, 128)\n",
      "(96966,)\n",
      "\n",
      "STAR2003\n",
      "oswald_STAR2000_orig.npz\n",
      "['feas_orig', 'labels_orig']\n",
      "(6668, 101, 128)\n",
      "(6668,)\n",
      "oswald_STAR2000_aug.npz\n",
      "['feas_aug', 'labels_aug']\n",
      "(52780, 101, 128)\n",
      "(52780,)\n",
      "oswald_STAR2006_orig.npz\n",
      "['feas_orig', 'labels_orig']\n",
      "(55284, 101, 128)\n",
      "(55284,)\n",
      "oswald_STAR2006_aug.npz\n",
      "['feas_aug', 'labels_aug']\n",
      "(71652, 101, 128)\n",
      "(71652,)\n",
      "oswald_HICEAS2002_orig.npz\n",
      "['feas_orig', 'labels_orig']\n",
      "(74181, 101, 128)\n",
      "(74181,)\n",
      "oswald_HICEAS2002_aug.npz\n",
      "['feas_aug', 'labels_aug']\n",
      "(91572, 101, 128)\n",
      "(91572,)\n",
      "oswald_PICEAS2005_orig.npz\n",
      "['feas_orig', 'labels_orig']\n",
      "(97088, 101, 128)\n",
      "(97088,)\n",
      "oswald_PICEAS2005_aug.npz\n",
      "['feas_aug', 'labels_aug']\n",
      "(135668, 101, 128)\n",
      "(135668,)\n",
      "(135668, 101, 128)\n",
      "(135668,)\n",
      "\n",
      "STAR2006\n",
      "oswald_STAR2000_orig.npz\n",
      "['feas_orig', 'labels_orig']\n",
      "(6668, 101, 128)\n",
      "(6668,)\n",
      "oswald_STAR2000_aug.npz\n",
      "['feas_aug', 'labels_aug']\n",
      "(52780, 101, 128)\n",
      "(52780,)\n",
      "oswald_STAR2003_orig.npz\n",
      "['feas_orig', 'labels_orig']\n",
      "(54550, 101, 128)\n",
      "(54550,)\n",
      "oswald_STAR2003_aug.npz\n",
      "['feas_aug', 'labels_aug']\n",
      "(66858, 101, 128)\n",
      "(66858,)\n",
      "oswald_HICEAS2002_orig.npz\n",
      "['feas_orig', 'labels_orig']\n",
      "(69387, 101, 128)\n",
      "(69387,)\n",
      "oswald_HICEAS2002_aug.npz\n",
      "['feas_aug', 'labels_aug']\n",
      "(86778, 101, 128)\n",
      "(86778,)\n",
      "oswald_PICEAS2005_orig.npz\n",
      "['feas_orig', 'labels_orig']\n",
      "(92294, 101, 128)\n",
      "(92294,)\n",
      "oswald_PICEAS2005_aug.npz\n",
      "['feas_aug', 'labels_aug']\n",
      "(130874, 101, 128)\n",
      "(130874,)\n",
      "(130874, 101, 128)\n",
      "(130874,)\n",
      "\n",
      "HICEAS2002\n",
      "oswald_STAR2000_orig.npz\n",
      "['feas_orig', 'labels_orig']\n",
      "(6668, 101, 128)\n",
      "(6668,)\n",
      "oswald_STAR2000_aug.npz\n",
      "['feas_aug', 'labels_aug']\n",
      "(52780, 101, 128)\n",
      "(52780,)\n",
      "oswald_STAR2003_orig.npz\n",
      "['feas_orig', 'labels_orig']\n",
      "(54550, 101, 128)\n",
      "(54550,)\n",
      "oswald_STAR2003_aug.npz\n",
      "['feas_aug', 'labels_aug']\n",
      "(66858, 101, 128)\n",
      "(66858,)\n",
      "oswald_STAR2006_orig.npz\n",
      "['feas_orig', 'labels_orig']\n",
      "(69362, 101, 128)\n",
      "(69362,)\n",
      "oswald_STAR2006_aug.npz\n",
      "['feas_aug', 'labels_aug']\n",
      "(85730, 101, 128)\n",
      "(85730,)\n",
      "oswald_PICEAS2005_orig.npz\n",
      "['feas_orig', 'labels_orig']\n",
      "(91246, 101, 128)\n",
      "(91246,)\n",
      "oswald_PICEAS2005_aug.npz\n",
      "['feas_aug', 'labels_aug']\n",
      "(129826, 101, 128)\n",
      "(129826,)\n",
      "(129826, 101, 128)\n",
      "(129826,)\n",
      "\n",
      "PICEAS2005\n",
      "oswald_STAR2000_orig.npz\n",
      "['feas_orig', 'labels_orig']\n",
      "(6668, 101, 128)\n",
      "(6668,)\n",
      "oswald_STAR2000_aug.npz\n",
      "['feas_aug', 'labels_aug']\n",
      "(52780, 101, 128)\n",
      "(52780,)\n",
      "oswald_STAR2003_orig.npz\n",
      "['feas_orig', 'labels_orig']\n",
      "(54550, 101, 128)\n",
      "(54550,)\n",
      "oswald_STAR2003_aug.npz\n",
      "['feas_aug', 'labels_aug']\n",
      "(66858, 101, 128)\n",
      "(66858,)\n",
      "oswald_STAR2006_orig.npz\n",
      "['feas_orig', 'labels_orig']\n",
      "(69362, 101, 128)\n",
      "(69362,)\n",
      "oswald_STAR2006_aug.npz\n",
      "['feas_aug', 'labels_aug']\n",
      "(85730, 101, 128)\n",
      "(85730,)\n",
      "oswald_HICEAS2002_orig.npz\n",
      "['feas_orig', 'labels_orig']\n",
      "(88259, 101, 128)\n",
      "(88259,)\n",
      "oswald_HICEAS2002_aug.npz\n",
      "['feas_aug', 'labels_aug']\n",
      "(105650, 101, 128)\n",
      "(105650,)\n",
      "(105650, 101, 128)\n",
      "(105650,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    for ee in deployment:\n",
    "        print(ee)\n",
    "        ee_others = [ee2 for ee2 in deployment if (ee2 != ee) ]\n",
    "        fea_train_files_tot = []\n",
    "        for ee2 in ee_others:\n",
    "            fea_train_files_tot.append('oswald_'+ee2+'_orig.npz')\n",
    "            fea_train_files_tot.append('oswald_'+ee2+'_aug.npz')\n",
    "\n",
    "        # Training data\n",
    "        fea_train_list = []\n",
    "        label_train_list = []\n",
    "        for ii in range(len(fea_train_files_tot)):\n",
    "            ff = fea_train_files_tot[ii]\n",
    "            print(ff)\n",
    "            fea_temp = np.load(os.path.join(feature_path, ff))\n",
    "            print(fea_temp.files)\n",
    "\n",
    "            if ii == 0:\n",
    "                fea_train = fea_temp['feas_orig']\n",
    "                label_train = fea_temp['labels_orig']\n",
    "                print(fea_train.shape)\n",
    "                print(label_train.shape)\n",
    "            elif ii % 2 == 0:  # even\n",
    "                fea_train = np.concatenate([fea_train, fea_temp['feas_orig']])\n",
    "                label_train = np.concatenate([label_train, fea_temp['labels_orig']])\n",
    "                print(fea_train.shape)\n",
    "                print(label_train.shape)\n",
    "            else:\n",
    "                fea_train = np.concatenate([fea_train, fea_temp['feas_aug']])\n",
    "                label_train = np.concatenate([label_train, fea_temp['labels_aug']])\n",
    "                print(fea_train.shape)\n",
    "                print(label_train.shape)\n",
    "        print(fea_train.shape)\n",
    "        print(label_train.shape)\n",
    "        np.savez(os.path.join(feature_path, './train_oswald_no_'+ee+'.npz'), fea_train=fea_train, label_train=label_train)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data generator\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, feature, label, batch_size=32, num_classes=None, shuffle=True):\n",
    "        self.batch_size = batch_size\n",
    "        self.X = feature\n",
    "        self.X_dim = len(feature.shape)\n",
    "        self.y = to_categorical(label, num_classes)\n",
    "        self.indices = np.arange(self.y.shape[0])\n",
    "        self.num_classes = num_classes\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        # self.index = np.arange(len(self.indices))\n",
    "        #self.df = dataframe\n",
    "        #self.indices = self.df.index.tolist()        \n",
    "        # self.x_col = x_col\n",
    "        # self.y_col = y_col\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(floor(len(self.indices)/self.batch_size))\n",
    "        # return label.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # index = self.index[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        # batch = [self.indices[k] for k in index]\n",
    "        batch = list(range(index*self.batch_size, (index+1)*self.batch_size))\n",
    "        \n",
    "        X, y = self.__get_data(batch)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "    def __get_data(self, batch):\n",
    "        y = np.zeros((self.batch_size, self.y.shape[1]))\n",
    "        \n",
    "        if self.X_dim == 3:\n",
    "            X = np.zeros((self.batch_size, self.X.shape[1], self.X.shape[2]))\n",
    "            for i, id in enumerate(batch):\n",
    "                X[i,:, :] = self.X[id, :, :]  # logic\n",
    "                y[i, :] = self.y[id, :] # labels\n",
    "                \n",
    "        elif self.X_dim == 4:\n",
    "            X = np.zeros((self.batch_size, self.X.shape[1], self.X.shape[2], self.X.shape[3]))\n",
    "            for i, id in enumerate(batch):\n",
    "                X[i,:, :, :] = self.X[id, :, :, :]  # logic\n",
    "                y[i, :] = self.y[id, :] # labels\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kong's attention\n",
    "# def max_pooling(inputs, **kwargs):\n",
    "#     input = inputs[0]   # (batch_size, time_steps, freq_bins)\n",
    "#     return K.max(input, axis=1)\n",
    "def max_pooling(inputs, **kwargs):\n",
    "    # input = inputs[0]   # (batch_size, time_steps, freq_bins)\n",
    "    return K.max(inputs, axis=1)\n",
    "\n",
    "\n",
    "def average_pooling(inputs, **kwargs):\n",
    "    input = inputs[0]   # (batch_size, time_steps, freq_bins)\n",
    "    return K.mean(input, axis=1)\n",
    "\n",
    "\n",
    "def attention_pooling(inputs, **kwargs):\n",
    "    [out, att] = inputs\n",
    "\n",
    "    epsilon = 1e-7\n",
    "    att = K.clip(att, epsilon, 1. - epsilon)\n",
    "    normalized_att = att / K.sum(att, axis=1)[:, None, :]\n",
    "\n",
    "    return K.sum(out * normalized_att, axis=1)\n",
    "\n",
    "\n",
    "def pooling_shape(input_shape):\n",
    "\n",
    "    if isinstance(input_shape, list):\n",
    "        (sample_num, time_steps, freq_bins) = input_shape[0]\n",
    "\n",
    "    else:\n",
    "        (sample_num, time_steps, freq_bins) = input_shape\n",
    "\n",
    "    return (sample_num, freq_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn14 attention with customized maxpooling\n",
    "def model_cnn14_attention_multi(time_steps, freq_bins, classes_num, model_type='feature_level_attention', conv_dim=64, rnn_dim=128, pool_size=2, pool_stride=2, hidden_units=512, l2_regu=0., drop_rate=0., multilabel=True):\n",
    "    # Kong's attention\n",
    "    # model_type = 'decision_level_max_pooling'  # problem with dimensions of the Lambda layer after training\n",
    "    # model_type = 'decision_level_average_pooling' # problem with dimensions of the Lambda layer after training\n",
    "    # model_type = 'decision_level_single_attention'\n",
    "    # model_type = 'decision_level_multi_attention'\n",
    "    # model_type = 'feature_level_attention'\n",
    "\n",
    "    input_layer = Input(shape=(time_steps, freq_bins, 1), name='input')\n",
    "    # group 1\n",
    "    y = Conv2D(conv_dim, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(input_layer)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = Conv2D(conv_dim, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = MaxPooling2D(pool_size=(pool_size, 2), strides=(pool_stride, 2), padding='same')(y)\n",
    "    y = Dropout(drop_rate)(y)\n",
    "    \n",
    "    # group 2\n",
    "    y = Conv2D(conv_dim*2, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = Conv2D(conv_dim*2, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = MaxPooling2D(pool_size=(pool_size, 2), strides=(pool_stride, 2), padding='same')(y)\n",
    "    y = Dropout(drop_rate)(y)\n",
    "    \n",
    "    # group 3\n",
    "    y = Conv2D(conv_dim*4, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = Conv2D(conv_dim*4, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = MaxPooling2D(pool_size=(pool_size, 2), strides=(pool_stride, 2), padding='same')(y)\n",
    "    y = Dropout(drop_rate)(y)\n",
    "    \n",
    "    # group 4 \n",
    "    y = Conv2D(conv_dim*8, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = Conv2D(conv_dim*8, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = MaxPooling2D(pool_size=(pool_size, 2), strides=(pool_stride, 2), padding='same')(y)\n",
    "    y = Dropout(drop_rate)(y)\n",
    "\n",
    "    # group 5\n",
    "    y = Conv2D(conv_dim*16, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = Conv2D(conv_dim*16, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = MaxPooling2D(pool_size=(pool_size, 2), strides=(1, 2), padding='same')(y)\n",
    "    y = Dropout(drop_rate)(y)\n",
    "\n",
    "    # group 6\n",
    "    y = Conv2D(conv_dim*32, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = Conv2D(conv_dim*32, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = MaxPooling2D(pool_size=(pool_size, 2), strides=(1, 2), padding='same')(y)\n",
    "    y = Dropout(drop_rate)(y)\n",
    "    \n",
    "    # change dimensions: samples, time, frequency, channels => samples, time, frequency*channels\n",
    "    dim_cnn = K.int_shape(y)\n",
    "    y = Reshape((dim_cnn[1], dim_cnn[2]*dim_cnn[3]))(y)\n",
    "\n",
    "    a1 = Dense(hidden_units)(y)\n",
    "    a1 = BatchNormalization()(a1)\n",
    "    a1 = Activation('relu')(a1)\n",
    "    a1 = Dropout(drop_rate)(a1)\n",
    "\n",
    "    a2 = Dense(hidden_units)(a1)\n",
    "    a2 = BatchNormalization()(a2)\n",
    "    a2 = Activation('relu')(a2)\n",
    "    a2 = Dropout(drop_rate)(a2)\n",
    "\n",
    "    a3 = Dense(hidden_units)(a2)\n",
    "    a3 = BatchNormalization()(a3)\n",
    "    a3 = Activation('relu')(a3)\n",
    "    a3 = Dropout(drop_rate)(a3)\n",
    "\n",
    "    # Pooling layers\n",
    "    if model_type == 'decision_level_max_pooling':\n",
    "        '''Global max pooling.\n",
    "\n",
    "        [1] Choi, Keunwoo, et al. \"Automatic tagging using deep convolutional \n",
    "        neural networks.\" arXiv preprint arXiv:1606.00298 (2016).\n",
    "        '''\n",
    "        cla = Dense(classes_num, activation='sigmoid')(a3)\n",
    "        \n",
    "        # output_layer = Lambda(\n",
    "        #    max_pooling, \n",
    "        #    output_shape=pooling_shape)(\n",
    "        #    [cla])\n",
    "        output_layer = Lambda(max_pooling)(cla)\n",
    "\n",
    "    elif model_type == 'decision_level_average_pooling':\n",
    "        '''Global average pooling.\n",
    "\n",
    "        [2] Lin, Min, et al. Qiang Chen, and Shuicheng Yan. \"Network in \n",
    "        network.\" arXiv preprint arXiv:1312.4400 (2013).\n",
    "        '''\n",
    "        cla = Dense(classes_num, activation='sigmoid')(a3)\n",
    "        # output_layer = Lambda(\n",
    "        #    average_pooling,\n",
    "        #    output_shape=pooling_shape)(\n",
    "        #    [cla])\n",
    "        output_layer = Lambda(average_pooling)(cla)\n",
    "\n",
    "    elif model_type == 'decision_level_single_attention':\n",
    "        '''Decision level single attention pooling.\n",
    "        [3] Kong, Qiuqiang, et al. \"Audio Set classification with attention\n",
    "        model: A probabilistic perspective.\" arXiv preprint arXiv:1711.00927\n",
    "        (2017).\n",
    "        '''\n",
    "        cla = Dense(classes_num, activation='sigmoid')(a3)\n",
    "        att = Dense(classes_num, activation='softmax')(a3)\n",
    "        output_layer = Lambda(\n",
    "            attention_pooling, output_shape=pooling_shape)([cla, att])\n",
    "\n",
    "    elif model_type == 'decision_level_multi_attention':\n",
    "        '''Decision level multi attention pooling.\n",
    "        [4] Yu, Changsong, et al. \"Multi-level Attention Model for Weakly\n",
    "        Supervised Audio Classification.\" arXiv preprint arXiv:1803.02353\n",
    "        (2018).\n",
    "        '''\n",
    "        cla1 = Dense(classes_num, activation='sigmoid')(a2)\n",
    "        att1 = Dense(classes_num, activation='softmax')(a2)\n",
    "        out1 = Lambda(\n",
    "            attention_pooling, output_shape=pooling_shape)([cla1, att1])\n",
    "\n",
    "        cla2 = Dense(classes_num, activation='sigmoid')(a3)\n",
    "        att2 = Dense(classes_num, activation='softmax')(a3)\n",
    "        out2 = Lambda(\n",
    "            attention_pooling, output_shape=pooling_shape)([cla2, att2])\n",
    "\n",
    "        b1 = Concatenate(axis=-1)([out1, out2])\n",
    "        b1 = Dense(classes_num)(b1)\n",
    "        \n",
    "        if multilabel:\n",
    "            output_layer = Activation('sigmoid')(b1)\n",
    "        else:\n",
    "            output_layer = Activation('softmax')(b1)\n",
    "\n",
    "    elif model_type == 'feature_level_attention':\n",
    "        '''Feature level attention.\n",
    "        [1] Kong, Qiuqiang, et al. \"Weakly labelled audioset tagging with \n",
    "        attention neural networks.\" (2019).\n",
    "        '''\n",
    "        cla = Dense(hidden_units, activation='linear')(a3)\n",
    "        att = Dense(hidden_units, activation='sigmoid')(a3)\n",
    "        b1 = Lambda(\n",
    "            attention_pooling, output_shape=pooling_shape)([cla, att])\n",
    "\n",
    "        b1 = BatchNormalization()(b1)\n",
    "        b1 = Activation(activation='relu')(b1)\n",
    "        b1 = Dropout(drop_rate)(b1)\n",
    "        \n",
    "        if multilabel:\n",
    "            output_layer = Dense(classes_num, activation='sigmoid')(b1)\n",
    "        else:\n",
    "            output_layer = Dense(classes_num, activation='softmax')(b1)\n",
    "\n",
    "    else:\n",
    "        raise Exception(\"Incorrect model_type!\")\n",
    "\n",
    "    # Build model\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn14 attention\n",
    "def model_cnn14_attention(time_steps, freq_bins, classes_num, model_type='feature_level_attention', conv_dim=64, rnn_dim=128, pool_size=2, pool_stride=2, hidden_units=512, l2_regu=0., drop_rate=0., multilabel=True):\n",
    "    # Kong's attention\n",
    "    # model_type = 'decision_level_max_pooling'  # problem with dimensions of the Lambda layer after training\n",
    "    # model_type = 'decision_level_average_pooling' # problem with dimensions of the Lambda layer after training\n",
    "    # model_type = 'decision_level_single_attention'\n",
    "    # model_type = 'decision_level_multi_attention'\n",
    "    # model_type = 'feature_level_attention'\n",
    "\n",
    "    input_layer = Input(shape=(time_steps, freq_bins, 1), name='input')\n",
    "    # group 1\n",
    "    y = Conv2D(conv_dim, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(input_layer)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = Conv2D(conv_dim, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = MaxPooling2D(pool_size=(pool_size, 2), strides=(pool_stride, 2), padding='same')(y)\n",
    "    y = Dropout(drop_rate)(y)\n",
    "    \n",
    "    # group 2\n",
    "    y = Conv2D(conv_dim*2, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = Conv2D(conv_dim*2, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = MaxPooling2D(pool_size=(pool_size, 2), strides=(pool_stride, 2), padding='same')(y)\n",
    "    y = Dropout(drop_rate)(y)\n",
    "    \n",
    "    # group 3\n",
    "    y = Conv2D(conv_dim*4, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = Conv2D(conv_dim*4, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = MaxPooling2D(pool_size=(pool_size, 2), strides=(pool_stride, 2), padding='same')(y)\n",
    "    y = Dropout(drop_rate)(y)\n",
    "    \n",
    "    # group 4 \n",
    "    y = Conv2D(conv_dim*8, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = Conv2D(conv_dim*8, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = MaxPooling2D(pool_size=(pool_size, 2), strides=(pool_stride, 2), padding='same')(y)\n",
    "    y = Dropout(drop_rate)(y)\n",
    "\n",
    "    # group 5\n",
    "    y = Conv2D(conv_dim*16, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = Conv2D(conv_dim*16, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = MaxPooling2D(pool_size=(pool_size, 2), strides=(pool_stride, 2), padding='same')(y)\n",
    "    y = Dropout(drop_rate)(y)\n",
    "\n",
    "    # group 6\n",
    "    y = Conv2D(conv_dim*32, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = Conv2D(conv_dim*32, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = MaxPooling2D(pool_size=(pool_size, 2), strides=(pool_stride, 2), padding='same')(y)\n",
    "    y = Dropout(drop_rate)(y)\n",
    "    \n",
    "    # change dimensions: samples, time, frequency, channels => samples, time, frequency*channels\n",
    "    dim_cnn = K.int_shape(y)\n",
    "    y = Reshape((dim_cnn[1], dim_cnn[2]*dim_cnn[3]))(y)\n",
    "\n",
    "    a1 = Dense(hidden_units)(y)\n",
    "    a1 = BatchNormalization()(a1)\n",
    "    a1 = Activation('relu')(a1)\n",
    "    a1 = Dropout(drop_rate)(a1)\n",
    "\n",
    "    a2 = Dense(hidden_units)(a1)\n",
    "    a2 = BatchNormalization()(a2)\n",
    "    a2 = Activation('relu')(a2)\n",
    "    a2 = Dropout(drop_rate)(a2)\n",
    "\n",
    "    a3 = Dense(hidden_units)(a2)\n",
    "    a3 = BatchNormalization()(a3)\n",
    "    a3 = Activation('relu')(a3)\n",
    "    a3 = Dropout(drop_rate)(a3)\n",
    "\n",
    "    # Pooling layers\n",
    "    if model_type == 'decision_level_max_pooling':\n",
    "        '''Global max pooling.\n",
    "\n",
    "        [1] Choi, Keunwoo, et al. \"Automatic tagging using deep convolutional \n",
    "        neural networks.\" arXiv preprint arXiv:1606.00298 (2016).\n",
    "        '''\n",
    "        cla = Dense(classes_num, activation='sigmoid')(a3)\n",
    "        \n",
    "        # output_layer = Lambda(\n",
    "        #    max_pooling, \n",
    "        #    output_shape=pooling_shape)(\n",
    "        #    [cla])\n",
    "        output_layer = Lambda(max_pooling)(cla)\n",
    "\n",
    "    elif model_type == 'decision_level_average_pooling':\n",
    "        '''Global average pooling.\n",
    "\n",
    "        [2] Lin, Min, et al. Qiang Chen, and Shuicheng Yan. \"Network in \n",
    "        network.\" arXiv preprint arXiv:1312.4400 (2013).\n",
    "        '''\n",
    "        cla = Dense(classes_num, activation='sigmoid')(a3)\n",
    "        # output_layer = Lambda(\n",
    "        #    average_pooling,\n",
    "        #    output_shape=pooling_shape)(\n",
    "        #    [cla])\n",
    "        output_layer = Lambda(average_pooling)(cla)\n",
    "\n",
    "    elif model_type == 'decision_level_single_attention':\n",
    "        '''Decision level single attention pooling.\n",
    "        [3] Kong, Qiuqiang, et al. \"Audio Set classification with attention\n",
    "        model: A probabilistic perspective.\" arXiv preprint arXiv:1711.00927\n",
    "        (2017).\n",
    "        '''\n",
    "        cla = Dense(classes_num, activation='sigmoid')(a3)\n",
    "        att = Dense(classes_num, activation='softmax')(a3)\n",
    "        output_layer = Lambda(\n",
    "            attention_pooling, output_shape=pooling_shape)([cla, att])\n",
    "\n",
    "    elif model_type == 'decision_level_multi_attention':\n",
    "        '''Decision level multi attention pooling.\n",
    "        [4] Yu, Changsong, et al. \"Multi-level Attention Model for Weakly\n",
    "        Supervised Audio Classification.\" arXiv preprint arXiv:1803.02353\n",
    "        (2018).\n",
    "        '''\n",
    "        cla1 = Dense(classes_num, activation='sigmoid')(a2)\n",
    "        att1 = Dense(classes_num, activation='softmax')(a2)\n",
    "        out1 = Lambda(\n",
    "            attention_pooling, output_shape=pooling_shape)([cla1, att1])\n",
    "\n",
    "        cla2 = Dense(classes_num, activation='sigmoid')(a3)\n",
    "        att2 = Dense(classes_num, activation='softmax')(a3)\n",
    "        out2 = Lambda(\n",
    "            attention_pooling, output_shape=pooling_shape)([cla2, att2])\n",
    "\n",
    "        b1 = Concatenate(axis=-1)([out1, out2])\n",
    "        b1 = Dense(classes_num)(b1)\n",
    "        \n",
    "        if multilabel:\n",
    "            output_layer = Activation('sigmoid')(b1)\n",
    "        else:\n",
    "            output_layer = Activation('softmax')(b1)\n",
    "\n",
    "    elif model_type == 'feature_level_attention':\n",
    "        '''Feature level attention.\n",
    "        [1] Kong, Qiuqiang, et al. \"Weakly labelled audioset tagging with \n",
    "        attention neural networks.\" (2019).\n",
    "        '''\n",
    "        cla = Dense(hidden_units, activation='linear')(a3)\n",
    "        att = Dense(hidden_units, activation='sigmoid')(a3)\n",
    "        b1 = Lambda(\n",
    "            attention_pooling, output_shape=pooling_shape)([cla, att])\n",
    "\n",
    "        b1 = BatchNormalization()(b1)\n",
    "        b1 = Activation(activation='relu')(b1)\n",
    "        b1 = Dropout(drop_rate)(b1)\n",
    "        \n",
    "        if multilabel:\n",
    "            output_layer = Dense(classes_num, activation='sigmoid')(b1)\n",
    "        else:\n",
    "            output_layer = Dense(classes_num, activation='softmax')(b1)\n",
    "\n",
    "    else:\n",
    "        raise Exception(\"Incorrect model_type!\")\n",
    "\n",
    "    # Build model\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_cnn14(time_steps, freq_bins, classes_num, pool_size=2, pool_stride=2, conv_dim=16, fcn_dim=512, l2_regu=0., drop_rate=0.):\n",
    "    # input\n",
    "    input_layer = Input(shape=(time_steps, freq_bins, 1), name='input')\n",
    "    \n",
    "    # group 1\n",
    "    y = Conv2D(conv_dim, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(input_layer)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = Conv2D(conv_dim, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')(y)\n",
    "    y = Dropout(drop_rate)(y)\n",
    "    \n",
    "    # group 2\n",
    "    y = Conv2D(conv_dim*2, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = Conv2D(conv_dim*2, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')(y)\n",
    "    y = Dropout(drop_rate)(y)\n",
    "    \n",
    "    # group 3\n",
    "    y = Conv2D(conv_dim*4, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = Conv2D(conv_dim*4, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')(y)\n",
    "    y = Dropout(drop_rate)(y)\n",
    "    \n",
    "    # group 4 \n",
    "    y = Conv2D(conv_dim*8, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = Conv2D(conv_dim*8, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')(y)\n",
    "    y = Dropout(drop_rate)(y)\n",
    "\n",
    "    # group 5\n",
    "    y = Conv2D(conv_dim*16, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = Conv2D(conv_dim*16, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')(y)\n",
    "    y = Dropout(drop_rate)(y)\n",
    "\n",
    "    # group 6\n",
    "    y = Conv2D(conv_dim*32, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    y = Conv2D(conv_dim*32, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(l2_regu))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation(activation='relu')(y)\n",
    "    \n",
    "    y = GlobalMaxPooling2D()(y)\n",
    "    \n",
    "    # FC block\n",
    "    y = Dense(fcn_dim, activation='relu', name='cnn14_fcn')(y)  # original 512\n",
    "    x = Dense(classes_num, activation='softmax')(y)\n",
    "    \n",
    "    # Build model\n",
    "    model = Model(inputs=input_layer, outputs=x)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model compile, class weight & fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_best_model(model_folder, remove_others=False):\n",
    "#     model_list = glob.glob(model_folder+'/*.hdf5')\n",
    "#     model_list.sort()\n",
    "#     the_best_model = model_list[-1]\n",
    "    \n",
    "#     if remove_others==True:\n",
    "#         for mm in model_list[:-1]:\n",
    "#             os.remove(mm)\n",
    "            \n",
    "#     print(the_best_model)\n",
    "    \n",
    "#     return the_best_model\n",
    "import re\n",
    "\n",
    "def find_best_model(classifier_path, fmt='epoch_\\d+_valloss_(\\d+.\\d{4})_valacc_\\d+.\\d{4}.hdf5', is_max=False, purge=True):\n",
    "    \"\"\"\n",
    "    Return the path to the model with the best accuracy, given the path to\n",
    "    all the trained classifiers\n",
    "    Args:\n",
    "        classifier_path: path to all the trained classifiers\n",
    "        fmt: e.g. \"epoch_\\d+_[0-1].\\d+_(\\d+.\\d{4}).hdf5\"\n",
    "        'epoch_\\d+_valloss_(\\d+.\\d{4})_valacc_\\d+.\\d{4}.hdf5'\n",
    "        is_max: use max; otherwise, min\n",
    "        purge: True to purge models files except the best one\n",
    "    Return:\n",
    "        the path of the model with the best accuracy\n",
    "    \"\"\"\n",
    "    # list all files ending with .hdf5\n",
    "    day_list = sorted(glob.glob(os.path.join(classifier_path + '/', '*.hdf5')))\n",
    "\n",
    "    # re the last 4 digits for accuracy\n",
    "    hdf5_filename = []\n",
    "    hdf5_accu = np.zeros(len(day_list))\n",
    "    for dd in range(len(day_list)):\n",
    "        filename = os.path.basename(day_list[dd])\n",
    "        hdf5_filename.append(filename)\n",
    "        # m = re.search(\"_F1_(0.\\d{4}).hdf5\", filename)\n",
    "        # m = re.search(\"_([0-1].\\d{4}).hdf5\", filename)\n",
    "        # m = re.search(\"epoch_\\d+_[0-1].\\d+_(\\d+.\\d{4}).hdf5\", filename)\n",
    "        m = re.search(fmt, filename)\n",
    "        try:\n",
    "            hdf5_accu[dd] = float(m.groups()[0])\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    # select the laregest one and write to the variable classifier_file\n",
    "    if len(hdf5_accu) == 0:\n",
    "        best_model_path = ''\n",
    "        best_accu = 0\n",
    "    else:\n",
    "        if is_max is True:\n",
    "            ind_max = np.argmax(hdf5_accu)\n",
    "        else: # use min instead\n",
    "            ind_max = np.argmin(hdf5_accu)\n",
    "        best_model_path = day_list[int(ind_max)]\n",
    "        best_accu = hdf5_accu[ind_max]\n",
    "        # purge all model files except the best_model\n",
    "        if purge:\n",
    "            for ff in day_list:\n",
    "                if ff != best_model_path:\n",
    "                    os.remove(ff)\n",
    "    print('Best model:'+str(best_accu))\n",
    "    print(best_model_path)\n",
    "    return best_model_path, best_accu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### cnn4 + attention\n",
    "# model = model_cnn_attention(dim_time, dim_freq, num_species, model_type='decision_level_max_pooling', conv_dim=conv_dim, l2_regu=l2_regu, drop_rate=drop_rate)\n",
    "# model = model_cnn_attention(dim_time, dim_freq, num_species, model_type='decision_level_multi_attention', conv_dim=conv_dim, l2_regu=l2_regu, drop_rate=drop_rate)\n",
    "# model = model_cnn_attention(dim_time, dim_freq, num_species, model_type='feature_level_attention', conv_dim=conv_dim, l2_regu=l2_regu, drop_rate=drop_rate)\n",
    "\n",
    "# vggish\n",
    "# model = model_vggish(dim_time, dim_freq, num_species, conv_dim=conv_dim, fcn_dim=fcn_dim)\n",
    "\n",
    "# cnn10\n",
    "# model = model_cnn10(dim_time, dim_freq, num_species, conv_dim=conv_dim, fcn_dim=fcn_dim, l2_regu=l2_regu, drop_rate=drop_rate)\n",
    "\n",
    "# cnn14\n",
    "# model = model_cnn14(dim_time, dim_freq, num_species, conv_dim=conv_dim, fcn_dim=fcn_dim, l2_regu=l2_regu, drop_rate=drop_rate)\n",
    "\n",
    "# cnn14 attention\n",
    "# model = model_cnn14_attention(dim_time, dim_freq, num_species, model_type='feature_level_attention', conv_dim=conv_dim, pool_size=pool_size, pool_stride=pool_stride, hidden_units=hidden_units, l2_regu=l2_regu, drop_rate=drop_rate)\n",
    "# model = model_cnn14_bigru_attention(dim_time, dim_freq, num_species, model_type='feature_level_attention', conv_dim=conv_dim, rnn_dim=rnn_dim, hidden_units=hidden_units, l2_regu=l2_regu, drop_rate=drop_rate)\n",
    "\n",
    "# model = model_cnn14_attention_multi(dim_time, dim_freq, num_species, model_type='feature_level_attention', conv_dim=conv_dim, pool_size=pool_size, pool_stride=pool_stride, hidden_units=hidden_units, l2_regu=l2_regu, drop_rate=drop_rate)\n",
    "# loss = CategoricalCrossentropy()\n",
    "# model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss=loss, metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundaries = [20, 40]\n",
    "values = [1.0e-3, 3.33e-4, 1.0e-4]\n",
    "learning_rate_fn = PiecewiseConstantDecay(boundaries, values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.now()\n",
    "# create a folder based on date & time\n",
    "fit_result_path1 = os.path.join(fit_result_path, today.strftime('%Y%m%d_%H%M%S'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STAR2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STAR2000\n"
     ]
    }
   ],
   "source": [
    "ee = deployment[0]\n",
    "print(ee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "fea_temp = np.load(os.path.join(feature_path, 'train_oswald_no_'+ee+'.npz'))\n",
    "fea_train = fea_temp['fea_train']\n",
    "label_train_list = fea_temp['label_train']\n",
    "del fea_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train = np.zeros(len(label_train_list))\n",
    "for ii in range(len(label_train_list)):\n",
    "    label_train[ii] = species_dict[label_train_list[ii]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing data\n",
    "fea_temp = np.load(os.path.join(feature_path, 'oswald_'+ee+'_orig.npz'))\n",
    "fea_test = fea_temp['feas_orig']\n",
    "label_test_list = fea_temp['labels_orig']\n",
    "\n",
    "fea_test = fea_test[:,:100,:]\n",
    "label_test = np.zeros(len(label_test_list))\n",
    "for ii in range(len(label_test_list)):\n",
    "    label_test[ii] = species_dict[label_test_list[ii]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_train = fea_train[:,:100,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train = np.zeros(len(label_train_list))\n",
    "for ii in range(len(label_train_list)):\n",
    "    label_train[ii] = species_dict[label_train_list[ii]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'BD': 15028,\n",
       "         'CD': 4848,\n",
       "         'FKW': 20160,\n",
       "         'SPIN': 5734,\n",
       "         'SPT': 13436,\n",
       "         'STR': 12528,\n",
       "         'PLT': 14288,\n",
       "         'RT': 10944})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(label_train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0.0: 121, 1.0: 3964, 5.0: 31, 6.0: 76, 4.0: 491, 3.0: 845, 2.0: 1140})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(label_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_result_path2 = os.path.join(fit_result_path1, ee)\n",
    "if not os.path.exists(fit_result_path2):\n",
    "    makedirs(fit_result_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature train shape: (96966, 100, 128)\n",
      "feature test shape: (6668, 100, 128)\n",
      "label train shape: (96966,)\n",
      "label test shape: (6668,)\n",
      "dim_time: 100\n",
      "dim_freq: 128\n"
     ]
    }
   ],
   "source": [
    "print('feature train shape: '+str(fea_train.shape))\n",
    "print('feature test shape: '+str(fea_test.shape))\n",
    "print('label train shape: '+str(label_train.shape))\n",
    "print('label test shape: '+str(label_test.shape))\n",
    "\n",
    "dim_time = fea_train.shape[1]\n",
    "dim_freq = fea_train.shape[2]\n",
    "print('dim_time: '+str(dim_time))\n",
    "print('dim_freq: '+str(dim_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle features & labels\n",
    "fea_train, label_train = shuffle(fea_train, label_train, random_state=0)\n",
    "fea_test, label_test = shuffle(fea_test, label_test, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class weight\n",
    "weights = compute_class_weight(class_weight='balanced', classes=np.unique(label_train), y=label_train)\n",
    "\n",
    "class_weights = dict()\n",
    "for ii in range(num_species):\n",
    "    class_weights[ii] = weights[ii]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_train = np.expand_dims(fea_train, axis=3)\n",
    "fea_test = np.expand_dims(fea_test, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_train, fea_validate, label_train, label_validate = train_test_split(fea_train, label_train, test_size=0.30, random_state=42)\n",
    "\n",
    "train_generator = DataGenerator(fea_train, label_train, batch_size=batch_size, num_classes=num_species)\n",
    "del fea_train\n",
    "validate_generator = DataGenerator(fea_validate, label_validate, batch_size=batch_size, num_classes=num_species)\n",
    "del fea_validate\n",
    "\n",
    "# test_generator = DataGenerator(fea_test, label_test, batch_size=batch_size, num_classes=num_species)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 2.0845 - accuracy: 0.1162\n",
      "Epoch 00001: val_loss improved from inf to 2.07992, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210224_120153/STAR2000/epoch_01_valloss_2.0799_valacc_0.0830.hdf5\n",
      "2121/2121 [==============================] - 70s 33ms/step - loss: 2.0845 - accuracy: 0.1162 - val_loss: 2.0799 - val_accuracy: 0.0830\n",
      "Epoch 2/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 2.0800 - accuracy: 0.1038\n",
      "Epoch 00002: val_loss improved from 2.07992 to 2.07948, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210224_120153/STAR2000/epoch_02_valloss_2.0795_valacc_0.0549.hdf5\n",
      "2121/2121 [==============================] - 70s 33ms/step - loss: 2.0800 - accuracy: 0.1038 - val_loss: 2.0795 - val_accuracy: 0.0549\n",
      "Epoch 3/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 2.0801 - accuracy: 0.1070\n",
      "Epoch 00003: val_loss did not improve from 2.07948\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 2.0801 - accuracy: 0.1070 - val_loss: 2.0796 - val_accuracy: 0.1404\n",
      "Epoch 4/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 2.0800 - accuracy: 0.1182\n",
      "Epoch 00004: val_loss did not improve from 2.07948\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 2.0800 - accuracy: 0.1182 - val_loss: 2.0796 - val_accuracy: 0.0777\n",
      "Epoch 5/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 2.0800 - accuracy: 0.1367\n",
      "Epoch 00005: val_loss improved from 2.07948 to 2.07944, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210224_120153/STAR2000/epoch_05_valloss_2.0794_valacc_0.1427.hdf5\n",
      "2121/2121 [==============================] - 70s 33ms/step - loss: 2.0800 - accuracy: 0.1367 - val_loss: 2.0794 - val_accuracy: 0.1427\n",
      "Epoch 6/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 2.0800 - accuracy: 0.1531\n",
      "Epoch 00006: val_loss did not improve from 2.07944\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 2.0800 - accuracy: 0.1531 - val_loss: 2.0794 - val_accuracy: 0.1426\n",
      "Epoch 7/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 2.0800 - accuracy: 0.1400\n",
      "Epoch 00007: val_loss did not improve from 2.07944\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 2.0800 - accuracy: 0.1400 - val_loss: 2.0794 - val_accuracy: 0.1642\n",
      "Epoch 8/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 2.0800 - accuracy: 0.1162\n",
      "Epoch 00008: val_loss did not improve from 2.07944\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 2.0800 - accuracy: 0.1162 - val_loss: 2.0794 - val_accuracy: 0.1636\n",
      "Epoch 9/200\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 2.0801 - accuracy: 0.1279\n",
      "Epoch 00009: val_loss did not improve from 2.07944\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 2.0800 - accuracy: 0.1279 - val_loss: 2.0795 - val_accuracy: 0.1322\n",
      "Epoch 10/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 2.0805 - accuracy: 0.1524\n",
      "Epoch 00010: val_loss improved from 2.07944 to 2.07918, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210224_120153/STAR2000/epoch_10_valloss_2.0792_valacc_0.1566.hdf5\n",
      "2121/2121 [==============================] - 70s 33ms/step - loss: 2.0805 - accuracy: 0.1524 - val_loss: 2.0792 - val_accuracy: 0.1566\n",
      "Epoch 11/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 2.0378 - accuracy: 0.1832\n",
      "Epoch 00011: val_loss improved from 2.07918 to 1.93856, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210224_120153/STAR2000/epoch_11_valloss_1.9386_valacc_0.2658.hdf5\n",
      "2121/2121 [==============================] - 70s 33ms/step - loss: 2.0378 - accuracy: 0.1832 - val_loss: 1.9386 - val_accuracy: 0.2658\n",
      "Epoch 12/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 1.8071 - accuracy: 0.2973\n",
      "Epoch 00012: val_loss improved from 1.93856 to 1.74759, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210224_120153/STAR2000/epoch_12_valloss_1.7476_valacc_0.3157.hdf5\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 1.8071 - accuracy: 0.2973 - val_loss: 1.7476 - val_accuracy: 0.3157\n",
      "Epoch 13/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 1.6650 - accuracy: 0.3541\n",
      "Epoch 00013: val_loss did not improve from 1.74759\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 1.6650 - accuracy: 0.3541 - val_loss: 1.8650 - val_accuracy: 0.3199\n",
      "Epoch 14/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 1.5310 - accuracy: 0.4213\n",
      "Epoch 00014: val_loss did not improve from 1.74759\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 1.5310 - accuracy: 0.4213 - val_loss: 1.9830 - val_accuracy: 0.2120\n",
      "Epoch 15/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 1.4452 - accuracy: 0.4590\n",
      "Epoch 00015: val_loss improved from 1.74759 to 1.54207, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210224_120153/STAR2000/epoch_15_valloss_1.5421_valacc_0.4259.hdf5\n",
      "2121/2121 [==============================] - 70s 33ms/step - loss: 1.4452 - accuracy: 0.4590 - val_loss: 1.5421 - val_accuracy: 0.4259\n",
      "Epoch 16/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 1.3830 - accuracy: 0.4872\n",
      "Epoch 00016: val_loss improved from 1.54207 to 1.49814, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210224_120153/STAR2000/epoch_16_valloss_1.4981_valacc_0.4173.hdf5\n",
      "2121/2121 [==============================] - 70s 33ms/step - loss: 1.3830 - accuracy: 0.4872 - val_loss: 1.4981 - val_accuracy: 0.4173\n",
      "Epoch 17/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 1.3316 - accuracy: 0.5077\n",
      "Epoch 00017: val_loss did not improve from 1.49814\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 1.3316 - accuracy: 0.5077 - val_loss: 2.0379 - val_accuracy: 0.4089\n",
      "Epoch 18/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 1.2912 - accuracy: 0.5232\n",
      "Epoch 00018: val_loss did not improve from 1.49814\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 1.2912 - accuracy: 0.5232 - val_loss: 1.7548 - val_accuracy: 0.3815\n",
      "Epoch 19/200\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 1.2517 - accuracy: 0.5387\n",
      "Epoch 00019: val_loss improved from 1.49814 to 1.26980, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210224_120153/STAR2000/epoch_19_valloss_1.2698_valacc_0.5146.hdf5\n",
      "2121/2121 [==============================] - 70s 33ms/step - loss: 1.2517 - accuracy: 0.5387 - val_loss: 1.2698 - val_accuracy: 0.5146\n",
      "Epoch 20/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 1.2190 - accuracy: 0.5529\n",
      "Epoch 00020: val_loss did not improve from 1.26980\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 1.2190 - accuracy: 0.5529 - val_loss: 1.5256 - val_accuracy: 0.4390\n",
      "Epoch 21/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 1.1866 - accuracy: 0.5650\n",
      "Epoch 00021: val_loss did not improve from 1.26980\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 1.1866 - accuracy: 0.5650 - val_loss: 1.4187 - val_accuracy: 0.4639\n",
      "Epoch 22/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 1.1557 - accuracy: 0.5765\n",
      "Epoch 00022: val_loss improved from 1.26980 to 1.19289, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210224_120153/STAR2000/epoch_22_valloss_1.1929_valacc_0.5515.hdf5\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 1.1557 - accuracy: 0.5765 - val_loss: 1.1929 - val_accuracy: 0.5515\n",
      "Epoch 23/200\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 1.1294 - accuracy: 0.5861\n",
      "Epoch 00023: val_loss improved from 1.19289 to 1.12506, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210224_120153/STAR2000/epoch_23_valloss_1.1251_valacc_0.5744.hdf5\n",
      "2121/2121 [==============================] - 70s 33ms/step - loss: 1.1293 - accuracy: 0.5861 - val_loss: 1.1251 - val_accuracy: 0.5744\n",
      "Epoch 24/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 1.0975 - accuracy: 0.5967\n",
      "Epoch 00024: val_loss did not improve from 1.12506\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 1.0975 - accuracy: 0.5967 - val_loss: 1.3584 - val_accuracy: 0.5287\n",
      "Epoch 25/200\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 1.0735 - accuracy: 0.6067\n",
      "Epoch 00025: val_loss did not improve from 1.12506\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 1.0736 - accuracy: 0.6068 - val_loss: 1.1890 - val_accuracy: 0.5513\n",
      "Epoch 26/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 1.0507 - accuracy: 0.6110\n",
      "Epoch 00026: val_loss did not improve from 1.12506\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 1.0507 - accuracy: 0.6110 - val_loss: 1.6376 - val_accuracy: 0.4676\n",
      "Epoch 27/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 1.0274 - accuracy: 0.6234\n",
      "Epoch 00027: val_loss improved from 1.12506 to 1.03488, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210224_120153/STAR2000/epoch_27_valloss_1.0349_valacc_0.6061.hdf5\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 1.0274 - accuracy: 0.6234 - val_loss: 1.0349 - val_accuracy: 0.6061\n",
      "Epoch 28/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 1.0032 - accuracy: 0.6300\n",
      "Epoch 00028: val_loss did not improve from 1.03488\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 1.0032 - accuracy: 0.6300 - val_loss: 1.0663 - val_accuracy: 0.5967\n",
      "Epoch 29/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 0.9792 - accuracy: 0.6405\n",
      "Epoch 00029: val_loss did not improve from 1.03488\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 0.9792 - accuracy: 0.6405 - val_loss: 1.2813 - val_accuracy: 0.5162\n",
      "Epoch 30/200\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 0.9572 - accuracy: 0.6457\n",
      "Epoch 00030: val_loss improved from 1.03488 to 0.99812, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210224_120153/STAR2000/epoch_30_valloss_0.9981_valacc_0.6270.hdf5\n",
      "2121/2121 [==============================] - 70s 33ms/step - loss: 0.9571 - accuracy: 0.6457 - val_loss: 0.9981 - val_accuracy: 0.6270\n",
      "Epoch 31/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 0.9342 - accuracy: 0.6550\n",
      "Epoch 00031: val_loss did not improve from 0.99812\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 0.9342 - accuracy: 0.6550 - val_loss: 1.0042 - val_accuracy: 0.6214\n",
      "Epoch 32/200\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 0.9111 - accuracy: 0.6611\n",
      "Epoch 00032: val_loss did not improve from 0.99812\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 0.9111 - accuracy: 0.6611 - val_loss: 1.0150 - val_accuracy: 0.6263\n",
      "Epoch 33/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 0.8850 - accuracy: 0.6737\n",
      "Epoch 00033: val_loss improved from 0.99812 to 0.96247, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210224_120153/STAR2000/epoch_33_valloss_0.9625_valacc_0.6383.hdf5\n",
      "2121/2121 [==============================] - 70s 33ms/step - loss: 0.8850 - accuracy: 0.6737 - val_loss: 0.9625 - val_accuracy: 0.6383\n",
      "Epoch 34/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 0.8670 - accuracy: 0.6780\n",
      "Epoch 00034: val_loss did not improve from 0.96247\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 0.8670 - accuracy: 0.6780 - val_loss: 1.0981 - val_accuracy: 0.6034\n",
      "Epoch 35/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 0.8437 - accuracy: 0.6870\n",
      "Epoch 00035: val_loss did not improve from 0.96247\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 0.8437 - accuracy: 0.6870 - val_loss: 1.0356 - val_accuracy: 0.6149\n",
      "Epoch 36/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 0.8230 - accuracy: 0.6921\n",
      "Epoch 00036: val_loss did not improve from 0.96247\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 0.8230 - accuracy: 0.6921 - val_loss: 1.0403 - val_accuracy: 0.6202\n",
      "Epoch 37/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 0.8009 - accuracy: 0.6996\n",
      "Epoch 00037: val_loss improved from 0.96247 to 0.93843, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210224_120153/STAR2000/epoch_37_valloss_0.9384_valacc_0.6526.hdf5\n",
      "2121/2121 [==============================] - 70s 33ms/step - loss: 0.8009 - accuracy: 0.6996 - val_loss: 0.9384 - val_accuracy: 0.6526\n",
      "Epoch 38/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 0.7834 - accuracy: 0.7063\n",
      "Epoch 00038: val_loss did not improve from 0.93843\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 0.7834 - accuracy: 0.7063 - val_loss: 1.1965 - val_accuracy: 0.5923\n",
      "Epoch 39/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 0.7592 - accuracy: 0.7147\n",
      "Epoch 00039: val_loss did not improve from 0.93843\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 0.7592 - accuracy: 0.7147 - val_loss: 1.2072 - val_accuracy: 0.5781\n",
      "Epoch 40/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 0.7411 - accuracy: 0.7212\n",
      "Epoch 00040: val_loss did not improve from 0.93843\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 0.7411 - accuracy: 0.7212 - val_loss: 1.0133 - val_accuracy: 0.6550\n",
      "Epoch 41/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 0.7203 - accuracy: 0.7273\n",
      "Epoch 00041: val_loss improved from 0.93843 to 0.87757, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210224_120153/STAR2000/epoch_41_valloss_0.8776_valacc_0.6793.hdf5\n",
      "2121/2121 [==============================] - 70s 33ms/step - loss: 0.7203 - accuracy: 0.7273 - val_loss: 0.8776 - val_accuracy: 0.6793\n",
      "Epoch 42/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 0.6966 - accuracy: 0.7365\n",
      "Epoch 00042: val_loss did not improve from 0.87757\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 0.6966 - accuracy: 0.7365 - val_loss: 1.4596 - val_accuracy: 0.5924\n",
      "Epoch 43/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 0.6766 - accuracy: 0.7433\n",
      "Epoch 00043: val_loss did not improve from 0.87757\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 0.6766 - accuracy: 0.7433 - val_loss: 1.0380 - val_accuracy: 0.6539\n",
      "Epoch 44/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 0.6635 - accuracy: 0.7471\n",
      "Epoch 00044: val_loss did not improve from 0.87757\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 0.6635 - accuracy: 0.7471 - val_loss: 1.5649 - val_accuracy: 0.5529\n",
      "Epoch 45/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 0.6439 - accuracy: 0.7540\n",
      "Epoch 00045: val_loss did not improve from 0.87757\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 0.6439 - accuracy: 0.7540 - val_loss: 0.9245 - val_accuracy: 0.6675\n",
      "Epoch 46/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 0.6259 - accuracy: 0.7604\n",
      "Epoch 00046: val_loss did not improve from 0.87757\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 0.6259 - accuracy: 0.7604 - val_loss: 0.9194 - val_accuracy: 0.6872\n",
      "Epoch 47/200\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 0.6070 - accuracy: 0.7679\n",
      "Epoch 00047: val_loss did not improve from 0.87757\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 0.6070 - accuracy: 0.7679 - val_loss: 1.0563 - val_accuracy: 0.6390\n",
      "Epoch 48/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 0.5907 - accuracy: 0.7735\n",
      "Epoch 00048: val_loss did not improve from 0.87757\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 0.5907 - accuracy: 0.7735 - val_loss: 0.9199 - val_accuracy: 0.6838\n",
      "Epoch 49/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 0.5686 - accuracy: 0.7803\n",
      "Epoch 00049: val_loss did not improve from 0.87757\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 0.5686 - accuracy: 0.7803 - val_loss: 0.9186 - val_accuracy: 0.6782\n",
      "Epoch 50/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 0.5549 - accuracy: 0.7868\n",
      "Epoch 00050: val_loss did not improve from 0.87757\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 0.5549 - accuracy: 0.7868 - val_loss: 1.0635 - val_accuracy: 0.6700\n",
      "Epoch 51/200\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 0.5414 - accuracy: 0.7923\n",
      "Epoch 00051: val_loss did not improve from 0.87757\n",
      "2121/2121 [==============================] - 70s 33ms/step - loss: 0.5414 - accuracy: 0.7923 - val_loss: 1.2582 - val_accuracy: 0.6097\n",
      "Epoch 52/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 0.5252 - accuracy: 0.7968\n",
      "Epoch 00052: val_loss did not improve from 0.87757\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 0.5252 - accuracy: 0.7968 - val_loss: 0.9245 - val_accuracy: 0.7043\n",
      "Epoch 53/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 0.5126 - accuracy: 0.8012\n",
      "Epoch 00053: val_loss did not improve from 0.87757\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 0.5126 - accuracy: 0.8012 - val_loss: 0.9910 - val_accuracy: 0.6685\n",
      "Epoch 54/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 0.4992 - accuracy: 0.8072\n",
      "Epoch 00054: val_loss improved from 0.87757 to 0.84423, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210224_120153/STAR2000/epoch_54_valloss_0.8442_valacc_0.7074.hdf5\n",
      "2121/2121 [==============================] - 70s 33ms/step - loss: 0.4992 - accuracy: 0.8072 - val_loss: 0.8442 - val_accuracy: 0.7074\n",
      "Epoch 55/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 0.4797 - accuracy: 0.8147\n",
      "Epoch 00055: val_loss did not improve from 0.84423\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 0.4797 - accuracy: 0.8147 - val_loss: 1.1119 - val_accuracy: 0.6829\n",
      "Epoch 56/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 0.4682 - accuracy: 0.8182\n",
      "Epoch 00056: val_loss did not improve from 0.84423\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 0.4682 - accuracy: 0.8182 - val_loss: 1.0596 - val_accuracy: 0.6570\n",
      "Epoch 57/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 0.4546 - accuracy: 0.8232\n",
      "Epoch 00057: val_loss did not improve from 0.84423\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 0.4546 - accuracy: 0.8232 - val_loss: 1.1874 - val_accuracy: 0.6764\n",
      "Epoch 58/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 0.4398 - accuracy: 0.8284\n",
      "Epoch 00058: val_loss did not improve from 0.84423\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 0.4398 - accuracy: 0.8284 - val_loss: 0.8996 - val_accuracy: 0.7086\n",
      "Epoch 59/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 0.4285 - accuracy: 0.8326\n",
      "Epoch 00059: val_loss did not improve from 0.84423\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 0.4285 - accuracy: 0.8326 - val_loss: 0.9430 - val_accuracy: 0.7042\n",
      "Epoch 60/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 0.4080 - accuracy: 0.8404\n",
      "Epoch 00060: val_loss did not improve from 0.84423\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 0.4080 - accuracy: 0.8404 - val_loss: 0.9890 - val_accuracy: 0.7037\n",
      "Epoch 61/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 0.4005 - accuracy: 0.8429\n",
      "Epoch 00061: val_loss did not improve from 0.84423\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 0.4005 - accuracy: 0.8429 - val_loss: 0.9213 - val_accuracy: 0.7160\n",
      "Epoch 62/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 0.3890 - accuracy: 0.8480\n",
      "Epoch 00062: val_loss did not improve from 0.84423\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 0.3890 - accuracy: 0.8480 - val_loss: 0.9727 - val_accuracy: 0.6992\n",
      "Epoch 63/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 0.3725 - accuracy: 0.8524\n",
      "Epoch 00063: val_loss did not improve from 0.84423\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 0.3725 - accuracy: 0.8524 - val_loss: 1.2938 - val_accuracy: 0.6558\n",
      "Epoch 64/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 0.3648 - accuracy: 0.8561\n",
      "Epoch 00064: val_loss did not improve from 0.84423\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 0.3648 - accuracy: 0.8561 - val_loss: 0.8811 - val_accuracy: 0.7267\n",
      "Epoch 65/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 0.3506 - accuracy: 0.8624\n",
      "Epoch 00065: val_loss did not improve from 0.84423\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 0.3506 - accuracy: 0.8624 - val_loss: 0.8954 - val_accuracy: 0.7206\n",
      "Epoch 66/200\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 0.3398 - accuracy: 0.8651\n",
      "Epoch 00066: val_loss did not improve from 0.84423\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 0.3398 - accuracy: 0.8651 - val_loss: 0.9417 - val_accuracy: 0.7290\n",
      "Epoch 67/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 0.3276 - accuracy: 0.8716\n",
      "Epoch 00067: val_loss did not improve from 0.84423\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 0.3276 - accuracy: 0.8716 - val_loss: 1.0995 - val_accuracy: 0.6814\n",
      "Epoch 68/200\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 0.3241 - accuracy: 0.8725\n",
      "Epoch 00068: val_loss did not improve from 0.84423\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 0.3240 - accuracy: 0.8725 - val_loss: 0.9663 - val_accuracy: 0.7240\n",
      "Epoch 69/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 0.3123 - accuracy: 0.8783\n",
      "Epoch 00069: val_loss did not improve from 0.84423\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 0.3123 - accuracy: 0.8783 - val_loss: 1.0422 - val_accuracy: 0.7041\n",
      "Epoch 70/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 0.3030 - accuracy: 0.8797\n",
      "Epoch 00070: val_loss did not improve from 0.84423\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 0.3030 - accuracy: 0.8797 - val_loss: 1.2404 - val_accuracy: 0.6871\n",
      "Epoch 71/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 0.2918 - accuracy: 0.8848\n",
      "Epoch 00071: val_loss did not improve from 0.84423\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 0.2918 - accuracy: 0.8848 - val_loss: 1.0930 - val_accuracy: 0.6953\n",
      "Epoch 72/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 0.2823 - accuracy: 0.8892\n",
      "Epoch 00072: val_loss did not improve from 0.84423\n",
      "2121/2121 [==============================] - 69s 33ms/step - loss: 0.2823 - accuracy: 0.8892 - val_loss: 1.0858 - val_accuracy: 0.6928\n",
      "Epoch 73/200\n",
      "2120/2121 [============================>.] - ETA: 0s - loss: 0.2758 - accuracy: 0.8914\n",
      "Epoch 00073: val_loss did not improve from 0.84423\n",
      "2121/2121 [==============================] - 70s 33ms/step - loss: 0.2758 - accuracy: 0.8914 - val_loss: 1.1411 - val_accuracy: 0.6944\n",
      "Epoch 74/200\n",
      "2121/2121 [==============================] - ETA: 0s - loss: 0.2683 - accuracy: 0.8953\n",
      "Epoch 00074: val_loss did not improve from 0.84423\n",
      "2121/2121 [==============================] - 69s 32ms/step - loss: 0.2683 - accuracy: 0.8953 - val_loss: 1.0867 - val_accuracy: 0.7132\n",
      "Epoch 00074: early stopping\n"
     ]
    }
   ],
   "source": [
    "model = model_cnn14_attention_multi(dim_time, dim_freq, num_species, model_type='feature_level_attention', conv_dim=conv_dim, pool_size=pool_size, pool_stride=pool_stride, hidden_units=hidden_units, l2_regu=l2_regu, drop_rate=drop_rate)\n",
    "loss = CategoricalCrossentropy()\n",
    "# model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate_fn), loss=loss, metrics=['accuracy'])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss=loss, metrics=['accuracy'])\n",
    "\n",
    "# With classes\n",
    "# history = model.fit(fea_train, to_categorical(label_train), class_weight=class_weights, validation_split=0.3, batch_size=batch_size, epochs=num_epoch, callbacks=[EarlyStopping(patience=num_patience), ModelCheckpoint(filepath=os.path.join(fit_result_path, '{epoch:02d}-{val_loss:.4f}.hdf5'), verbose=1, monitor=\"val_loss\", save_best_only=True)])\n",
    "# history = model.fit(train_generator, validation_data=validate_generator, class_weight=class_weights, epochs=num_epoch, callbacks=[EarlyStopping(patience=num_patience, monitor='val_loss', mode='min', verbose=1), TensorBoard(log_dir=fit_result_path1), ModelCheckpoint(filepath=os.path.join(fit_result_path1, '{epoch:02d}-{val_loss:.4f}.hdf5'), verbose=1, monitor=\"val_loss\", save_best_only=True)])\n",
    "history = model.fit(train_generator, validation_data=validate_generator, class_weight=class_weights, epochs=num_epoch, callbacks=[EarlyStopping(patience=num_patience, monitor='val_loss', mode='min', verbose=1), TensorBoard(log_dir=fit_result_path2), ModelCheckpoint(filepath=os.path.join(fit_result_path2, 'epoch_{epoch:02d}_valloss_{val_loss:.4f}_valacc_{val_accuracy:.4f}.hdf5' ), verbose=1, monitor=\"val_loss\", save_best_only=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model:0.8442\n",
      "/home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210224_120153/STAR2000/epoch_54_valloss_0.8442_valacc_0.7074.hdf5\n"
     ]
    }
   ],
   "source": [
    "# fit_result_path1 = '/home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210210_224527'\n",
    "the_best_model, _ = find_best_model(fit_result_path2, purge=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 100, 128, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 100, 128, 16) 160         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 100, 128, 16) 64          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 100, 128, 16) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 100, 128, 16) 2320        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 100, 128, 16) 64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 100, 128, 16) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 50, 64, 16)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 50, 64, 16)   0           max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 50, 64, 32)   4640        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 50, 64, 32)   128         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 50, 64, 32)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 50, 64, 32)   9248        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 50, 64, 32)   128         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 50, 64, 32)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 25, 32, 32)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 25, 32, 32)   0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 25, 32, 64)   18496       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 25, 32, 64)   256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 25, 32, 64)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 25, 32, 64)   36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 25, 32, 64)   256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 25, 32, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 13, 16, 64)   0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 13, 16, 64)   0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 13, 16, 128)  73856       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 13, 16, 128)  512         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 13, 16, 128)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 13, 16, 128)  147584      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 13, 16, 128)  512         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 13, 16, 128)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 7, 8, 128)    0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 7, 8, 128)    0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 7, 8, 256)    295168      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 7, 8, 256)    1024        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 7, 8, 256)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 7, 8, 256)    590080      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 7, 8, 256)    1024        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 7, 8, 256)    0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 7, 4, 256)    0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 7, 4, 256)    0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 7, 4, 512)    1180160     dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 7, 4, 512)    2048        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 7, 4, 512)    0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 7, 4, 512)    2359808     activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 7, 4, 512)    2048        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 7, 4, 512)    0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 7, 2, 512)    0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 7, 2, 512)    0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 7, 1024)      0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 7, 512)       524800      reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 7, 512)       2048        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 7, 512)       0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 7, 512)       0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 7, 512)       262656      dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 7, 512)       2048        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 7, 512)       0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 7, 512)       0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 7, 512)       262656      dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 7, 512)       2048        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 7, 512)       0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 7, 512)       0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 7, 512)       262656      dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 7, 512)       262656      dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 512)          0           dense_3[0][0]                    \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 512)          2048        lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 512)          0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 512)          0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 8)            4104        dropout_9[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 6,314,232\n",
      "Trainable params: 6,306,104\n",
      "Non-trainable params: 8,128\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_model(the_best_model)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pred = model.predict(fea_test)\n",
    "# label_pred = model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=200, precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "['BD', 'CD', 'STR', 'SPT', 'SPIN', 'PLT', 'RT', 'FKW']\n",
      "\n",
      "[[  44   14    9   29    8    5    7    5]\n",
      " [ 741 1762  404  401  121  333  182   20]\n",
      " [ 274  173  250  235   45   97   51   15]\n",
      " [  87  393   28  221   15   57   32   12]\n",
      " [ 181   24   26  162   81   12    3    2]\n",
      " [   0    0    0    0    0   26    3    2]\n",
      " [  17    2    3    5    3   12   29    5]\n",
      " [   0    0    0    0    0    0    0    0]]\n",
      "\n",
      "[[0.36 0.12 0.07 0.24 0.07 0.04 0.06 0.04]\n",
      " [0.19 0.44 0.1  0.1  0.03 0.08 0.05 0.01]\n",
      " [0.24 0.15 0.22 0.21 0.04 0.09 0.04 0.01]\n",
      " [0.1  0.47 0.03 0.26 0.02 0.07 0.04 0.01]\n",
      " [0.37 0.05 0.05 0.33 0.16 0.02 0.01 0.  ]\n",
      " [0.   0.   0.   0.   0.   0.84 0.1  0.06]\n",
      " [0.22 0.03 0.04 0.07 0.04 0.16 0.38 0.07]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.  ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix:\")\n",
    "cm = confusion_matrix(label_test, np.argmax(label_pred, axis=1), labels=species_id)\n",
    "\n",
    "print(species_list)\n",
    "print('')\n",
    "print(cm)\n",
    "print('')\n",
    "\n",
    "cm2 = cm*1.0\n",
    "for ii in range(cm.shape[0]):\n",
    "    cm_row = cm[ii, :]*1.0\n",
    "\n",
    "    cm_row_sum = cm_row.sum()\n",
    "    if cm_row_sum != 0:\n",
    "        cm2[ii, :] = cm_row / cm_row_sum\n",
    "    else:\n",
    "        cm2[ii, :] = np.zeros(cm.shape[1])\n",
    "\n",
    "print(cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics._plot.confusion_matrix import ConfusionMatrixDisplay\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=species_list)\n",
    "disp2 = ConfusionMatrixDisplay(confusion_matrix=cm2, display_labels=species_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f37e06ec4f0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=[15, 15])\n",
    "disp.plot(include_values=True,\n",
    "                     cmap='viridis', ax=ax, xticks_rotation='horizontal',\n",
    "                     values_format=None, colorbar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f37e06ecf40>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=[15, 15])\n",
    "disp2.plot(include_values=True,\n",
    "                     cmap='viridis', ax=ax, xticks_rotation='horizontal',\n",
    "                     values_format='.2f', colorbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# score histogram of label_pred\n",
    "plt.hist(label_pred[:, 7], 21); plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## top k accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import top_k_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36187762447510496"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_accuracy_score(label_test, label_pred, k=1, labels=list(range(num_species)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5256448710257948"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_accuracy_score(label_test, label_pred, k=2, labels=list(range(num_species)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6454709058188363"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_accuracy_score(label_test, label_pred, k=3, labels=list(range(num_species)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7429514097180564"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_accuracy_score(label_test, label_pred, k=4, labels=list(range(num_species)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8318836232753449"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_accuracy_score(label_test, label_pred, k=5, labels=list(range(num_species)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8954709058188363"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_accuracy_score(label_test, label_pred, k=6, labels=list(range(num_species)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ys587/miniconda3/envs/whistle_classifier/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:817: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision_score(to_categorical(label_test, num_classes=8), label_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1=to_categorical(label_test, num_classes=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STAR2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STAR2003\n"
     ]
    }
   ],
   "source": [
    "ee = deployment[1]\n",
    "print(ee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "fea_temp = np.load(os.path.join(feature_path, 'train_oswald_no_'+ee+'.npz'))\n",
    "fea_train = fea_temp['fea_train']\n",
    "label_train_list = fea_temp['label_train']\n",
    "del fea_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train = np.zeros(len(label_train_list))\n",
    "for ii in range(len(label_train_list)):\n",
    "    label_train[ii] = species_dict[label_train_list[ii]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing data\n",
    "fea_temp = np.load(os.path.join(feature_path, 'oswald_'+ee+'_orig.npz'))\n",
    "fea_test = fea_temp['feas_orig']\n",
    "label_test_list = fea_temp['labels_orig']\n",
    "\n",
    "fea_test = fea_test[:,:100,:]\n",
    "label_test = np.zeros(len(label_test_list))\n",
    "for ii in range(len(label_test_list)):\n",
    "    label_test[ii] = species_dict[label_test_list[ii]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_train = fea_train[:,:100,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train = np.zeros(len(label_train_list))\n",
    "for ii in range(len(label_train_list)):\n",
    "    label_train[ii] = species_dict[label_train_list[ii]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'BD': 14412,\n",
       "         'CD': 24120,\n",
       "         'PLT': 14784,\n",
       "         'RT': 12008,\n",
       "         'SPIN': 11014,\n",
       "         'SPT': 18590,\n",
       "         'STR': 23280,\n",
       "         'FKW': 17460})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(label_train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0.0: 231, 1.0: 752, 7.0: 270, 4.0: 51, 3.0: 412, 2.0: 54})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(label_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_result_path2 = os.path.join(fit_result_path1, ee)\n",
    "if not os.path.exists(fit_result_path2):\n",
    "    makedirs(fit_result_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature train shape: (135668, 100, 128)\n",
      "feature test shape: (1770, 100, 128)\n",
      "label train shape: (135668,)\n",
      "label test shape: (1770,)\n",
      "dim_time: 100\n",
      "dim_freq: 128\n"
     ]
    }
   ],
   "source": [
    "print('feature train shape: '+str(fea_train.shape))\n",
    "print('feature test shape: '+str(fea_test.shape))\n",
    "print('label train shape: '+str(label_train.shape))\n",
    "print('label test shape: '+str(label_test.shape))\n",
    "\n",
    "dim_time = fea_train.shape[1]\n",
    "dim_freq = fea_train.shape[2]\n",
    "print('dim_time: '+str(dim_time))\n",
    "print('dim_freq: '+str(dim_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle features & labels\n",
    "fea_train, label_train = shuffle(fea_train, label_train, random_state=0)\n",
    "fea_test, label_test = shuffle(fea_test, label_test, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class weight\n",
    "weights = compute_class_weight(class_weight='balanced', classes=np.unique(label_train), y=label_train)\n",
    "\n",
    "class_weights = dict()\n",
    "for ii in range(num_species):\n",
    "    class_weights[ii] = weights[ii]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_train = np.expand_dims(fea_train, axis=3)\n",
    "fea_test = np.expand_dims(fea_test, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_train, fea_validate, label_train, label_validate = train_test_split(fea_train, label_train, test_size=0.30, random_state=42)\n",
    "\n",
    "train_generator = DataGenerator(fea_train, label_train, batch_size=batch_size, num_classes=num_species)\n",
    "del fea_train\n",
    "validate_generator = DataGenerator(fea_validate, label_validate, batch_size=batch_size, num_classes=num_species)\n",
    "del fea_validate\n",
    "\n",
    "# test_generator = DataGenerator(fea_test, label_test, batch_size=batch_size, num_classes=num_species)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "   2/2967 [..............................] - ETA: 7:40 - loss: 1.9965 - accuracy: 0.0781WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.142694). Check your callbacks.\n",
      "2966/2967 [============================>.] - ETA: 0s - loss: 1.8472 - accuracy: 0.2598\n",
      "Epoch 00001: val_loss improved from inf to 1.80735, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210224_120153/STAR2003/epoch_01_valloss_1.8074_valacc_0.3479.hdf5\n",
      "2967/2967 [==============================] - 97s 33ms/step - loss: 1.8471 - accuracy: 0.2598 - val_loss: 1.8074 - val_accuracy: 0.3479\n",
      "Epoch 2/200\n",
      "2967/2967 [==============================] - ETA: 0s - loss: 1.4823 - accuracy: 0.4359\n",
      "Epoch 00002: val_loss improved from 1.80735 to 1.62807, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210224_120153/STAR2003/epoch_02_valloss_1.6281_valacc_0.4032.hdf5\n",
      "2967/2967 [==============================] - 96s 32ms/step - loss: 1.4823 - accuracy: 0.4359 - val_loss: 1.6281 - val_accuracy: 0.4032\n",
      "Epoch 3/200\n",
      "2967/2967 [==============================] - ETA: 0s - loss: 1.3456 - accuracy: 0.4918\n",
      "Epoch 00003: val_loss improved from 1.62807 to 1.44253, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210224_120153/STAR2003/epoch_03_valloss_1.4425_valacc_0.4813.hdf5\n",
      "2967/2967 [==============================] - 96s 32ms/step - loss: 1.3456 - accuracy: 0.4918 - val_loss: 1.4425 - val_accuracy: 0.4813\n",
      "Epoch 4/200\n",
      "2967/2967 [==============================] - ETA: 0s - loss: 1.2541 - accuracy: 0.5304\n",
      "Epoch 00004: val_loss improved from 1.44253 to 1.31625, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210224_120153/STAR2003/epoch_04_valloss_1.3163_valacc_0.5064.hdf5\n",
      "2967/2967 [==============================] - 96s 32ms/step - loss: 1.2541 - accuracy: 0.5304 - val_loss: 1.3163 - val_accuracy: 0.5064\n",
      "Epoch 5/200\n",
      "2966/2967 [============================>.] - ETA: 0s - loss: 1.1808 - accuracy: 0.5602\n",
      "Epoch 00005: val_loss improved from 1.31625 to 1.26551, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210224_120153/STAR2003/epoch_05_valloss_1.2655_valacc_0.5306.hdf5\n",
      "2967/2967 [==============================] - 96s 32ms/step - loss: 1.1808 - accuracy: 0.5602 - val_loss: 1.2655 - val_accuracy: 0.5306\n",
      "Epoch 6/200\n",
      "2967/2967 [==============================] - ETA: 0s - loss: 1.1177 - accuracy: 0.5848\n",
      "Epoch 00006: val_loss improved from 1.26551 to 1.16016, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210224_120153/STAR2003/epoch_06_valloss_1.1602_valacc_0.5633.hdf5\n",
      "2967/2967 [==============================] - 96s 32ms/step - loss: 1.1177 - accuracy: 0.5848 - val_loss: 1.1602 - val_accuracy: 0.5633\n",
      "Epoch 7/200\n",
      "2967/2967 [==============================] - ETA: 0s - loss: 1.0633 - accuracy: 0.6049\n",
      "Epoch 00007: val_loss did not improve from 1.16016\n",
      "2967/2967 [==============================] - 96s 32ms/step - loss: 1.0633 - accuracy: 0.6049 - val_loss: 1.1698 - val_accuracy: 0.5694\n",
      "Epoch 8/200\n",
      "2967/2967 [==============================] - ETA: 0s - loss: 1.0178 - accuracy: 0.6207\n",
      "Epoch 00008: val_loss improved from 1.16016 to 1.11735, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210224_120153/STAR2003/epoch_08_valloss_1.1173_valacc_0.5806.hdf5\n",
      "2967/2967 [==============================] - 96s 32ms/step - loss: 1.0178 - accuracy: 0.6207 - val_loss: 1.1173 - val_accuracy: 0.5806\n",
      "Epoch 9/200\n",
      "2967/2967 [==============================] - ETA: 0s - loss: 0.9758 - accuracy: 0.6345\n",
      "Epoch 00009: val_loss improved from 1.11735 to 1.06486, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210224_120153/STAR2003/epoch_09_valloss_1.0649_valacc_0.6010.hdf5\n",
      "2967/2967 [==============================] - 96s 32ms/step - loss: 0.9758 - accuracy: 0.6345 - val_loss: 1.0649 - val_accuracy: 0.6010\n",
      "Epoch 10/200\n",
      "2967/2967 [==============================] - ETA: 0s - loss: 0.9422 - accuracy: 0.6478\n",
      "Epoch 00010: val_loss did not improve from 1.06486\n",
      "2967/2967 [==============================] - 96s 32ms/step - loss: 0.9422 - accuracy: 0.6478 - val_loss: 1.2110 - val_accuracy: 0.5535\n",
      "Epoch 11/200\n",
      "2966/2967 [============================>.] - ETA: 0s - loss: 0.9080 - accuracy: 0.6592\n",
      "Epoch 00011: val_loss did not improve from 1.06486\n",
      "2967/2967 [==============================] - 96s 32ms/step - loss: 0.9079 - accuracy: 0.6592 - val_loss: 1.0740 - val_accuracy: 0.6024\n",
      "Epoch 12/200\n",
      "2967/2967 [==============================] - ETA: 0s - loss: 0.8743 - accuracy: 0.6700\n",
      "Epoch 00012: val_loss improved from 1.06486 to 0.87887, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210224_120153/STAR2003/epoch_12_valloss_0.8789_valacc_0.6703.hdf5\n",
      "2967/2967 [==============================] - 96s 32ms/step - loss: 0.8743 - accuracy: 0.6700 - val_loss: 0.8789 - val_accuracy: 0.6703\n",
      "Epoch 13/200\n",
      "2967/2967 [==============================] - ETA: 0s - loss: 0.8435 - accuracy: 0.6829\n",
      "Epoch 00013: val_loss did not improve from 0.87887\n",
      "2967/2967 [==============================] - 97s 33ms/step - loss: 0.8435 - accuracy: 0.6829 - val_loss: 0.9447 - val_accuracy: 0.6548\n",
      "Epoch 14/200\n",
      "2967/2967 [==============================] - ETA: 0s - loss: 0.8185 - accuracy: 0.6889\n",
      "Epoch 00014: val_loss improved from 0.87887 to 0.85574, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210224_120153/STAR2003/epoch_14_valloss_0.8557_valacc_0.6768.hdf5\n",
      "2967/2967 [==============================] - 95s 32ms/step - loss: 0.8185 - accuracy: 0.6889 - val_loss: 0.8557 - val_accuracy: 0.6768\n",
      "Epoch 15/200\n",
      "2967/2967 [==============================] - ETA: 0s - loss: 0.7894 - accuracy: 0.7004\n",
      "Epoch 00015: val_loss did not improve from 0.85574\n",
      "2967/2967 [==============================] - 95s 32ms/step - loss: 0.7894 - accuracy: 0.7004 - val_loss: 0.9640 - val_accuracy: 0.6441\n",
      "Epoch 16/200\n",
      "2967/2967 [==============================] - ETA: 0s - loss: 0.7643 - accuracy: 0.7100\n",
      "Epoch 00016: val_loss did not improve from 0.85574\n",
      "2967/2967 [==============================] - 96s 32ms/step - loss: 0.7643 - accuracy: 0.7100 - val_loss: 0.9277 - val_accuracy: 0.6598\n",
      "Epoch 17/200\n",
      "2967/2967 [==============================] - ETA: 0s - loss: 0.7413 - accuracy: 0.7171\n",
      "Epoch 00017: val_loss did not improve from 0.85574\n",
      "2967/2967 [==============================] - 96s 32ms/step - loss: 0.7413 - accuracy: 0.7171 - val_loss: 0.9560 - val_accuracy: 0.6492\n",
      "Epoch 18/200\n",
      "2967/2967 [==============================] - ETA: 0s - loss: 0.7143 - accuracy: 0.7275\n",
      "Epoch 00018: val_loss improved from 0.85574 to 0.81791, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210224_120153/STAR2003/epoch_18_valloss_0.8179_valacc_0.7031.hdf5\n",
      "2967/2967 [==============================] - 99s 33ms/step - loss: 0.7143 - accuracy: 0.7275 - val_loss: 0.8179 - val_accuracy: 0.7031\n",
      "Epoch 19/200\n",
      "2967/2967 [==============================] - ETA: 0s - loss: 0.6921 - accuracy: 0.7337\n",
      "Epoch 00019: val_loss did not improve from 0.81791\n",
      "2967/2967 [==============================] - 99s 33ms/step - loss: 0.6921 - accuracy: 0.7337 - val_loss: 0.8823 - val_accuracy: 0.6814\n",
      "Epoch 20/200\n",
      "2966/2967 [============================>.] - ETA: 0s - loss: 0.6709 - accuracy: 0.7416\n",
      "Epoch 00020: val_loss did not improve from 0.81791\n",
      "2967/2967 [==============================] - 98s 33ms/step - loss: 0.6708 - accuracy: 0.7416 - val_loss: 0.8982 - val_accuracy: 0.6839\n",
      "Epoch 21/200\n",
      "2967/2967 [==============================] - ETA: 0s - loss: 0.6521 - accuracy: 0.7485\n",
      "Epoch 00021: val_loss improved from 0.81791 to 0.81318, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210224_120153/STAR2003/epoch_21_valloss_0.8132_valacc_0.7038.hdf5\n",
      "2967/2967 [==============================] - 95s 32ms/step - loss: 0.6521 - accuracy: 0.7485 - val_loss: 0.8132 - val_accuracy: 0.7038\n",
      "Epoch 22/200\n",
      "2966/2967 [============================>.] - ETA: 0s - loss: 0.6329 - accuracy: 0.7554\n",
      "Epoch 00022: val_loss improved from 0.81318 to 0.80751, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210224_120153/STAR2003/epoch_22_valloss_0.8075_valacc_0.7082.hdf5\n",
      "2967/2967 [==============================] - 98s 33ms/step - loss: 0.6328 - accuracy: 0.7554 - val_loss: 0.8075 - val_accuracy: 0.7082\n",
      "Epoch 23/200\n",
      "2967/2967 [==============================] - ETA: 0s - loss: 0.6107 - accuracy: 0.7637\n",
      "Epoch 00023: val_loss did not improve from 0.80751\n",
      "2967/2967 [==============================] - 100s 34ms/step - loss: 0.6107 - accuracy: 0.7637 - val_loss: 0.8518 - val_accuracy: 0.6939\n",
      "Epoch 24/200\n",
      "2967/2967 [==============================] - ETA: 0s - loss: 0.5908 - accuracy: 0.7699\n",
      "Epoch 00024: val_loss did not improve from 0.80751\n",
      "2967/2967 [==============================] - 97s 33ms/step - loss: 0.5908 - accuracy: 0.7699 - val_loss: 0.8363 - val_accuracy: 0.7002\n",
      "Epoch 25/200\n",
      "2967/2967 [==============================] - ETA: 0s - loss: 0.5765 - accuracy: 0.7751\n",
      "Epoch 00025: val_loss did not improve from 0.80751\n",
      "2967/2967 [==============================] - 95s 32ms/step - loss: 0.5765 - accuracy: 0.7751 - val_loss: 0.9154 - val_accuracy: 0.6883\n",
      "Epoch 26/200\n",
      "2966/2967 [============================>.] - ETA: 0s - loss: 0.5552 - accuracy: 0.7830\n",
      "Epoch 00026: val_loss improved from 0.80751 to 0.79333, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210224_120153/STAR2003/epoch_26_valloss_0.7933_valacc_0.7157.hdf5\n",
      "2967/2967 [==============================] - 96s 32ms/step - loss: 0.5552 - accuracy: 0.7830 - val_loss: 0.7933 - val_accuracy: 0.7157\n",
      "Epoch 27/200\n",
      "2967/2967 [==============================] - ETA: 0s - loss: 0.5399 - accuracy: 0.7892\n",
      "Epoch 00027: val_loss did not improve from 0.79333\n",
      "2967/2967 [==============================] - 95s 32ms/step - loss: 0.5399 - accuracy: 0.7892 - val_loss: 0.8960 - val_accuracy: 0.6968\n",
      "Epoch 28/200\n",
      "2967/2967 [==============================] - ETA: 0s - loss: 0.5220 - accuracy: 0.7962\n",
      "Epoch 00028: val_loss did not improve from 0.79333\n",
      "2967/2967 [==============================] - 95s 32ms/step - loss: 0.5220 - accuracy: 0.7962 - val_loss: 0.8701 - val_accuracy: 0.6967\n",
      "Epoch 29/200\n",
      "2966/2967 [============================>.] - ETA: 0s - loss: 0.5080 - accuracy: 0.8007\n",
      "Epoch 00029: val_loss did not improve from 0.79333\n",
      "2967/2967 [==============================] - 96s 32ms/step - loss: 0.5080 - accuracy: 0.8007 - val_loss: 0.8156 - val_accuracy: 0.7169\n",
      "Epoch 30/200\n",
      "2967/2967 [==============================] - ETA: 0s - loss: 0.4888 - accuracy: 0.8082\n",
      "Epoch 00030: val_loss did not improve from 0.79333\n",
      "2967/2967 [==============================] - 95s 32ms/step - loss: 0.4888 - accuracy: 0.8082 - val_loss: 0.8465 - val_accuracy: 0.7117\n",
      "Epoch 31/200\n",
      "2967/2967 [==============================] - ETA: 0s - loss: 0.4730 - accuracy: 0.8130\n",
      "Epoch 00031: val_loss improved from 0.79333 to 0.76301, saving model to /home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210224_120153/STAR2003/epoch_31_valloss_0.7630_valacc_0.7405.hdf5\n",
      "2967/2967 [==============================] - 95s 32ms/step - loss: 0.4730 - accuracy: 0.8130 - val_loss: 0.7630 - val_accuracy: 0.7405\n",
      "Epoch 32/200\n",
      "2966/2967 [============================>.] - ETA: 0s - loss: 0.4615 - accuracy: 0.8181\n",
      "Epoch 00032: val_loss did not improve from 0.76301\n",
      "2967/2967 [==============================] - 98s 33ms/step - loss: 0.4615 - accuracy: 0.8181 - val_loss: 0.8174 - val_accuracy: 0.7243\n",
      "Epoch 33/200\n",
      "2967/2967 [==============================] - ETA: 0s - loss: 0.4418 - accuracy: 0.8253\n",
      "Epoch 00033: val_loss did not improve from 0.76301\n",
      "2967/2967 [==============================] - 96s 32ms/step - loss: 0.4418 - accuracy: 0.8253 - val_loss: 0.7751 - val_accuracy: 0.7329\n",
      "Epoch 34/200\n",
      "1919/2967 [==================>...........] - ETA: 30s - loss: 0.4274 - accuracy: 0.8313"
     ]
    }
   ],
   "source": [
    "model = model_cnn14_attention_multi(dim_time, dim_freq, num_species, model_type='feature_level_attention', conv_dim=conv_dim, pool_size=pool_size, pool_stride=pool_stride, hidden_units=hidden_units, l2_regu=l2_regu, drop_rate=drop_rate)\n",
    "loss = CategoricalCrossentropy()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate_fn), loss=loss, metrics=['accuracy'])\n",
    "\n",
    "# With classes\n",
    "# history = model.fit(fea_train, to_categorical(label_train), class_weight=class_weights, validation_split=0.3, batch_size=batch_size, epochs=num_epoch, callbacks=[EarlyStopping(patience=num_patience), ModelCheckpoint(filepath=os.path.join(fit_result_path, '{epoch:02d}-{val_loss:.4f}.hdf5'), verbose=1, monitor=\"val_loss\", save_best_only=True)])\n",
    "# history = model.fit(train_generator, validation_data=validate_generator, class_weight=class_weights, epochs=num_epoch, callbacks=[EarlyStopping(patience=num_patience, monitor='val_loss', mode='min', verbose=1), TensorBoard(log_dir=fit_result_path1), ModelCheckpoint(filepath=os.path.join(fit_result_path1, '{epoch:02d}-{val_loss:.4f}.hdf5'), verbose=1, monitor=\"val_loss\", save_best_only=True)])\n",
    "history = model.fit(train_generator, validation_data=validate_generator, class_weight=class_weights, epochs=num_epoch, callbacks=[EarlyStopping(patience=num_patience, monitor='val_loss', mode='min', verbose=1), TensorBoard(log_dir=fit_result_path2), ModelCheckpoint(filepath=os.path.join(fit_result_path2, 'epoch_{epoch:02d}_valloss_{val_loss:.4f}_valacc_{val_accuracy:.4f}.hdf5' ), verbose=1, monitor=\"val_loss\", save_best_only=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit_result_path1 = '/home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210210_224527'\n",
    "the_best_model, _ = find_best_model(fit_result_path2, purge=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = load_model(the_best_model)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pred = model.predict(fea_test)\n",
    "# label_pred = model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=200, precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion matrix:\")\n",
    "cm = confusion_matrix(label_test, np.argmax(label_pred, axis=1), labels=species_id)\n",
    "\n",
    "print(species_list)\n",
    "print('')\n",
    "print(cm)\n",
    "print('')\n",
    "\n",
    "cm2 = cm*1.0\n",
    "for ii in range(cm.shape[0]):\n",
    "    cm_row = cm[ii, :]*1.0\n",
    "\n",
    "    cm_row_sum = cm_row.sum()\n",
    "    if cm_row_sum != 0:\n",
    "        cm2[ii, :] = cm_row / cm_row_sum\n",
    "    else:\n",
    "        cm2[ii, :] = np.zeros(cm.shape[1])\n",
    "\n",
    "print(cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics._plot.confusion_matrix import ConfusionMatrixDisplay\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=species_list)\n",
    "disp2 = ConfusionMatrixDisplay(confusion_matrix=cm2, display_labels=species_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[15, 15])\n",
    "disp.plot(include_values=True,\n",
    "                     cmap='viridis', ax=ax, xticks_rotation='horizontal',\n",
    "                     values_format=None, colorbar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[15, 15])\n",
    "disp2.plot(include_values=True,\n",
    "                     cmap='viridis', ax=ax, xticks_rotation='horizontal',\n",
    "                     values_format='.2f', colorbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STAR2006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee = deployment[2]\n",
    "print(ee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "fea_temp = np.load(os.path.join(feature_path, 'train_oswald_no_'+ee+'.npz'))\n",
    "fea_train = fea_temp['fea_train']\n",
    "label_train_list = fea_temp['label_train']\n",
    "del fea_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train = np.zeros(len(label_train_list))\n",
    "for ii in range(len(label_train_list)):\n",
    "    label_train[ii] = species_dict[label_train_list[ii]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing data\n",
    "fea_temp = np.load(os.path.join(feature_path, 'oswald_'+ee+'_orig.npz'))\n",
    "fea_test = fea_temp['feas_orig']\n",
    "label_test_list = fea_temp['labels_orig']\n",
    "\n",
    "fea_test = fea_test[:,:100,:]\n",
    "label_test = np.zeros(len(label_test_list))\n",
    "for ii in range(len(label_test_list)):\n",
    "    label_test[ii] = species_dict[label_test_list[ii]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_train = fea_train[:,:100,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train = np.zeros(len(label_train_list))\n",
    "for ii in range(len(label_train_list)):\n",
    "    label_train[ii] = species_dict[label_train_list[ii]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Counter(label_train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(label_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_result_path2 = os.path.join(fit_result_path1, ee)\n",
    "if not os.path.exists(fit_result_path2):\n",
    "    makedirs(fit_result_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('feature train shape: '+str(fea_train.shape))\n",
    "print('feature test shape: '+str(fea_test.shape))\n",
    "print('label train shape: '+str(label_train.shape))\n",
    "print('label test shape: '+str(label_test.shape))\n",
    "\n",
    "dim_time = fea_train.shape[1]\n",
    "dim_freq = fea_train.shape[2]\n",
    "print('dim_time: '+str(dim_time))\n",
    "print('dim_freq: '+str(dim_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle features & labels\n",
    "fea_train, label_train = shuffle(fea_train, label_train, random_state=0)\n",
    "fea_test, label_test = shuffle(fea_test, label_test, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class weight\n",
    "weights = compute_class_weight(class_weight='balanced', classes=np.unique(label_train), y=label_train)\n",
    "\n",
    "class_weights = dict()\n",
    "for ii in range(num_species):\n",
    "    class_weights[ii] = weights[ii]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_train = np.expand_dims(fea_train, axis=3)\n",
    "fea_test = np.expand_dims(fea_test, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_train, fea_validate, label_train, label_validate = train_test_split(fea_train, label_train, test_size=0.30, random_state=42)\n",
    "\n",
    "train_generator = DataGenerator(fea_train, label_train, batch_size=batch_size, num_classes=num_species)\n",
    "del fea_train\n",
    "validate_generator = DataGenerator(fea_validate, label_validate, batch_size=batch_size, num_classes=num_species)\n",
    "del fea_validate\n",
    "\n",
    "# test_generator = DataGenerator(fea_test, label_test, batch_size=batch_size, num_classes=num_species)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = model_cnn14_attention_multi(dim_time, dim_freq, num_species, model_type='feature_level_attention', conv_dim=conv_dim, pool_size=pool_size, pool_stride=pool_stride, hidden_units=hidden_units, l2_regu=l2_regu, drop_rate=drop_rate)\n",
    "loss = CategoricalCrossentropy()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate_fn), loss=loss, metrics=['accuracy'])\n",
    "\n",
    "# With classes\n",
    "# history = model.fit(fea_train, to_categorical(label_train), class_weight=class_weights, validation_split=0.3, batch_size=batch_size, epochs=num_epoch, callbacks=[EarlyStopping(patience=num_patience), ModelCheckpoint(filepath=os.path.join(fit_result_path, '{epoch:02d}-{val_loss:.4f}.hdf5'), verbose=1, monitor=\"val_loss\", save_best_only=True)])\n",
    "# history = model.fit(train_generator, validation_data=validate_generator, class_weight=class_weights, epochs=num_epoch, callbacks=[EarlyStopping(patience=num_patience, monitor='val_loss', mode='min', verbose=1), TensorBoard(log_dir=fit_result_path1), ModelCheckpoint(filepath=os.path.join(fit_result_path1, '{epoch:02d}-{val_loss:.4f}.hdf5'), verbose=1, monitor=\"val_loss\", save_best_only=True)])\n",
    "history = model.fit(train_generator, validation_data=validate_generator, class_weight=class_weights, epochs=num_epoch, callbacks=[EarlyStopping(patience=num_patience, monitor='val_loss', mode='min', verbose=1), TensorBoard(log_dir=fit_result_path2), ModelCheckpoint(filepath=os.path.join(fit_result_path2, 'epoch_{epoch:02d}_valloss_{val_loss:.4f}_valacc_{val_accuracy:.4f}.hdf5' ), verbose=1, monitor=\"val_loss\", save_best_only=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit_result_path1 = '/home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210210_224527'\n",
    "the_best_model, _ = find_best_model(fit_result_path2, purge=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = load_model(the_best_model)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pred = model.predict(fea_test)\n",
    "# label_pred = model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=200, precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion matrix:\")\n",
    "cm = confusion_matrix(label_test, np.argmax(label_pred, axis=1), labels=species_id)\n",
    "\n",
    "print(species_list)\n",
    "print('')\n",
    "print(cm)\n",
    "print('')\n",
    "\n",
    "cm2 = cm*1.0\n",
    "for ii in range(cm.shape[0]):\n",
    "    cm_row = cm[ii, :]*1.0\n",
    "\n",
    "    cm_row_sum = cm_row.sum()\n",
    "    if cm_row_sum != 0:\n",
    "        cm2[ii, :] = cm_row / cm_row_sum\n",
    "    else:\n",
    "        cm2[ii, :] = np.zeros(cm.shape[1])\n",
    "\n",
    "print(cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics._plot.confusion_matrix import ConfusionMatrixDisplay\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=species_list)\n",
    "disp2 = ConfusionMatrixDisplay(confusion_matrix=cm2, display_labels=species_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[15, 15])\n",
    "disp.plot(include_values=True,\n",
    "                     cmap='viridis', ax=ax, xticks_rotation='horizontal',\n",
    "                     values_format=None, colorbar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[15, 15])\n",
    "disp2.plot(include_values=True,\n",
    "                     cmap='viridis', ax=ax, xticks_rotation='horizontal',\n",
    "                     values_format='.2f', colorbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HICEAS2002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee = deployment[3]\n",
    "print(ee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "fea_temp = np.load(os.path.join(feature_path, 'train_oswald_no_'+ee+'.npz'))\n",
    "fea_train = fea_temp['fea_train']\n",
    "label_train_list = fea_temp['label_train']\n",
    "del fea_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train = np.zeros(len(label_train_list))\n",
    "for ii in range(len(label_train_list)):\n",
    "    label_train[ii] = species_dict[label_train_list[ii]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing data\n",
    "fea_temp = np.load(os.path.join(feature_path, 'oswald_'+ee+'_orig.npz'))\n",
    "fea_test = fea_temp['feas_orig']\n",
    "label_test_list = fea_temp['labels_orig']\n",
    "\n",
    "fea_test = fea_test[:,:100,:]\n",
    "label_test = np.zeros(len(label_test_list))\n",
    "for ii in range(len(label_test_list)):\n",
    "    label_test[ii] = species_dict[label_test_list[ii]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_train = fea_train[:,:100,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train = np.zeros(len(label_train_list))\n",
    "for ii in range(len(label_train_list)):\n",
    "    label_train[ii] = species_dict[label_train_list[ii]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Counter(label_train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(label_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_result_path2 = os.path.join(fit_result_path1, ee)\n",
    "if not os.path.exists(fit_result_path2):\n",
    "    makedirs(fit_result_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('feature train shape: '+str(fea_train.shape))\n",
    "print('feature test shape: '+str(fea_test.shape))\n",
    "print('label train shape: '+str(label_train.shape))\n",
    "print('label test shape: '+str(label_test.shape))\n",
    "\n",
    "dim_time = fea_train.shape[1]\n",
    "dim_freq = fea_train.shape[2]\n",
    "print('dim_time: '+str(dim_time))\n",
    "print('dim_freq: '+str(dim_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle features & labels\n",
    "fea_train, label_train = shuffle(fea_train, label_train, random_state=0)\n",
    "fea_test, label_test = shuffle(fea_test, label_test, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class weight\n",
    "weights = compute_class_weight(class_weight='balanced', classes=np.unique(label_train), y=label_train)\n",
    "\n",
    "class_weights = dict()\n",
    "for ii in range(num_species):\n",
    "    class_weights[ii] = weights[ii]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_train = np.expand_dims(fea_train, axis=3)\n",
    "fea_test = np.expand_dims(fea_test, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_train, fea_validate, label_train, label_validate = train_test_split(fea_train, label_train, test_size=0.30, random_state=42)\n",
    "\n",
    "train_generator = DataGenerator(fea_train, label_train, batch_size=batch_size, num_classes=num_species)\n",
    "del fea_train\n",
    "validate_generator = DataGenerator(fea_validate, label_validate, batch_size=batch_size, num_classes=num_species)\n",
    "del fea_validate\n",
    "\n",
    "# test_generator = DataGenerator(fea_test, label_test, batch_size=batch_size, num_classes=num_species)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = model_cnn14_attention_multi(dim_time, dim_freq, num_species, model_type='feature_level_attention', conv_dim=conv_dim, pool_size=pool_size, pool_stride=pool_stride, hidden_units=hidden_units, l2_regu=l2_regu, drop_rate=drop_rate)\n",
    "loss = CategoricalCrossentropy()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate_fn), loss=loss, metrics=['accuracy'])\n",
    "\n",
    "# With classes\n",
    "# history = model.fit(fea_train, to_categorical(label_train), class_weight=class_weights, validation_split=0.3, batch_size=batch_size, epochs=num_epoch, callbacks=[EarlyStopping(patience=num_patience), ModelCheckpoint(filepath=os.path.join(fit_result_path, '{epoch:02d}-{val_loss:.4f}.hdf5'), verbose=1, monitor=\"val_loss\", save_best_only=True)])\n",
    "# history = model.fit(train_generator, validation_data=validate_generator, class_weight=class_weights, epochs=num_epoch, callbacks=[EarlyStopping(patience=num_patience, monitor='val_loss', mode='min', verbose=1), TensorBoard(log_dir=fit_result_path1), ModelCheckpoint(filepath=os.path.join(fit_result_path1, '{epoch:02d}-{val_loss:.4f}.hdf5'), verbose=1, monitor=\"val_loss\", save_best_only=True)])\n",
    "history = model.fit(train_generator, validation_data=validate_generator, class_weight=class_weights, epochs=num_epoch, callbacks=[EarlyStopping(patience=num_patience, monitor='val_loss', mode='min', verbose=1), TensorBoard(log_dir=fit_result_path2), ModelCheckpoint(filepath=os.path.join(fit_result_path2, 'epoch_{epoch:02d}_valloss_{val_loss:.4f}_valacc_{val_accuracy:.4f}.hdf5' ), verbose=1, monitor=\"val_loss\", save_best_only=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit_result_path1 = '/home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210210_224527'\n",
    "the_best_model, _ = find_best_model(fit_result_path2, purge=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = load_model(the_best_model)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pred = model.predict(fea_test)\n",
    "# label_pred = model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=200, precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion matrix:\")\n",
    "cm = confusion_matrix(label_test, np.argmax(label_pred, axis=1), labels=species_id)\n",
    "\n",
    "print(species_list)\n",
    "print('')\n",
    "print(cm)\n",
    "print('')\n",
    "\n",
    "cm2 = cm*1.0\n",
    "for ii in range(cm.shape[0]):\n",
    "    cm_row = cm[ii, :]*1.0\n",
    "\n",
    "    cm_row_sum = cm_row.sum()\n",
    "    if cm_row_sum != 0:\n",
    "        cm2[ii, :] = cm_row / cm_row_sum\n",
    "    else:\n",
    "        cm2[ii, :] = np.zeros(cm.shape[1])\n",
    "\n",
    "print(cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics._plot.confusion_matrix import ConfusionMatrixDisplay\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=species_list)\n",
    "disp2 = ConfusionMatrixDisplay(confusion_matrix=cm2, display_labels=species_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[15, 15])\n",
    "disp.plot(include_values=True,\n",
    "                     cmap='viridis', ax=ax, xticks_rotation='horizontal',\n",
    "                     values_format=None, colorbar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[15, 15])\n",
    "disp2.plot(include_values=True,\n",
    "                     cmap='viridis', ax=ax, xticks_rotation='horizontal',\n",
    "                     values_format='.2f', colorbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PICES2005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee = deployment[4]\n",
    "print(ee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "fea_temp = np.load(os.path.join(feature_path, 'train_oswald_no_'+ee+'.npz'))\n",
    "fea_train = fea_temp['fea_train']\n",
    "label_train_list = fea_temp['label_train']\n",
    "del fea_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train = np.zeros(len(label_train_list))\n",
    "for ii in range(len(label_train_list)):\n",
    "    label_train[ii] = species_dict[label_train_list[ii]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing data\n",
    "fea_temp = np.load(os.path.join(feature_path, 'oswald_'+ee+'_orig.npz'))\n",
    "fea_test = fea_temp['feas_orig']\n",
    "label_test_list = fea_temp['labels_orig']\n",
    "\n",
    "fea_test = fea_test[:,:100,:]\n",
    "label_test = np.zeros(len(label_test_list))\n",
    "for ii in range(len(label_test_list)):\n",
    "    label_test[ii] = species_dict[label_test_list[ii]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_train = fea_train[:,:100,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train = np.zeros(len(label_train_list))\n",
    "for ii in range(len(label_train_list)):\n",
    "    label_train[ii] = species_dict[label_train_list[ii]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Counter(label_train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(label_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_result_path2 = os.path.join(fit_result_path1, ee)\n",
    "if not os.path.exists(fit_result_path2):\n",
    "    makedirs(fit_result_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('feature train shape: '+str(fea_train.shape))\n",
    "print('feature test shape: '+str(fea_test.shape))\n",
    "print('label train shape: '+str(label_train.shape))\n",
    "print('label test shape: '+str(label_test.shape))\n",
    "\n",
    "dim_time = fea_train.shape[1]\n",
    "dim_freq = fea_train.shape[2]\n",
    "print('dim_time: '+str(dim_time))\n",
    "print('dim_freq: '+str(dim_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle features & labels\n",
    "fea_train, label_train = shuffle(fea_train, label_train, random_state=0)\n",
    "fea_test, label_test = shuffle(fea_test, label_test, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class weight\n",
    "weights = compute_class_weight(class_weight='balanced', classes=np.unique(label_train), y=label_train)\n",
    "\n",
    "class_weights = dict()\n",
    "for ii in range(num_species):\n",
    "    class_weights[ii] = weights[ii]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_train = np.expand_dims(fea_train, axis=3)\n",
    "fea_test = np.expand_dims(fea_test, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_train, fea_validate, label_train, label_validate = train_test_split(fea_train, label_train, test_size=0.30, random_state=42)\n",
    "\n",
    "train_generator = DataGenerator(fea_train, label_train, batch_size=batch_size, num_classes=num_species)\n",
    "del fea_train\n",
    "validate_generator = DataGenerator(fea_validate, label_validate, batch_size=batch_size, num_classes=num_species)\n",
    "del fea_validate\n",
    "\n",
    "# test_generator = DataGenerator(fea_test, label_test, batch_size=batch_size, num_classes=num_species)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = model_cnn14_attention_multi(dim_time, dim_freq, num_species, model_type='feature_level_attention', conv_dim=conv_dim, pool_size=pool_size, pool_stride=pool_stride, hidden_units=hidden_units, l2_regu=l2_regu, drop_rate=drop_rate)\n",
    "loss = CategoricalCrossentropy()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate_fn), loss=loss, metrics=['accuracy'])\n",
    "\n",
    "# With classes\n",
    "# history = model.fit(fea_train, to_categorical(label_train), class_weight=class_weights, validation_split=0.3, batch_size=batch_size, epochs=num_epoch, callbacks=[EarlyStopping(patience=num_patience), ModelCheckpoint(filepath=os.path.join(fit_result_path, '{epoch:02d}-{val_loss:.4f}.hdf5'), verbose=1, monitor=\"val_loss\", save_best_only=True)])\n",
    "# history = model.fit(train_generator, validation_data=validate_generator, class_weight=class_weights, epochs=num_epoch, callbacks=[EarlyStopping(patience=num_patience, monitor='val_loss', mode='min', verbose=1), TensorBoard(log_dir=fit_result_path1), ModelCheckpoint(filepath=os.path.join(fit_result_path1, '{epoch:02d}-{val_loss:.4f}.hdf5'), verbose=1, monitor=\"val_loss\", save_best_only=True)])\n",
    "history = model.fit(train_generator, validation_data=validate_generator, class_weight=class_weights, epochs=num_epoch, callbacks=[EarlyStopping(patience=num_patience, monitor='val_loss', mode='min', verbose=1), TensorBoard(log_dir=fit_result_path2), ModelCheckpoint(filepath=os.path.join(fit_result_path2, 'epoch_{epoch:02d}_valloss_{val_loss:.4f}_valacc_{val_accuracy:.4f}.hdf5' ), verbose=1, monitor=\"val_loss\", save_best_only=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit_result_path1 = '/home/ys587/__Data/__whistle/__whislte_30_species/__fit_result_species/20210210_224527'\n",
    "the_best_model, _ = find_best_model(fit_result_path2, purge=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = load_model(the_best_model)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pred = model.predict(fea_test)\n",
    "# label_pred = model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=200, precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confusion matrix:\")\n",
    "cm = confusion_matrix(label_test, np.argmax(label_pred, axis=1), labels=species_id)\n",
    "\n",
    "print(species_list)\n",
    "print('')\n",
    "print(cm)\n",
    "print('')\n",
    "\n",
    "cm2 = cm*1.0\n",
    "for ii in range(cm.shape[0]):\n",
    "    cm_row = cm[ii, :]*1.0\n",
    "\n",
    "    cm_row_sum = cm_row.sum()\n",
    "    if cm_row_sum != 0:\n",
    "        cm2[ii, :] = cm_row / cm_row_sum\n",
    "    else:\n",
    "        cm2[ii, :] = np.zeros(cm.shape[1])\n",
    "\n",
    "print(cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics._plot.confusion_matrix import ConfusionMatrixDisplay\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=species_list)\n",
    "disp2 = ConfusionMatrixDisplay(confusion_matrix=cm2, display_labels=species_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[15, 15])\n",
    "disp.plot(include_values=True,\n",
    "                     cmap='viridis', ax=ax, xticks_rotation='horizontal',\n",
    "                     values_format=None, colorbar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[15, 15])\n",
    "disp2.plot(include_values=True,\n",
    "                     cmap='viridis', ax=ax, xticks_rotation='horizontal',\n",
    "                     values_format='.2f', colorbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
